{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "id": "tkly-X7mA3Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "fiSOUPhP54pQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "514ebfc7-4841-4909-8c11-78d5d3cfc305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/devign-CodeVul/dataset"
      ],
      "metadata": {
        "id": "Q-iloZyP5_Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf9d922-4b1a-49d2-a7d7-a37085f28f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devign-CodeVul/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUKIcvud5xgl"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1x6hoF7G-tSYxg8AFybggypLZgMGDNHfF\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess.py\n"
      ],
      "metadata": {
        "id": "7aB2TOcP52wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_json('/content/drive/MyDrive/devign-CodeVul/dataset/train.jsonl', lines=True)\n"
      ],
      "metadata": {
        "id": "wjEhM6mT8bk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "I5Oi6KoQA7_S",
        "outputId": "43faa964-48d2-48af-bce7-7843b3c0ec71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      project                                 commit_id  target  \\\n",
              "0      FFmpeg  973b1a6b9070e2bf17d17568cbaf4043ce931f51       0   \n",
              "1      FFmpeg  321b2a9ded0468670b7678b7c098886930ae16b2       0   \n",
              "2      FFmpeg  5d5de3eba4c7890c2e8077f5b4ae569671d11cf8       0   \n",
              "3      FFmpeg  57d77b3963ce1023eaf5ada8cba58b9379405cc8       0   \n",
              "4      FFmpeg  aba232cfa9b193604ed98f3fa505378d006b1b3b       1   \n",
              "...       ...                                       ...     ...   \n",
              "21849    qemu  a8170e5e97ad17ca169c64ba87ae2f53850dab4c       0   \n",
              "21850    qemu  1ea879e5580f63414693655fcf0328559cdce138       0   \n",
              "21851    qemu  f74990a5d019751c545e9800a3376b6336e77d38       0   \n",
              "21852    qemu  a89f364ae8740dfc31b321eed9ee454e996dc3c1       0   \n",
              "21853    qemu  39fb730aed8c5f7b0058845cb9feac0d4b177985       0   \n",
              "\n",
              "                                                    func    idx  \n",
              "0      static av_cold int vdadec_init(AVCodecContext ...      0  \n",
              "1      static int transcode(AVFormatContext **output_...      1  \n",
              "2      static void v4l2_free_buffer(void *opaque, uin...      2  \n",
              "3      int av_opencl_buffer_write(cl_mem dst_cl_buf, ...      4  \n",
              "4      static int r3d_read_rdvo(AVFormatContext *s, A...      5  \n",
              "...                                                  ...    ...  \n",
              "21849  static void exynos4210_mct_write(void *opaque,...  27312  \n",
              "21850  static int no_init_in (HWVoiceIn *hw, audsetti...  27313  \n",
              "21851  uint32_t HELPER(stfle)(CPUS390XState *env, uin...  27314  \n",
              "21852  static void pxa2xx_fir_write(void *opaque, hwa...  27315  \n",
              "21853  static void disas_thumb_insn(CPUARMState *env,...  27316  \n",
              "\n",
              "[21854 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-859701cc-ff81-4101-8243-d866eee312b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project</th>\n",
              "      <th>commit_id</th>\n",
              "      <th>target</th>\n",
              "      <th>func</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>973b1a6b9070e2bf17d17568cbaf4043ce931f51</td>\n",
              "      <td>0</td>\n",
              "      <td>static av_cold int vdadec_init(AVCodecContext ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>321b2a9ded0468670b7678b7c098886930ae16b2</td>\n",
              "      <td>0</td>\n",
              "      <td>static int transcode(AVFormatContext **output_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>5d5de3eba4c7890c2e8077f5b4ae569671d11cf8</td>\n",
              "      <td>0</td>\n",
              "      <td>static void v4l2_free_buffer(void *opaque, uin...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>57d77b3963ce1023eaf5ada8cba58b9379405cc8</td>\n",
              "      <td>0</td>\n",
              "      <td>int av_opencl_buffer_write(cl_mem dst_cl_buf, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>aba232cfa9b193604ed98f3fa505378d006b1b3b</td>\n",
              "      <td>1</td>\n",
              "      <td>static int r3d_read_rdvo(AVFormatContext *s, A...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21849</th>\n",
              "      <td>qemu</td>\n",
              "      <td>a8170e5e97ad17ca169c64ba87ae2f53850dab4c</td>\n",
              "      <td>0</td>\n",
              "      <td>static void exynos4210_mct_write(void *opaque,...</td>\n",
              "      <td>27312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21850</th>\n",
              "      <td>qemu</td>\n",
              "      <td>1ea879e5580f63414693655fcf0328559cdce138</td>\n",
              "      <td>0</td>\n",
              "      <td>static int no_init_in (HWVoiceIn *hw, audsetti...</td>\n",
              "      <td>27313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21851</th>\n",
              "      <td>qemu</td>\n",
              "      <td>f74990a5d019751c545e9800a3376b6336e77d38</td>\n",
              "      <td>0</td>\n",
              "      <td>uint32_t HELPER(stfle)(CPUS390XState *env, uin...</td>\n",
              "      <td>27314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21852</th>\n",
              "      <td>qemu</td>\n",
              "      <td>a89f364ae8740dfc31b321eed9ee454e996dc3c1</td>\n",
              "      <td>0</td>\n",
              "      <td>static void pxa2xx_fir_write(void *opaque, hwa...</td>\n",
              "      <td>27315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21853</th>\n",
              "      <td>qemu</td>\n",
              "      <td>39fb730aed8c5f7b0058845cb9feac0d4b177985</td>\n",
              "      <td>0</td>\n",
              "      <td>static void disas_thumb_insn(CPUARMState *env,...</td>\n",
              "      <td>27316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21854 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-859701cc-ff81-4101-8243-d866eee312b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-859701cc-ff81-4101-8243-d866eee312b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-859701cc-ff81-4101-8243-d866eee312b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df =  pd.read_json('/content/drive/MyDrive/devign-CodeVul/dataset/test.jsonl', lines=True)\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "vu1kul_EA9iE",
        "outputId": "778aef76-030e-4670-d089-b952a0b50032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     project                                 commit_id  target  \\\n",
              "0     FFmpeg  32bf6550cb9cc9f487a6722fe2bfc272a93c1065       0   \n",
              "1       qemu  c0c24b95542bc1a4dc3fc6ea71475ae04fa69189       1   \n",
              "2     FFmpeg  5ff998a233d759d0de83ea6f95c383d03d25d88e       1   \n",
              "3       qemu  24408a7d2b459bed3697367b81ada76518ca96ef       0   \n",
              "4     FFmpeg  68f593b48433842f3407586679fe07f3e5199ab9       0   \n",
              "...      ...                                       ...     ...   \n",
              "2727    qemu  04088adbe0c5adca66adb6022723362ad90ed0fc       0   \n",
              "2728  FFmpeg  3a25c707fae3c6e99fdda40474c3d74be24cc4c3       0   \n",
              "2729  FFmpeg  d6604b29ef544793479d7fb4e05ef6622bb3e534       0   \n",
              "2730    qemu  a8170e5e97ad17ca169c64ba87ae2f53850dab4c       0   \n",
              "2731  FFmpeg  7104c23bd1a1dcb8a7d9e2c8838c7ce55c30a331       0   \n",
              "\n",
              "                                                   func    idx  \n",
              "0     int ff_get_wav_header(AVFormatContext *s, AVIO...      3  \n",
              "1     static int xen_9pfs_connect(struct XenDevice *...     12  \n",
              "2     static int subframe_count_exact(FlacEncodeCont...     35  \n",
              "3     static void ppc_spapr_init(QEMUMachineInitArgs...     43  \n",
              "4     static int mpeg1_decode_sequence(AVCodecContex...     60  \n",
              "...                                                 ...    ...  \n",
              "2727  static void *mpc8544_load_device_tree(target_p...  27266  \n",
              "2728  static int mov_read_trak(MOVContext *c, ByteIO...  27272  \n",
              "2729  static av_cold int libschroedinger_encode_init...  27296  \n",
              "2730  static struct omap_mcbsp_s *omap_mcbsp_init(Me...  27311  \n",
              "2731  static void rv34_pred_mv(RV34DecContext *r, in...  27317  \n",
              "\n",
              "[2732 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d538294-bcc3-40b1-9f7f-9a6f0ee4b949\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project</th>\n",
              "      <th>commit_id</th>\n",
              "      <th>target</th>\n",
              "      <th>func</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>32bf6550cb9cc9f487a6722fe2bfc272a93c1065</td>\n",
              "      <td>0</td>\n",
              "      <td>int ff_get_wav_header(AVFormatContext *s, AVIO...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qemu</td>\n",
              "      <td>c0c24b95542bc1a4dc3fc6ea71475ae04fa69189</td>\n",
              "      <td>1</td>\n",
              "      <td>static int xen_9pfs_connect(struct XenDevice *...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>5ff998a233d759d0de83ea6f95c383d03d25d88e</td>\n",
              "      <td>1</td>\n",
              "      <td>static int subframe_count_exact(FlacEncodeCont...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>qemu</td>\n",
              "      <td>24408a7d2b459bed3697367b81ada76518ca96ef</td>\n",
              "      <td>0</td>\n",
              "      <td>static void ppc_spapr_init(QEMUMachineInitArgs...</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>68f593b48433842f3407586679fe07f3e5199ab9</td>\n",
              "      <td>0</td>\n",
              "      <td>static int mpeg1_decode_sequence(AVCodecContex...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>qemu</td>\n",
              "      <td>04088adbe0c5adca66adb6022723362ad90ed0fc</td>\n",
              "      <td>0</td>\n",
              "      <td>static void *mpc8544_load_device_tree(target_p...</td>\n",
              "      <td>27266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2728</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>3a25c707fae3c6e99fdda40474c3d74be24cc4c3</td>\n",
              "      <td>0</td>\n",
              "      <td>static int mov_read_trak(MOVContext *c, ByteIO...</td>\n",
              "      <td>27272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2729</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>d6604b29ef544793479d7fb4e05ef6622bb3e534</td>\n",
              "      <td>0</td>\n",
              "      <td>static av_cold int libschroedinger_encode_init...</td>\n",
              "      <td>27296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2730</th>\n",
              "      <td>qemu</td>\n",
              "      <td>a8170e5e97ad17ca169c64ba87ae2f53850dab4c</td>\n",
              "      <td>0</td>\n",
              "      <td>static struct omap_mcbsp_s *omap_mcbsp_init(Me...</td>\n",
              "      <td>27311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2731</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>7104c23bd1a1dcb8a7d9e2c8838c7ce55c30a331</td>\n",
              "      <td>0</td>\n",
              "      <td>static void rv34_pred_mv(RV34DecContext *r, in...</td>\n",
              "      <td>27317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2732 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d538294-bcc3-40b1-9f7f-9a6f0ee4b949')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d538294-bcc3-40b1-9f7f-9a6f0ee4b949 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d538294-bcc3-40b1-9f7f-9a6f0ee4b949');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df = pd.read_json('/content/drive/MyDrive/devign-CodeVul/dataset/valid.jsonl', lines=True)\n",
        "valid_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "Bd8M0Pr3VDm5",
        "outputId": "da62bf66-bb80-4abb-ad01-6ad2c2ee0488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     project                                 commit_id  target  \\\n",
              "0       qemu  aa1530dec499f7525d2ccaa0e3a876dc8089ed1e       1   \n",
              "1       qemu  21ce148c7ec71ee32834061355a5ecfd1a11f90f       1   \n",
              "2       qemu  089da572b956ef0f8f5b8d5917358e07892a77c2       1   \n",
              "3       qemu  98f343395e937fa1db3a28dfb4f303f97cfddd6c       1   \n",
              "4       qemu  c39ce112b60ffafbaf700853e32bea74cbb2c148       0   \n",
              "...      ...                                       ...     ...   \n",
              "2727    qemu  2637c754ccdb286890ed2a8d0d1da775dbd062af       0   \n",
              "2728    qemu  9012a53f067a78022947e18050b145c34a3dc599       0   \n",
              "2729    qemu  ad196a9d0c14f681f010bb4b979030ec125ba976       0   \n",
              "2730    qemu  a6152b52bc50c5cf1cd118a74b483dd3f0748ebd       0   \n",
              "2731    qemu  196a778428989217b82de042725dc8eb29c8f8d8       1   \n",
              "\n",
              "                                                   func    idx  \n",
              "0     static void filter_mirror_setup(NetFilterState...      8  \n",
              "1     static inline int64_t sub64(const int64_t a, c...     10  \n",
              "2     void fw_cfg_add_callback(FWCfgState *s, uint16...     15  \n",
              "3     static void emulated_push_error(EmulatedState ...     22  \n",
              "4     static void do_busid_cmd(ESPState *s, uint8_t ...     51  \n",
              "...                                                 ...    ...  \n",
              "2727  void cpu_dump_state(CPUState *env, FILE *f,\\n\\...  27264  \n",
              "2728  static void rtas_start_cpu(PowerPCCPU *cpu_, s...  27269  \n",
              "2729  void net_slirp_redir(Monitor *mon, const char ...  27275  \n",
              "2730  int ppc_hash64_handle_mmu_fault(PowerPCCPU *cp...  27276  \n",
              "2731  static void qxl_reset_surfaces(PCIQXLDevice *d...  27290  \n",
              "\n",
              "[2732 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8d6f184-7b6a-4dfa-8bc0-2c7c1a984ff4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project</th>\n",
              "      <th>commit_id</th>\n",
              "      <th>target</th>\n",
              "      <th>func</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qemu</td>\n",
              "      <td>aa1530dec499f7525d2ccaa0e3a876dc8089ed1e</td>\n",
              "      <td>1</td>\n",
              "      <td>static void filter_mirror_setup(NetFilterState...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qemu</td>\n",
              "      <td>21ce148c7ec71ee32834061355a5ecfd1a11f90f</td>\n",
              "      <td>1</td>\n",
              "      <td>static inline int64_t sub64(const int64_t a, c...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>qemu</td>\n",
              "      <td>089da572b956ef0f8f5b8d5917358e07892a77c2</td>\n",
              "      <td>1</td>\n",
              "      <td>void fw_cfg_add_callback(FWCfgState *s, uint16...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>qemu</td>\n",
              "      <td>98f343395e937fa1db3a28dfb4f303f97cfddd6c</td>\n",
              "      <td>1</td>\n",
              "      <td>static void emulated_push_error(EmulatedState ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>qemu</td>\n",
              "      <td>c39ce112b60ffafbaf700853e32bea74cbb2c148</td>\n",
              "      <td>0</td>\n",
              "      <td>static void do_busid_cmd(ESPState *s, uint8_t ...</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>qemu</td>\n",
              "      <td>2637c754ccdb286890ed2a8d0d1da775dbd062af</td>\n",
              "      <td>0</td>\n",
              "      <td>void cpu_dump_state(CPUState *env, FILE *f,\\n\\...</td>\n",
              "      <td>27264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2728</th>\n",
              "      <td>qemu</td>\n",
              "      <td>9012a53f067a78022947e18050b145c34a3dc599</td>\n",
              "      <td>0</td>\n",
              "      <td>static void rtas_start_cpu(PowerPCCPU *cpu_, s...</td>\n",
              "      <td>27269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2729</th>\n",
              "      <td>qemu</td>\n",
              "      <td>ad196a9d0c14f681f010bb4b979030ec125ba976</td>\n",
              "      <td>0</td>\n",
              "      <td>void net_slirp_redir(Monitor *mon, const char ...</td>\n",
              "      <td>27275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2730</th>\n",
              "      <td>qemu</td>\n",
              "      <td>a6152b52bc50c5cf1cd118a74b483dd3f0748ebd</td>\n",
              "      <td>0</td>\n",
              "      <td>int ppc_hash64_handle_mmu_fault(PowerPCCPU *cp...</td>\n",
              "      <td>27276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2731</th>\n",
              "      <td>qemu</td>\n",
              "      <td>196a778428989217b82de042725dc8eb29c8f8d8</td>\n",
              "      <td>1</td>\n",
              "      <td>static void qxl_reset_surfaces(PCIQXLDevice *d...</td>\n",
              "      <td>27290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2732 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8d6f184-7b6a-4dfa-8bc0-2c7c1a984ff4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8d6f184-7b6a-4dfa-8bc0-2c7c1a984ff4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8d6f184-7b6a-4dfa-8bc0-2c7c1a984ff4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/devign-CodeVul/evaluator/evaluator.py -a /content/drive/MyDrive/devign-CodeVul/evaluator/tests.jsonl -p /content/drive/MyDrive/devign-CodeVul/evaluator/predictions.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-bQCH9HBci5",
        "outputId": "0b87faf1-55ce-4f77-fc74-f9aab517e673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devign-CodeVul/evaluator/tests.jsonl\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 1}\n",
            "/content/drive/MyDrive/devign-CodeVul/evaluator/predictions.txt\n",
            "prediction: {0: 0, 1: 1, 2: 1, 3: 0, 4: 0}\n",
            "{'Acc': 0.6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/devign-CodeVul/code\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW2e6p41Cs6W",
        "outputId": "2aa57227-91a1-4677-d2c8-bf1518180190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devign-CodeVul/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibugvXRMExk7",
        "outputId": "36111f74-9fe9-4984-c6a1-0a5d60dbf0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl\n",
        "!pip -q install pytorch-lightning==1.2.7 transformers torchmetrics awscli mlflow boto3 pycm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2irSouVRFkqk",
        "outputId": "65a53589-73e2-4944-e76a-64859ae6259e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: torch_xla-1.8-cp37-cp37m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m830.7/830.7 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 KB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m595.7/595.7 KB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m447.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "o7FNEzuwF6Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip list | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y2mTqnYGljX",
        "outputId": "82f16f01-5738-4409-ba09-c0fed720dbd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                         1.13.1+cu116\n",
            "torchaudio                    0.13.1+cu116\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.14.1\n",
            "torchvision                   0.14.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pytorch-lightning==1.2.7 transformers torchmetrics awscli mlflow boto3 pycm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4wAUcI2HKM-",
        "outputId": "36abd6f8-b137-4172-9ab2-3b6155d17507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m830.7/830.7 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 KB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m595.7/595.7 KB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "KOawmtOCFGRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CODEBERT RESULTS"
      ],
      "metadata": {
        "id": "0fqBZwbQOGnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!python run.py \\\n",
        "    --output_dir=./saved_models \\\n",
        "    --model_type=roberta \\\n",
        "    --tokenizer_name=microsoft/codebert-base \\\n",
        "    --model_name_or_path=microsoft/codebert-base \\\n",
        "    --do_train \\\n",
        "    --train_data_file=../dataset/train.jsonl \\\n",
        "    --eval_data_file=../dataset/valid.jsonl \\\n",
        "    --test_data_file=../dataset/test.jsonl \\\n",
        "    --epoch 5 \\\n",
        "    --block_size 400 \\\n",
        "    --train_batch_size 16 \\\n",
        "    --eval_batch_size 32 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --max_grad_norm 1.0 \\\n",
        "    --evaluate_during_training \\\n",
        "    --seed 123456  2>&1 | tee train.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlma81WbExdi",
        "outputId": "5c9326f9-b2b2-4f97-af06-1b130607d2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.8/dist-packages (0.15.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.3.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate) (4.4.0)\n",
            "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "epoch 0 loss 0.67966: 100%|██████████| 1366/1366 [28:38<00:00,  1.26s/it]\n",
            "epoch 1 loss 0.62217: 100%|██████████| 1366/1366 [28:43<00:00,  1.26s/it]\n",
            "epoch 2 loss 0.54651: 100%|██████████| 1366/1366 [28:43<00:00,  1.26s/it]\n",
            "epoch 3 loss 0.47434: 100%|██████████| 1366/1366 [28:41<00:00,  1.26s/it]\n",
            "epoch 4 loss 0.4081: 100%|██████████| 1366/1366 [28:42<00:00,  1.26s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py \\\n",
        "    --output_dir=./saved_models \\\n",
        "    --model_type=roberta \\\n",
        "    --tokenizer_name=microsoft/codebert-base \\\n",
        "    --model_name_or_path=microsoft/codebert-base \\\n",
        "    --do_eval \\\n",
        "    --do_test \\\n",
        "    --train_data_file=../dataset/train.jsonl \\\n",
        "    --eval_data_file=../dataset/valid.jsonl \\\n",
        "    --test_data_file=../dataset/test.jsonl \\\n",
        "    --epoch 5 \\\n",
        "    --block_size 400 \\\n",
        "    --train_batch_size 16 \\\n",
        "    --eval_batch_size 32 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --max_grad_norm 1.0 \\\n",
        "    --evaluate_during_training \\\n",
        "    --seed 123456 2>&1 | tee test.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TMtyPThEYgy",
        "outputId": "26be8650-453b-4d82-fcef-69d7f56415a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 86/86 [01:10<00:00,  1.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/devign-CodeVul/evaluator/evaluator.py -a /content/drive/MyDrive/devign-CodeVul/dataset/test.jsonl -p ./saved_models/predictions.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp0Xe5NJzXOG",
        "outputId": "7f7f25ca-bbd6-4b5d-c850-709a27e522a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devign-CodeVul/dataset/test.jsonl\n",
            "{3: 0, 12: 1, 35: 1, 43: 0, 60: 0, 70: 0, 83: 1, 84: 1, 108: 0, 121: 1, 122: 1, 149: 1, 164: 1, 176: 0, 178: 0, 179: 0, 185: 0, 200: 1, 218: 0, 244: 1, 245: 1, 246: 1, 248: 1, 262: 1, 265: 1, 272: 1, 280: 1, 289: 0, 304: 1, 305: 1, 321: 0, 325: 0, 338: 1, 369: 1, 372: 1, 373: 1, 391: 1, 399: 0, 402: 0, 404: 0, 436: 1, 439: 1, 444: 1, 461: 0, 474: 0, 490: 1, 491: 1, 501: 0, 510: 0, 539: 1, 547: 0, 566: 0, 569: 1, 572: 1, 573: 1, 574: 1, 585: 1, 599: 0, 657: 1, 666: 0, 669: 1, 674: 1, 677: 0, 683: 1, 686: 1, 707: 1, 710: 1, 729: 1, 740: 1, 748: 1, 767: 1, 781: 1, 794: 0, 797: 0, 837: 1, 848: 1, 855: 1, 860: 1, 883: 0, 886: 0, 899: 0, 906: 0, 913: 0, 921: 1, 924: 1, 937: 1, 941: 1, 944: 1, 946: 1, 961: 1, 963: 1, 971: 1, 982: 0, 1035: 1, 1038: 1, 1040: 1, 1046: 1, 1056: 1, 1059: 1, 1060: 0, 1089: 1, 1107: 0, 1108: 0, 1119: 0, 1121: 0, 1122: 0, 1130: 1, 1136: 1, 1137: 1, 1145: 0, 1167: 0, 1194: 0, 1215: 0, 1227: 0, 1277: 1, 1290: 0, 1307: 1, 1308: 1, 1318: 1, 1335: 1, 1338: 1, 1341: 1, 1351: 0, 1360: 0, 1373: 1, 1377: 1, 1381: 1, 1404: 1, 1420: 1, 1426: 0, 1434: 1, 1435: 1, 1439: 1, 1457: 1, 1469: 1, 1473: 1, 1476: 1, 1487: 0, 1497: 0, 1500: 0, 1507: 1, 1508: 1, 1519: 1, 1525: 0, 1533: 1, 1540: 0, 1557: 0, 1573: 0, 1616: 0, 1621: 0, 1626: 0, 1628: 0, 1657: 0, 1672: 1, 1710: 0, 1712: 0, 1713: 0, 1721: 1, 1726: 1, 1736: 1, 1760: 0, 1770: 0, 1783: 1, 1791: 1, 1802: 1, 1804: 1, 1817: 1, 1822: 1, 1878: 1, 1883: 1, 1894: 0, 1896: 0, 1900: 0, 1902: 0, 1905: 0, 1909: 0, 1917: 0, 1937: 1, 1945: 1, 1946: 0, 1981: 0, 1983: 0, 1990: 0, 1994: 1, 1998: 1, 2009: 1, 2010: 1, 2027: 1, 2047: 0, 2049: 0, 2053: 0, 2063: 0, 2083: 0, 2084: 0, 2093: 0, 2110: 0, 2115: 1, 2124: 1, 2130: 1, 2133: 1, 2142: 1, 2148: 1, 2157: 0, 2182: 0, 2187: 0, 2188: 0, 2190: 0, 2195: 0, 2213: 1, 2229: 1, 2246: 0, 2265: 0, 2280: 0, 2297: 0, 2298: 0, 2300: 0, 2325: 1, 2328: 1, 2329: 1, 2334: 1, 2348: 1, 2349: 1, 2358: 1, 2365: 0, 2395: 1, 2400: 1, 2415: 1, 2424: 1, 2429: 0, 2451: 1, 2466: 0, 2471: 0, 2502: 0, 2523: 0, 2534: 0, 2535: 0, 2538: 0, 2564: 0, 2583: 0, 2594: 0, 2602: 0, 2604: 0, 2620: 1, 2622: 1, 2624: 1, 2628: 0, 2632: 0, 2634: 0, 2649: 1, 2656: 1, 2665: 0, 2673: 1, 2677: 1, 2680: 1, 2704: 1, 2737: 0, 2762: 0, 2793: 0, 2806: 0, 2817: 0, 2818: 0, 2820: 0, 2832: 1, 2846: 1, 2857: 1, 2880: 0, 2884: 0, 2895: 0, 2903: 0, 2911: 0, 2913: 0, 2914: 0, 2929: 0, 2946: 1, 2950: 1, 2958: 1, 2967: 1, 2996: 0, 3001: 1, 3003: 1, 3020: 0, 3040: 0, 3054: 0, 3065: 0, 3070: 1, 3076: 1, 3082: 1, 3098: 1, 3117: 0, 3130: 1, 3153: 0, 3158: 1, 3160: 1, 3161: 1, 3162: 1, 3176: 1, 3179: 1, 3180: 1, 3182: 1, 3183: 0, 3184: 1, 3205: 1, 3211: 0, 3227: 1, 3228: 1, 3236: 1, 3237: 1, 3256: 0, 3266: 0, 3274: 0, 3278: 1, 3279: 1, 3288: 1, 3290: 0, 3293: 1, 3320: 1, 3322: 1, 3327: 1, 3330: 0, 3333: 0, 3348: 0, 3375: 1, 3392: 1, 3394: 1, 3397: 1, 3398: 1, 3399: 1, 3401: 1, 3416: 0, 3440: 0, 3449: 0, 3452: 0, 3456: 1, 3460: 1, 3476: 1, 3484: 1, 3499: 1, 3502: 1, 3513: 0, 3517: 0, 3521: 0, 3540: 1, 3551: 1, 3555: 1, 3561: 1, 3582: 1, 3596: 1, 3598: 1, 3602: 1, 3610: 1, 3611: 1, 3621: 1, 3634: 1, 3658: 0, 3681: 1, 3691: 1, 3714: 1, 3721: 1, 3722: 1, 3731: 1, 3743: 0, 3748: 0, 3755: 0, 3763: 0, 3766: 0, 3770: 0, 3778: 0, 3795: 0, 3811: 0, 3815: 0, 3824: 1, 3832: 0, 3834: 0, 3838: 0, 3845: 0, 3901: 0, 3913: 1, 3920: 0, 3924: 0, 3926: 0, 3933: 0, 3946: 0, 3956: 1, 3960: 1, 3970: 1, 3971: 0, 3977: 1, 3984: 1, 3988: 1, 4006: 1, 4009: 1, 4017: 1, 4025: 0, 4029: 1, 4041: 1, 4062: 1, 4064: 1, 4070: 1, 4080: 1, 4091: 1, 4093: 1, 4095: 1, 4104: 0, 4141: 1, 4159: 1, 4165: 1, 4166: 1, 4173: 0, 4178: 0, 4196: 0, 4198: 0, 4209: 0, 4211: 0, 4213: 0, 4217: 0, 4218: 0, 4221: 0, 4253: 1, 4255: 1, 4256: 1, 4260: 0, 4306: 0, 4307: 0, 4315: 0, 4337: 0, 4341: 0, 4344: 0, 4360: 1, 4362: 1, 4385: 1, 4389: 0, 4411: 0, 4440: 0, 4479: 0, 4488: 0, 4519: 1, 4521: 1, 4524: 0, 4539: 1, 4540: 0, 4551: 0, 4555: 0, 4556: 0, 4563: 0, 4569: 0, 4570: 0, 4571: 0, 4607: 0, 4609: 0, 4610: 0, 4611: 0, 4615: 0, 4639: 1, 4645: 1, 4668: 1, 4681: 0, 4685: 0, 4697: 1, 4698: 0, 4718: 0, 4760: 1, 4761: 1, 4762: 0, 4766: 1, 4768: 1, 4769: 1, 4770: 1, 4781: 1, 4798: 1, 4800: 0, 4801: 1, 4815: 1, 4835: 0, 4842: 0, 4849: 0, 4873: 0, 4874: 1, 4879: 0, 4892: 0, 4893: 0, 4896: 0, 4899: 0, 4924: 0, 4961: 0, 4995: 1, 5035: 0, 5044: 0, 5054: 0, 5060: 1, 5071: 1, 5093: 0, 5099: 0, 5102: 0, 5104: 0, 5121: 1, 5129: 1, 5138: 1, 5146: 1, 5171: 1, 5172: 1, 5174: 1, 5190: 1, 5191: 1, 5198: 0, 5201: 0, 5219: 0, 5222: 0, 5229: 0, 5250: 0, 5263: 1, 5277: 1, 5281: 0, 5283: 0, 5298: 0, 5304: 0, 5306: 0, 5308: 1, 5314: 1, 5327: 1, 5353: 0, 5356: 0, 5357: 0, 5361: 1, 5381: 0, 5386: 0, 5408: 1, 5416: 0, 5429: 1, 5430: 1, 5437: 1, 5452: 1, 5457: 0, 5482: 0, 5490: 1, 5500: 1, 5508: 1, 5509: 1, 5539: 0, 5567: 0, 5581: 0, 5582: 0, 5587: 0, 5607: 1, 5617: 0, 5621: 1, 5624: 1, 5630: 1, 5646: 0, 5670: 0, 5672: 0, 5673: 0, 5676: 0, 5694: 0, 5707: 0, 5718: 1, 5731: 1, 5754: 1, 5755: 1, 5762: 0, 5767: 1, 5781: 1, 5789: 1, 5797: 1, 5810: 0, 5820: 0, 5826: 0, 5834: 1, 5837: 1, 5845: 1, 5846: 1, 5855: 1, 5864: 1, 5875: 0, 5899: 0, 5905: 1, 5908: 1, 5920: 1, 5931: 1, 5962: 1, 5963: 1, 5965: 1, 5981: 1, 6007: 0, 6008: 0, 6025: 1, 6032: 0, 6033: 0, 6043: 0, 6063: 0, 6069: 0, 6092: 0, 6098: 0, 6103: 1, 6108: 1, 6112: 1, 6125: 1, 6140: 0, 6160: 1, 6165: 1, 6186: 0, 6189: 0, 6193: 0, 6196: 0, 6206: 1, 6217: 1, 6241: 0, 6243: 0, 6251: 0, 6272: 1, 6277: 0, 6293: 0, 6307: 1, 6335: 1, 6346: 1, 6374: 1, 6385: 1, 6408: 0, 6432: 1, 6452: 0, 6455: 1, 6486: 1, 6489: 1, 6500: 1, 6507: 1, 6509: 1, 6519: 1, 6524: 0, 6532: 0, 6535: 0, 6543: 1, 6545: 1, 6547: 1, 6556: 1, 6575: 1, 6577: 1, 6580: 0, 6594: 0, 6605: 0, 6622: 0, 6628: 1, 6635: 1, 6641: 1, 6646: 1, 6650: 1, 6670: 1, 6674: 1, 6685: 1, 6699: 1, 6708: 0, 6727: 1, 6753: 0, 6763: 1, 6775: 1, 6778: 1, 6801: 0, 6816: 1, 6829: 0, 6838: 0, 6844: 0, 6852: 0, 6867: 0, 6879: 0, 6891: 1, 6919: 0, 6927: 0, 6935: 0, 6946: 1, 6951: 1, 6953: 1, 6956: 1, 6972: 1, 6997: 0, 6999: 1, 7004: 1, 7017: 0, 7019: 0, 7027: 0, 7033: 0, 7048: 1, 7066: 0, 7069: 0, 7099: 0, 7105: 0, 7109: 0, 7111: 0, 7119: 0, 7122: 0, 7125: 1, 7130: 1, 7150: 1, 7168: 1, 7174: 1, 7177: 0, 7191: 1, 7204: 1, 7213: 0, 7222: 0, 7243: 1, 7267: 1, 7269: 1, 7315: 0, 7324: 0, 7326: 0, 7327: 0, 7332: 0, 7334: 0, 7347: 1, 7351: 1, 7360: 0, 7380: 0, 7393: 1, 7398: 1, 7420: 0, 7428: 0, 7430: 0, 7448: 0, 7449: 0, 7458: 0, 7462: 0, 7471: 0, 7472: 0, 7480: 0, 7481: 0, 7490: 0, 7491: 0, 7498: 0, 7521: 1, 7556: 0, 7558: 0, 7579: 0, 7590: 1, 7596: 1, 7598: 0, 7609: 0, 7622: 1, 7649: 0, 7651: 0, 7654: 1, 7659: 0, 7662: 1, 7666: 1, 7670: 1, 7696: 1, 7716: 0, 7729: 0, 7732: 1, 7749: 0, 7754: 0, 7761: 0, 7762: 0, 7766: 0, 7777: 0, 7779: 0, 7780: 0, 7782: 0, 7808: 0, 7814: 0, 7828: 0, 7834: 0, 7852: 0, 7854: 0, 7866: 0, 7869: 0, 7873: 0, 7874: 0, 7881: 1, 7882: 1, 7885: 1, 7892: 1, 7893: 1, 7916: 1, 7925: 0, 7936: 0, 7967: 0, 7972: 0, 7977: 0, 7980: 0, 7982: 1, 7992: 0, 8010: 0, 8018: 0, 8021: 1, 8046: 0, 8049: 0, 8071: 0, 8085: 0, 8103: 1, 8105: 1, 8111: 1, 8112: 0, 8124: 1, 8130: 1, 8134: 0, 8145: 0, 8154: 1, 8155: 1, 8157: 1, 8158: 1, 8169: 1, 8171: 1, 8181: 0, 8197: 0, 8199: 0, 8208: 1, 8209: 1, 8211: 0, 8217: 1, 8221: 1, 8241: 0, 8247: 0, 8254: 0, 8271: 0, 8273: 0, 8291: 0, 8296: 0, 8313: 0, 8340: 0, 8357: 1, 8370: 0, 8380: 0, 8409: 0, 8412: 1, 8425: 0, 8431: 1, 8435: 1, 8447: 1, 8457: 1, 8466: 1, 8482: 0, 8487: 0, 8518: 1, 8522: 1, 8526: 1, 8534: 0, 8543: 1, 8565: 0, 8568: 0, 8577: 1, 8592: 1, 8617: 0, 8673: 0, 8707: 1, 8720: 1, 8755: 0, 8793: 1, 8794: 1, 8815: 1, 8825: 0, 8835: 0, 8846: 0, 8855: 0, 8858: 0, 8866: 0, 8878: 0, 8900: 1, 8901: 1, 8903: 1, 8927: 0, 8931: 0, 8946: 0, 8949: 0, 8955: 0, 8963: 0, 8970: 0, 8988: 0, 9025: 1, 9036: 0, 9038: 0, 9039: 0, 9047: 0, 9049: 0, 9055: 0, 9067: 0, 9072: 0, 9087: 1, 9091: 1, 9094: 0, 9095: 1, 9101: 1, 9106: 1, 9109: 1, 9122: 1, 9134: 0, 9150: 1, 9162: 1, 9172: 1, 9174: 1, 9176: 1, 9178: 1, 9189: 1, 9193: 1, 9210: 0, 9215: 0, 9225: 0, 9231: 1, 9238: 0, 9246: 0, 9255: 0, 9258: 0, 9260: 0, 9282: 0, 9283: 1, 9301: 1, 9330: 1, 9343: 0, 9347: 1, 9349: 1, 9351: 1, 9352: 1, 9366: 1, 9399: 1, 9418: 1, 9434: 1, 9435: 1, 9437: 1, 9443: 1, 9445: 1, 9457: 1, 9482: 0, 9508: 1, 9509: 1, 9510: 1, 9516: 1, 9528: 1, 9533: 0, 9546: 0, 9548: 0, 9574: 0, 9576: 0, 9584: 0, 9598: 1, 9607: 1, 9616: 1, 9619: 0, 9629: 0, 9630: 0, 9639: 0, 9643: 0, 9647: 0, 9650: 1, 9651: 1, 9670: 0, 9683: 0, 9706: 0, 9707: 0, 9709: 0, 9721: 1, 9722: 1, 9727: 0, 9744: 0, 9754: 0, 9761: 1, 9772: 1, 9781: 1, 9787: 1, 9789: 1, 9805: 0, 9817: 0, 9842: 1, 9845: 1, 9846: 1, 9864: 0, 9870: 0, 9896: 0, 9913: 1, 9922: 1, 9929: 1, 9934: 1, 9943: 0, 9956: 0, 9961: 0, 9977: 0, 10000: 0, 10026: 0, 10049: 0, 10055: 0, 10064: 0, 10081: 0, 10104: 1, 10128: 0, 10161: 0, 10175: 0, 10180: 1, 10190: 0, 10192: 0, 10194: 0, 10213: 0, 10233: 0, 10244: 0, 10253: 0, 10266: 0, 10268: 0, 10269: 0, 10278: 0, 10282: 0, 10291: 0, 10295: 0, 10308: 0, 10316: 0, 10322: 0, 10327: 0, 10333: 0, 10338: 0, 10351: 1, 10355: 1, 10364: 0, 10370: 0, 10374: 0, 10385: 0, 10406: 1, 10410: 0, 10414: 1, 10416: 1, 10429: 0, 10449: 0, 10478: 0, 10480: 0, 10485: 0, 10498: 0, 10502: 1, 10504: 1, 10513: 0, 10520: 1, 10539: 0, 10547: 0, 10554: 0, 10556: 0, 10564: 0, 10583: 0, 10594: 1, 10609: 1, 10620: 0, 10640: 1, 10648: 1, 10665: 1, 10670: 1, 10671: 1, 10672: 1, 10699: 1, 10721: 0, 10723: 1, 10727: 1, 10730: 1, 10735: 1, 10738: 0, 10741: 1, 10744: 1, 10750: 0, 10765: 0, 10767: 0, 10772: 1, 10773: 1, 10801: 1, 10836: 1, 10842: 1, 10847: 1, 10849: 1, 10857: 1, 10868: 1, 10869: 1, 10875: 0, 10877: 0, 10899: 0, 10914: 1, 10950: 0, 10962: 1, 10971: 1, 10974: 1, 10982: 0, 10984: 0, 10992: 0, 10999: 0, 11016: 0, 11026: 0, 11046: 1, 11070: 1, 11080: 0, 11084: 0, 11113: 1, 11117: 1, 11126: 0, 11127: 0, 11128: 0, 11140: 0, 11141: 0, 11142: 0, 11143: 0, 11167: 0, 11193: 1, 11202: 1, 11235: 1, 11268: 0, 11303: 0, 11316: 0, 11328: 1, 11334: 1, 11359: 1, 11361: 1, 11368: 1, 11381: 1, 11383: 1, 11400: 0, 11423: 0, 11427: 0, 11428: 0, 11433: 1, 11439: 1, 11444: 0, 11449: 1, 11455: 1, 11468: 0, 11488: 1, 11501: 1, 11516: 1, 11524: 1, 11527: 0, 11529: 0, 11535: 0, 11543: 1, 11546: 1, 11553: 0, 11566: 1, 11592: 0, 11608: 0, 11624: 0, 11631: 0, 11635: 0, 11641: 0, 11642: 0, 11646: 1, 11662: 0, 11665: 0, 11674: 0, 11685: 0, 11712: 1, 11714: 1, 11742: 1, 11748: 1, 11749: 1, 11781: 0, 11793: 0, 11795: 0, 11806: 1, 11810: 1, 11813: 1, 11833: 0, 11834: 0, 11840: 0, 11843: 0, 11844: 0, 11852: 0, 11853: 0, 11854: 0, 11861: 1, 11865: 1, 11877: 1, 11885: 1, 11911: 0, 11919: 0, 11933: 1, 11936: 1, 11957: 0, 11958: 0, 11969: 0, 11975: 0, 11978: 1, 11979: 1, 11980: 1, 11983: 0, 11985: 1, 11988: 1, 11998: 1, 12023: 0, 12026: 0, 12036: 0, 12038: 0, 12075: 1, 12079: 1, 12083: 1, 12086: 1, 12095: 1, 12099: 0, 12106: 0, 12111: 0, 12130: 0, 12133: 0, 12134: 0, 12142: 0, 12145: 0, 12182: 1, 12190: 0, 12192: 0, 12200: 1, 12205: 1, 12215: 1, 12216: 1, 12243: 1, 12245: 1, 12255: 1, 12257: 1, 12273: 1, 12278: 1, 12281: 1, 12305: 0, 12307: 0, 12314: 0, 12320: 0, 12326: 0, 12329: 0, 12347: 1, 12353: 0, 12357: 0, 12362: 0, 12365: 0, 12367: 0, 12376: 0, 12377: 0, 12378: 0, 12383: 0, 12384: 0, 12395: 0, 12402: 0, 12409: 1, 12412: 0, 12429: 1, 12434: 0, 12451: 0, 12452: 0, 12470: 0, 12477: 0, 12493: 1, 12499: 1, 12544: 0, 12545: 0, 12548: 1, 12556: 0, 12558: 1, 12585: 1, 12596: 1, 12607: 1, 12616: 0, 12624: 0, 12635: 0, 12642: 0, 12645: 0, 12663: 0, 12667: 0, 12668: 0, 12672: 0, 12686: 0, 12701: 0, 12704: 0, 12710: 0, 12724: 0, 12730: 0, 12741: 0, 12777: 0, 12780: 1, 12785: 1, 12786: 1, 12787: 1, 12789: 1, 12799: 1, 12805: 1, 12809: 1, 12810: 1, 12814: 1, 12828: 1, 12846: 0, 12853: 0, 12887: 0, 12894: 0, 12916: 1, 12927: 0, 12940: 1, 12946: 1, 12949: 1, 12951: 1, 12968: 1, 12984: 1, 13001: 0, 13002: 0, 13012: 0, 13024: 1, 13031: 1, 13035: 1, 13040: 1, 13050: 0, 13051: 0, 13068: 1, 13077: 1, 13081: 0, 13097: 1, 13100: 1, 13114: 1, 13118: 1, 13130: 1, 13136: 1, 13137: 0, 13140: 1, 13149: 0, 13154: 0, 13155: 0, 13156: 0, 13163: 0, 13172: 0, 13204: 1, 13205: 1, 13230: 1, 13236: 1, 13268: 1, 13273: 1, 13311: 1, 13316: 1, 13339: 0, 13347: 1, 13357: 0, 13363: 0, 13365: 0, 13366: 0, 13388: 0, 13415: 0, 13426: 0, 13429: 1, 13437: 1, 13442: 0, 13448: 1, 13462: 0, 13468: 1, 13488: 0, 13494: 0, 13504: 0, 13513: 0, 13517: 0, 13524: 0, 13548: 1, 13554: 1, 13555: 0, 13556: 1, 13571: 0, 13589: 0, 13604: 1, 13635: 1, 13636: 1, 13667: 1, 13672: 1, 13706: 1, 13712: 0, 13726: 1, 13728: 1, 13734: 1, 13736: 1, 13739: 1, 13740: 1, 13748: 1, 13754: 0, 13768: 0, 13772: 0, 13784: 1, 13809: 0, 13829: 0, 13855: 0, 13859: 1, 13867: 0, 13888: 1, 13890: 1, 13897: 1, 13899: 1, 13905: 1, 13906: 1, 13915: 1, 13943: 0, 13951: 0, 13969: 1, 13988: 1, 14014: 1, 14022: 1, 14023: 1, 14024: 1, 14025: 1, 14031: 1, 14056: 1, 14076: 0, 14090: 0, 14108: 0, 14126: 0, 14141: 1, 14144: 1, 14162: 1, 14168: 0, 14199: 1, 14220: 0, 14228: 0, 14248: 1, 14263: 0, 14289: 0, 14300: 1, 14306: 0, 14308: 1, 14309: 1, 14324: 1, 14350: 1, 14356: 1, 14359: 1, 14362: 1, 14366: 1, 14372: 1, 14376: 1, 14379: 1, 14387: 0, 14388: 0, 14393: 0, 14413: 0, 14442: 0, 14459: 1, 14469: 1, 14476: 0, 14499: 0, 14508: 0, 14521: 1, 14531: 0, 14557: 0, 14566: 0, 14588: 0, 14589: 0, 14591: 0, 14599: 1, 14612: 1, 14639: 1, 14654: 0, 14658: 1, 14665: 1, 14673: 0, 14679: 1, 14680: 1, 14694: 1, 14716: 0, 14723: 0, 14741: 1, 14745: 1, 14750: 1, 14774: 1, 14775: 1, 14777: 1, 14813: 0, 14814: 1, 14816: 1, 14822: 1, 14823: 1, 14840: 0, 14842: 0, 14846: 0, 14848: 0, 14865: 0, 14872: 0, 14884: 0, 14904: 0, 14911: 0, 14913: 0, 14936: 0, 14942: 1, 14951: 0, 14982: 0, 15001: 1, 15002: 1, 15016: 0, 15051: 0, 15055: 0, 15061: 0, 15066: 0, 15067: 0, 15077: 0, 15082: 0, 15094: 1, 15106: 0, 15108: 0, 15115: 1, 15124: 1, 15125: 1, 15132: 1, 15133: 1, 15136: 1, 15147: 1, 15173: 0, 15201: 1, 15206: 1, 15209: 1, 15239: 1, 15249: 0, 15252: 0, 15260: 1, 15288: 1, 15290: 1, 15301: 1, 15321: 0, 15341: 0, 15368: 1, 15373: 1, 15388: 1, 15389: 1, 15401: 0, 15411: 0, 15420: 0, 15434: 0, 15449: 0, 15457: 0, 15482: 0, 15486: 0, 15492: 0, 15495: 0, 15515: 1, 15517: 1, 15520: 0, 15521: 0, 15524: 0, 15530: 0, 15534: 0, 15535: 0, 15537: 0, 15549: 0, 15552: 0, 15555: 0, 15582: 1, 15589: 1, 15594: 1, 15615: 0, 15634: 0, 15644: 0, 15653: 0, 15654: 0, 15655: 0, 15664: 1, 15679: 0, 15690: 1, 15696: 0, 15723: 0, 15728: 0, 15775: 0, 15779: 0, 15788: 0, 15791: 0, 15804: 0, 15811: 0, 15818: 0, 15823: 0, 15833: 0, 15840: 0, 15846: 1, 15879: 0, 15883: 0, 15885: 0, 15890: 0, 15897: 0, 15906: 0, 15911: 0, 15924: 0, 15929: 0, 15943: 0, 15962: 0, 15965: 0, 15977: 0, 15980: 0, 15985: 0, 15987: 1, 15999: 1, 16020: 0, 16047: 1, 16057: 1, 16068: 0, 16083: 0, 16089: 0, 16090: 0, 16093: 1, 16112: 1, 16135: 1, 16147: 0, 16155: 0, 16163: 0, 16164: 0, 16177: 1, 16183: 0, 16190: 1, 16197: 1, 16203: 1, 16204: 1, 16205: 1, 16207: 1, 16211: 1, 16216: 1, 16227: 0, 16237: 0, 16246: 0, 16255: 0, 16256: 0, 16274: 0, 16276: 0, 16281: 0, 16293: 1, 16318: 0, 16335: 0, 16352: 1, 16360: 1, 16365: 1, 16370: 1, 16385: 1, 16406: 0, 16410: 0, 16412: 0, 16415: 0, 16419: 0, 16422: 0, 16431: 1, 16437: 1, 16449: 1, 16452: 0, 16465: 1, 16483: 0, 16498: 0, 16501: 0, 16507: 0, 16521: 0, 16524: 0, 16536: 0, 16542: 0, 16566: 0, 16585: 0, 16602: 0, 16614: 1, 16628: 0, 16651: 0, 16664: 1, 16666: 1, 16693: 1, 16700: 1, 16708: 1, 16717: 1, 16723: 0, 16724: 0, 16727: 0, 16728: 0, 16735: 0, 16752: 0, 16755: 1, 16767: 1, 16771: 1, 16780: 0, 16783: 0, 16787: 0, 16792: 0, 16794: 0, 16795: 0, 16808: 0, 16812: 0, 16829: 0, 16842: 0, 16862: 0, 16870: 0, 16879: 0, 16888: 0, 16890: 0, 16924: 1, 16930: 1, 16933: 1, 16984: 0, 16986: 0, 16999: 0, 17004: 0, 17009: 0, 17012: 0, 17021: 0, 17030: 0, 17043: 0, 17048: 0, 17072: 0, 17082: 0, 17085: 0, 17092: 0, 17101: 1, 17113: 1, 17118: 0, 17120: 0, 17124: 0, 17128: 0, 17133: 0, 17141: 0, 17152: 0, 17172: 1, 17199: 1, 17203: 0, 17206: 0, 17240: 0, 17242: 0, 17246: 0, 17258: 0, 17266: 0, 17267: 0, 17274: 0, 17280: 1, 17288: 0, 17301: 0, 17307: 0, 17308: 0, 17314: 0, 17325: 0, 17328: 1, 17329: 1, 17337: 1, 17341: 1, 17350: 1, 17353: 1, 17357: 0, 17362: 1, 17370: 1, 17381: 1, 17411: 1, 17412: 1, 17413: 1, 17428: 1, 17439: 0, 17449: 1, 17452: 0, 17480: 1, 17482: 1, 17513: 1, 17518: 1, 17534: 0, 17548: 1, 17553: 1, 17554: 1, 17576: 0, 17581: 0, 17587: 0, 17596: 0, 17597: 0, 17611: 1, 17615: 0, 17627: 0, 17641: 0, 17653: 0, 17664: 0, 17670: 0, 17678: 0, 17682: 0, 17699: 0, 17700: 0, 17710: 0, 17723: 0, 17735: 0, 17737: 1, 17742: 1, 17752: 1, 17765: 1, 17766: 1, 17786: 0, 17787: 0, 17792: 0, 17803: 0, 17805: 1, 17807: 0, 17808: 0, 17833: 1, 17877: 1, 17883: 1, 17885: 1, 17893: 1, 17904: 1, 17908: 1, 17909: 1, 17913: 0, 17929: 1, 17932: 1, 17953: 0, 17954: 0, 17972: 0, 17981: 0, 18015: 0, 18020: 0, 18038: 0, 18044: 0, 18067: 0, 18077: 1, 18095: 0, 18138: 0, 18142: 0, 18150: 0, 18159: 0, 18161: 0, 18171: 0, 18175: 1, 18187: 1, 18194: 1, 18195: 1, 18200: 0, 18202: 1, 18203: 1, 18211: 1, 18220: 0, 18231: 0, 18254: 0, 18267: 0, 18268: 0, 18272: 0, 18279: 0, 18282: 0, 18285: 1, 18304: 0, 18311: 1, 18323: 0, 18324: 0, 18326: 1, 18329: 1, 18344: 0, 18345: 0, 18351: 0, 18371: 0, 18384: 1, 18409: 1, 18412: 1, 18426: 1, 18437: 1, 18438: 1, 18439: 1, 18447: 1, 18457: 1, 18462: 0, 18474: 1, 18477: 1, 18493: 1, 18512: 1, 18513: 1, 18518: 0, 18523: 0, 18529: 0, 18545: 0, 18556: 1, 18559: 1, 18562: 1, 18578: 1, 18583: 0, 18596: 0, 18597: 0, 18598: 0, 18614: 0, 18619: 0, 18620: 0, 18624: 1, 18629: 1, 18640: 1, 18646: 0, 18648: 0, 18649: 0, 18673: 0, 18675: 0, 18696: 1, 18700: 1, 18719: 1, 18724: 0, 18727: 0, 18741: 0, 18744: 0, 18759: 1, 18773: 1, 18781: 0, 18799: 0, 18812: 1, 18819: 1, 18820: 1, 18830: 1, 18833: 1, 18838: 1, 18853: 0, 18892: 0, 18893: 0, 18915: 0, 18931: 0, 18942: 1, 18963: 1, 18969: 1, 18988: 0, 19003: 0, 19005: 1, 19011: 0, 19023: 1, 19027: 1, 19041: 1, 19075: 1, 19082: 1, 19090: 0, 19102: 0, 19108: 0, 19115: 0, 19116: 0, 19119: 0, 19126: 0, 19128: 0, 19129: 0, 19133: 0, 19160: 0, 19184: 0, 19198: 0, 19204: 0, 19216: 1, 19223: 1, 19237: 1, 19238: 1, 19243: 1, 19245: 1, 19253: 0, 19256: 0, 19274: 0, 19290: 0, 19291: 0, 19301: 0, 19307: 0, 19322: 0, 19353: 1, 19373: 0, 19380: 0, 19389: 0, 19403: 1, 19408: 1, 19411: 0, 19431: 1, 19434: 1, 19441: 1, 19469: 0, 19473: 0, 19490: 0, 19492: 0, 19494: 0, 19538: 0, 19554: 1, 19557: 1, 19567: 0, 19574: 0, 19576: 0, 19593: 1, 19595: 1, 19612: 1, 19633: 1, 19643: 1, 19650: 1, 19654: 0, 19665: 1, 19667: 1, 19684: 1, 19685: 1, 19709: 1, 19716: 1, 19721: 0, 19724: 0, 19728: 1, 19759: 0, 19782: 1, 19808: 1, 19809: 1, 19827: 1, 19834: 1, 19886: 0, 19889: 1, 19892: 1, 19908: 1, 19912: 1, 19916: 1, 19927: 0, 19962: 0, 19965: 1, 19966: 1, 19976: 1, 19987: 1, 19998: 0, 19999: 1, 20000: 1, 20005: 0, 20019: 0, 20022: 0, 20026: 1, 20032: 1, 20035: 1, 20054: 0, 20070: 0, 20086: 0, 20095: 0, 20102: 0, 20105: 0, 20109: 1, 20110: 1, 20129: 1, 20131: 1, 20148: 0, 20151: 0, 20158: 0, 20189: 0, 20197: 0, 20199: 0, 20200: 0, 20213: 0, 20233: 0, 20237: 0, 20238: 0, 20248: 0, 20257: 0, 20282: 0, 20283: 0, 20299: 0, 20301: 0, 20305: 1, 20320: 0, 20327: 1, 20328: 1, 20338: 0, 20345: 1, 20352: 0, 20365: 0, 20368: 0, 20370: 0, 20398: 0, 20410: 0, 20422: 1, 20425: 1, 20433: 0, 20434: 0, 20457: 1, 20467: 1, 20471: 1, 20480: 1, 20485: 0, 20495: 0, 20507: 0, 20518: 0, 20520: 0, 20531: 0, 20534: 0, 20541: 0, 20548: 0, 20549: 0, 20553: 0, 20562: 0, 20576: 1, 20581: 0, 20600: 1, 20606: 1, 20613: 1, 20617: 0, 20618: 0, 20620: 0, 20623: 1, 20631: 1, 20643: 1, 20644: 1, 20647: 1, 20659: 1, 20662: 0, 20697: 1, 20698: 1, 20716: 1, 20722: 1, 20728: 0, 20738: 0, 20741: 0, 20743: 0, 20751: 0, 20761: 1, 20766: 1, 20797: 0, 20802: 0, 20803: 0, 20811: 0, 20812: 0, 20831: 0, 20835: 1, 20840: 1, 20856: 0, 20902: 0, 20903: 0, 20908: 0, 20917: 1, 20918: 1, 20938: 0, 20945: 0, 20958: 0, 20961: 0, 20970: 0, 20975: 0, 20994: 0, 20996: 0, 21007: 1, 21012: 1, 21030: 1, 21034: 1, 21037: 1, 21050: 1, 21061: 1, 21070: 0, 21092: 0, 21100: 0, 21102: 0, 21106: 0, 21110: 0, 21118: 1, 21135: 1, 21155: 1, 21166: 0, 21168: 0, 21202: 0, 21218: 0, 21219: 0, 21250: 1, 21256: 0, 21261: 0, 21267: 0, 21281: 0, 21284: 1, 21296: 1, 21302: 1, 21306: 0, 21311: 0, 21324: 0, 21335: 1, 21348: 0, 21374: 1, 21383: 1, 21385: 1, 21386: 1, 21387: 1, 21392: 1, 21411: 0, 21413: 0, 21427: 0, 21430: 0, 21435: 0, 21450: 0, 21459: 0, 21466: 1, 21473: 0, 21487: 0, 21492: 0, 21508: 1, 21511: 1, 21513: 0, 21538: 0, 21549: 0, 21567: 1, 21569: 1, 21576: 0, 21583: 1, 21584: 0, 21585: 0, 21612: 0, 21622: 0, 21641: 0, 21665: 0, 21670: 1, 21694: 1, 21708: 1, 21723: 0, 21731: 0, 21739: 0, 21740: 0, 21750: 1, 21762: 1, 21766: 0, 21767: 0, 21776: 1, 21779: 0, 21794: 1, 21796: 1, 21820: 1, 21822: 1, 21828: 0, 21836: 1, 21841: 0, 21851: 0, 21863: 0, 21889: 1, 21899: 1, 21919: 1, 21925: 1, 21938: 0, 21957: 1, 21958: 1, 21962: 1, 21967: 1, 21969: 1, 21971: 1, 21995: 1, 22003: 1, 22006: 1, 22009: 1, 22013: 1, 22016: 1, 22034: 1, 22037: 1, 22047: 1, 22058: 1, 22065: 1, 22082: 0, 22086: 0, 22089: 0, 22093: 0, 22094: 0, 22132: 1, 22137: 0, 22140: 0, 22151: 0, 22155: 0, 22167: 1, 22201: 0, 22250: 1, 22265: 1, 22270: 0, 22276: 0, 22279: 0, 22280: 0, 22300: 1, 22316: 1, 22330: 0, 22361: 1, 22364: 1, 22365: 1, 22369: 1, 22379: 0, 22381: 1, 22387: 1, 22389: 1, 22392: 0, 22399: 0, 22413: 0, 22417: 0, 22418: 0, 22421: 0, 22425: 0, 22426: 1, 22429: 1, 22431: 1, 22436: 0, 22459: 0, 22462: 0, 22465: 0, 22503: 1, 22531: 1, 22534: 1, 22545: 0, 22552: 0, 22559: 0, 22597: 1, 22601: 0, 22615: 1, 22637: 0, 22652: 1, 22655: 1, 22662: 0, 22683: 1, 22693: 1, 22702: 1, 22705: 1, 22709: 1, 22718: 1, 22741: 1, 22752: 0, 22759: 0, 22801: 1, 22815: 1, 22826: 0, 22833: 1, 22834: 1, 22844: 1, 22875: 1, 22876: 1, 22906: 1, 22931: 1, 22944: 1, 22949: 0, 22955: 1, 22956: 1, 22959: 1, 22966: 1, 22969: 1, 22970: 1, 22976: 1, 22980: 1, 22994: 0, 23016: 0, 23049: 0, 23050: 0, 23052: 0, 23066: 0, 23074: 0, 23076: 0, 23088: 0, 23104: 0, 23105: 0, 23108: 0, 23116: 0, 23123: 0, 23136: 0, 23140: 0, 23145: 0, 23155: 0, 23159: 0, 23161: 0, 23163: 0, 23174: 0, 23184: 0, 23186: 1, 23193: 1, 23206: 1, 23213: 1, 23237: 0, 23244: 0, 23245: 0, 23247: 0, 23250: 0, 23256: 1, 23259: 0, 23274: 1, 23277: 1, 23299: 1, 23307: 1, 23309: 1, 23323: 1, 23339: 1, 23344: 0, 23354: 1, 23361: 0, 23371: 0, 23374: 0, 23386: 1, 23393: 0, 23405: 0, 23411: 0, 23425: 0, 23429: 1, 23455: 0, 23465: 0, 23470: 0, 23491: 0, 23495: 0, 23504: 0, 23508: 0, 23516: 0, 23540: 0, 23555: 0, 23560: 0, 23576: 0, 23587: 0, 23622: 0, 23626: 1, 23627: 1, 23636: 1, 23643: 1, 23656: 1, 23668: 0, 23680: 0, 23688: 0, 23692: 0, 23696: 0, 23704: 0, 23714: 0, 23744: 0, 23747: 0, 23751: 0, 23758: 0, 23762: 1, 23769: 1, 23771: 1, 23779: 1, 23786: 1, 23809: 1, 23816: 0, 23854: 0, 23855: 0, 23870: 0, 23872: 0, 23877: 0, 23888: 1, 23895: 1, 23899: 1, 23912: 1, 23916: 1, 23918: 1, 23922: 0, 23924: 0, 23933: 0, 23938: 0, 23942: 1, 23947: 1, 23956: 1, 23965: 1, 24009: 1, 24018: 1, 24044: 0, 24047: 0, 24050: 0, 24072: 0, 24075: 1, 24084: 0, 24085: 0, 24087: 0, 24090: 0, 24100: 0, 24103: 0, 24123: 1, 24141: 1, 24148: 0, 24162: 0, 24164: 0, 24179: 0, 24200: 0, 24201: 0, 24205: 0, 24206: 0, 24212: 0, 24213: 0, 24222: 1, 24230: 1, 24231: 1, 24244: 1, 24269: 0, 24280: 1, 24283: 1, 24289: 0, 24291: 0, 24292: 1, 24294: 1, 24311: 0, 24312: 0, 24315: 0, 24328: 1, 24331: 1, 24351: 1, 24356: 0, 24364: 1, 24368: 0, 24371: 0, 24375: 0, 24400: 1, 24424: 1, 24426: 0, 24433: 0, 24472: 1, 24478: 0, 24483: 1, 24484: 1, 24485: 1, 24486: 1, 24488: 0, 24501: 0, 24508: 0, 24540: 1, 24542: 1, 24555: 0, 24559: 1, 24578: 1, 24588: 0, 24603: 0, 24606: 0, 24621: 1, 24625: 1, 24626: 1, 24629: 0, 24631: 1, 24648: 1, 24655: 1, 24668: 1, 24677: 0, 24720: 0, 24730: 1, 24732: 1, 24742: 0, 24744: 0, 24748: 0, 24754: 0, 24756: 0, 24759: 0, 24761: 0, 24768: 0, 24771: 1, 24787: 0, 24794: 1, 24818: 1, 24824: 1, 24829: 0, 24847: 0, 24853: 0, 24855: 0, 24880: 0, 24881: 0, 24895: 1, 24896: 1, 24897: 1, 24899: 1, 24902: 1, 24921: 1, 24933: 0, 24968: 1, 25005: 0, 25024: 0, 25066: 1, 25075: 1, 25081: 1, 25091: 0, 25095: 0, 25103: 0, 25113: 0, 25119: 0, 25130: 1, 25134: 1, 25135: 1, 25149: 1, 25163: 0, 25167: 0, 25179: 1, 25181: 1, 25182: 1, 25185: 1, 25189: 1, 25223: 0, 25245: 1, 25247: 1, 25252: 1, 25260: 1, 25263: 1, 25265: 0, 25284: 0, 25310: 0, 25344: 0, 25353: 0, 25357: 0, 25370: 0, 25382: 1, 25401: 1, 25404: 1, 25413: 1, 25448: 0, 25459: 1, 25472: 1, 25492: 1, 25501: 1, 25505: 1, 25510: 0, 25515: 0, 25526: 0, 25530: 1, 25549: 0, 25550: 0, 25557: 1, 25566: 1, 25571: 0, 25574: 0, 25578: 0, 25580: 0, 25583: 0, 25593: 0, 25602: 1, 25619: 0, 25636: 0, 25669: 1, 25670: 1, 25672: 1, 25693: 0, 25704: 0, 25711: 0, 25729: 1, 25734: 1, 25737: 1, 25738: 1, 25741: 1, 25748: 1, 25753: 0, 25787: 1, 25810: 0, 25813: 0, 25814: 0, 25828: 1, 25831: 1, 25854: 1, 25859: 1, 25862: 1, 25865: 1, 25868: 1, 25869: 1, 25872: 1, 25925: 0, 25932: 0, 25936: 0, 25937: 0, 25947: 1, 25948: 0, 25958: 0, 25997: 0, 26003: 0, 26008: 0, 26030: 1, 26031: 1, 26038: 1, 26059: 0, 26061: 0, 26069: 0, 26075: 0, 26087: 1, 26090: 1, 26100: 1, 26110: 1, 26113: 0, 26117: 0, 26136: 1, 26152: 0, 26154: 0, 26158: 0, 26160: 0, 26173: 1, 26175: 1, 26183: 1, 26191: 0, 26225: 0, 26226: 0, 26234: 1, 26242: 0, 26243: 0, 26245: 0, 26251: 0, 26257: 0, 26259: 0, 26291: 1, 26294: 1, 26306: 1, 26315: 1, 26320: 1, 26330: 1, 26333: 1, 26360: 0, 26367: 1, 26388: 1, 26390: 0, 26396: 0, 26428: 1, 26435: 1, 26437: 1, 26443: 1, 26451: 0, 26458: 0, 26468: 0, 26472: 1, 26480: 0, 26481: 0, 26485: 0, 26489: 0, 26496: 0, 26512: 1, 26530: 1, 26531: 1, 26535: 0, 26538: 0, 26540: 0, 26543: 0, 26552: 0, 26559: 1, 26568: 0, 26587: 1, 26595: 0, 26599: 0, 26620: 1, 26642: 1, 26653: 0, 26663: 0, 26671: 0, 26673: 0, 26680: 0, 26701: 0, 26711: 0, 26725: 1, 26726: 1, 26730: 0, 26734: 1, 26738: 1, 26745: 1, 26749: 1, 26774: 0, 26776: 0, 26777: 0, 26780: 0, 26792: 0, 26819: 0, 26836: 1, 26841: 1, 26848: 1, 26862: 1, 26873: 0, 26880: 0, 26884: 0, 26886: 0, 26904: 0, 26935: 1, 26941: 0, 26945: 0, 26946: 0, 26947: 0, 26971: 0, 26987: 1, 26988: 0, 26993: 1, 27000: 0, 27007: 0, 27021: 1, 27045: 0, 27046: 0, 27048: 0, 27056: 0, 27058: 0, 27081: 1, 27083: 0, 27088: 0, 27100: 0, 27107: 1, 27129: 1, 27148: 1, 27151: 1, 27169: 1, 27171: 1, 27201: 0, 27203: 0, 27237: 1, 27254: 0, 27256: 0, 27257: 0, 27261: 0, 27266: 0, 27272: 0, 27296: 0, 27311: 0, 27317: 0}\n",
            "./saved_models/predictions.txt\n",
            "prediction: {3: 1, 12: 0, 35: 0, 43: 1, 60: 0, 70: 0, 83: 0, 84: 0, 108: 0, 121: 1, 122: 0, 149: 0, 164: 1, 176: 0, 178: 0, 179: 0, 185: 0, 200: 0, 218: 0, 244: 1, 245: 0, 246: 0, 248: 1, 262: 0, 265: 1, 272: 0, 280: 1, 289: 0, 304: 0, 305: 1, 321: 0, 325: 0, 338: 0, 369: 1, 372: 1, 373: 0, 391: 0, 399: 0, 402: 0, 404: 0, 436: 0, 439: 0, 444: 0, 461: 0, 474: 0, 490: 1, 491: 1, 501: 0, 510: 0, 539: 1, 547: 0, 566: 1, 569: 0, 572: 0, 573: 1, 574: 0, 585: 1, 599: 0, 657: 1, 666: 1, 669: 0, 674: 1, 677: 0, 683: 0, 686: 1, 707: 0, 710: 0, 729: 0, 740: 0, 748: 1, 767: 0, 781: 0, 794: 0, 797: 0, 837: 0, 848: 1, 855: 0, 860: 0, 883: 0, 886: 0, 899: 0, 906: 0, 913: 0, 921: 0, 924: 0, 937: 1, 941: 0, 944: 1, 946: 1, 961: 0, 963: 0, 971: 1, 982: 0, 1035: 0, 1038: 0, 1040: 1, 1046: 0, 1056: 1, 1059: 0, 1060: 0, 1089: 1, 1107: 0, 1108: 1, 1119: 1, 1121: 0, 1122: 0, 1130: 0, 1136: 1, 1137: 0, 1145: 0, 1167: 0, 1194: 1, 1215: 0, 1227: 0, 1277: 0, 1290: 0, 1307: 1, 1308: 1, 1318: 1, 1335: 0, 1338: 1, 1341: 1, 1351: 0, 1360: 0, 1373: 1, 1377: 0, 1381: 1, 1404: 1, 1420: 1, 1426: 1, 1434: 0, 1435: 1, 1439: 1, 1457: 0, 1469: 0, 1473: 0, 1476: 1, 1487: 0, 1497: 0, 1500: 1, 1507: 1, 1508: 1, 1519: 0, 1525: 0, 1533: 0, 1540: 0, 1557: 0, 1573: 0, 1616: 0, 1621: 0, 1626: 0, 1628: 1, 1657: 1, 1672: 0, 1710: 0, 1712: 1, 1713: 0, 1721: 0, 1726: 0, 1736: 1, 1760: 1, 1770: 0, 1783: 0, 1791: 1, 1802: 0, 1804: 1, 1817: 1, 1822: 0, 1878: 1, 1883: 1, 1894: 0, 1896: 0, 1900: 0, 1902: 0, 1905: 0, 1909: 0, 1917: 0, 1937: 0, 1945: 1, 1946: 0, 1981: 0, 1983: 1, 1990: 1, 1994: 1, 1998: 1, 2009: 0, 2010: 1, 2027: 0, 2047: 0, 2049: 1, 2053: 0, 2063: 1, 2083: 1, 2084: 0, 2093: 1, 2110: 1, 2115: 1, 2124: 0, 2130: 1, 2133: 1, 2142: 1, 2148: 0, 2157: 1, 2182: 0, 2187: 0, 2188: 1, 2190: 0, 2195: 0, 2213: 0, 2229: 1, 2246: 0, 2265: 1, 2280: 0, 2297: 0, 2298: 0, 2300: 1, 2325: 1, 2328: 0, 2329: 0, 2334: 0, 2348: 0, 2349: 0, 2358: 1, 2365: 0, 2395: 1, 2400: 1, 2415: 0, 2424: 0, 2429: 0, 2451: 0, 2466: 0, 2471: 0, 2502: 0, 2523: 1, 2534: 1, 2535: 0, 2538: 0, 2564: 0, 2583: 1, 2594: 0, 2602: 0, 2604: 0, 2620: 0, 2622: 1, 2624: 1, 2628: 0, 2632: 0, 2634: 0, 2649: 0, 2656: 0, 2665: 1, 2673: 0, 2677: 1, 2680: 1, 2704: 1, 2737: 0, 2762: 0, 2793: 0, 2806: 0, 2817: 0, 2818: 0, 2820: 1, 2832: 1, 2846: 0, 2857: 1, 2880: 0, 2884: 0, 2895: 0, 2903: 0, 2911: 0, 2913: 1, 2914: 1, 2929: 0, 2946: 0, 2950: 0, 2958: 0, 2967: 0, 2996: 0, 3001: 0, 3003: 0, 3020: 0, 3040: 0, 3054: 0, 3065: 0, 3070: 1, 3076: 0, 3082: 0, 3098: 0, 3117: 0, 3130: 0, 3153: 0, 3158: 0, 3160: 0, 3161: 0, 3162: 1, 3176: 1, 3179: 0, 3180: 0, 3182: 0, 3183: 0, 3184: 1, 3205: 0, 3211: 0, 3227: 1, 3228: 1, 3236: 0, 3237: 0, 3256: 0, 3266: 0, 3274: 1, 3278: 0, 3279: 1, 3288: 1, 3290: 1, 3293: 1, 3320: 0, 3322: 1, 3327: 0, 3330: 0, 3333: 0, 3348: 1, 3375: 1, 3392: 1, 3394: 0, 3397: 1, 3398: 0, 3399: 0, 3401: 0, 3416: 0, 3440: 0, 3449: 0, 3452: 0, 3456: 1, 3460: 0, 3476: 1, 3484: 0, 3499: 0, 3502: 0, 3513: 0, 3517: 0, 3521: 0, 3540: 1, 3551: 1, 3555: 1, 3561: 0, 3582: 0, 3596: 1, 3598: 1, 3602: 0, 3610: 0, 3611: 0, 3621: 1, 3634: 1, 3658: 1, 3681: 1, 3691: 1, 3714: 1, 3721: 0, 3722: 1, 3731: 0, 3743: 0, 3748: 0, 3755: 0, 3763: 0, 3766: 0, 3770: 0, 3778: 1, 3795: 0, 3811: 0, 3815: 0, 3824: 0, 3832: 0, 3834: 0, 3838: 0, 3845: 0, 3901: 0, 3913: 1, 3920: 0, 3924: 0, 3926: 0, 3933: 0, 3946: 0, 3956: 0, 3960: 0, 3970: 0, 3971: 1, 3977: 0, 3984: 1, 3988: 0, 4006: 0, 4009: 1, 4017: 1, 4025: 0, 4029: 1, 4041: 1, 4062: 1, 4064: 1, 4070: 1, 4080: 0, 4091: 0, 4093: 1, 4095: 0, 4104: 0, 4141: 1, 4159: 1, 4165: 0, 4166: 0, 4173: 0, 4178: 0, 4196: 0, 4198: 1, 4209: 0, 4211: 0, 4213: 0, 4217: 0, 4218: 0, 4221: 0, 4253: 0, 4255: 1, 4256: 0, 4260: 1, 4306: 1, 4307: 1, 4315: 1, 4337: 0, 4341: 1, 4344: 0, 4360: 1, 4362: 0, 4385: 1, 4389: 0, 4411: 0, 4440: 0, 4479: 0, 4488: 0, 4519: 1, 4521: 0, 4524: 0, 4539: 0, 4540: 0, 4551: 0, 4555: 0, 4556: 0, 4563: 0, 4569: 1, 4570: 0, 4571: 0, 4607: 0, 4609: 1, 4610: 0, 4611: 0, 4615: 1, 4639: 1, 4645: 0, 4668: 1, 4681: 0, 4685: 0, 4697: 0, 4698: 0, 4718: 0, 4760: 0, 4761: 0, 4762: 0, 4766: 1, 4768: 1, 4769: 1, 4770: 0, 4781: 0, 4798: 1, 4800: 0, 4801: 1, 4815: 1, 4835: 0, 4842: 0, 4849: 0, 4873: 0, 4874: 1, 4879: 0, 4892: 0, 4893: 0, 4896: 1, 4899: 0, 4924: 0, 4961: 1, 4995: 1, 5035: 0, 5044: 0, 5054: 0, 5060: 0, 5071: 1, 5093: 0, 5099: 0, 5102: 0, 5104: 1, 5121: 0, 5129: 0, 5138: 1, 5146: 1, 5171: 0, 5172: 0, 5174: 1, 5190: 0, 5191: 0, 5198: 0, 5201: 0, 5219: 0, 5222: 0, 5229: 0, 5250: 0, 5263: 1, 5277: 0, 5281: 1, 5283: 0, 5298: 0, 5304: 0, 5306: 0, 5308: 0, 5314: 0, 5327: 1, 5353: 0, 5356: 0, 5357: 1, 5361: 1, 5381: 0, 5386: 0, 5408: 0, 5416: 1, 5429: 1, 5430: 0, 5437: 1, 5452: 0, 5457: 0, 5482: 0, 5490: 0, 5500: 1, 5508: 0, 5509: 1, 5539: 0, 5567: 1, 5581: 0, 5582: 1, 5587: 1, 5607: 0, 5617: 0, 5621: 1, 5624: 0, 5630: 0, 5646: 0, 5670: 1, 5672: 0, 5673: 0, 5676: 1, 5694: 0, 5707: 0, 5718: 0, 5731: 0, 5754: 1, 5755: 0, 5762: 1, 5767: 0, 5781: 1, 5789: 1, 5797: 1, 5810: 0, 5820: 1, 5826: 1, 5834: 1, 5837: 0, 5845: 0, 5846: 0, 5855: 1, 5864: 1, 5875: 0, 5899: 0, 5905: 1, 5908: 0, 5920: 1, 5931: 0, 5962: 1, 5963: 1, 5965: 1, 5981: 0, 6007: 1, 6008: 1, 6025: 0, 6032: 0, 6033: 0, 6043: 0, 6063: 1, 6069: 1, 6092: 0, 6098: 0, 6103: 0, 6108: 1, 6112: 1, 6125: 1, 6140: 0, 6160: 1, 6165: 0, 6186: 1, 6189: 0, 6193: 1, 6196: 0, 6206: 0, 6217: 0, 6241: 1, 6243: 0, 6251: 1, 6272: 0, 6277: 0, 6293: 0, 6307: 0, 6335: 1, 6346: 1, 6374: 0, 6385: 0, 6408: 0, 6432: 1, 6452: 0, 6455: 0, 6486: 1, 6489: 1, 6500: 0, 6507: 0, 6509: 1, 6519: 1, 6524: 0, 6532: 0, 6535: 1, 6543: 1, 6545: 0, 6547: 1, 6556: 1, 6575: 0, 6577: 0, 6580: 0, 6594: 0, 6605: 0, 6622: 1, 6628: 1, 6635: 0, 6641: 0, 6646: 1, 6650: 0, 6670: 1, 6674: 1, 6685: 0, 6699: 0, 6708: 1, 6727: 1, 6753: 0, 6763: 0, 6775: 0, 6778: 1, 6801: 0, 6816: 0, 6829: 0, 6838: 0, 6844: 0, 6852: 0, 6867: 0, 6879: 0, 6891: 1, 6919: 0, 6927: 0, 6935: 0, 6946: 1, 6951: 0, 6953: 0, 6956: 0, 6972: 1, 6997: 0, 6999: 0, 7004: 0, 7017: 0, 7019: 1, 7027: 0, 7033: 0, 7048: 1, 7066: 0, 7069: 0, 7099: 0, 7105: 0, 7109: 0, 7111: 0, 7119: 0, 7122: 0, 7125: 0, 7130: 0, 7150: 1, 7168: 0, 7174: 1, 7177: 1, 7191: 1, 7204: 0, 7213: 0, 7222: 1, 7243: 0, 7267: 0, 7269: 1, 7315: 0, 7324: 0, 7326: 1, 7327: 0, 7332: 0, 7334: 0, 7347: 1, 7351: 0, 7360: 1, 7380: 0, 7393: 0, 7398: 0, 7420: 0, 7428: 0, 7430: 0, 7448: 1, 7449: 0, 7458: 1, 7462: 0, 7471: 1, 7472: 1, 7480: 0, 7481: 0, 7490: 0, 7491: 0, 7498: 0, 7521: 0, 7556: 0, 7558: 1, 7579: 1, 7590: 0, 7596: 1, 7598: 1, 7609: 0, 7622: 1, 7649: 0, 7651: 0, 7654: 0, 7659: 0, 7662: 1, 7666: 0, 7670: 1, 7696: 0, 7716: 0, 7729: 0, 7732: 0, 7749: 0, 7754: 0, 7761: 1, 7762: 0, 7766: 0, 7777: 0, 7779: 0, 7780: 0, 7782: 1, 7808: 1, 7814: 1, 7828: 0, 7834: 1, 7852: 0, 7854: 0, 7866: 0, 7869: 0, 7873: 0, 7874: 0, 7881: 1, 7882: 1, 7885: 1, 7892: 0, 7893: 0, 7916: 0, 7925: 0, 7936: 0, 7967: 1, 7972: 0, 7977: 0, 7980: 1, 7982: 1, 7992: 0, 8010: 0, 8018: 0, 8021: 1, 8046: 1, 8049: 0, 8071: 0, 8085: 1, 8103: 1, 8105: 0, 8111: 1, 8112: 0, 8124: 1, 8130: 1, 8134: 0, 8145: 0, 8154: 0, 8155: 0, 8157: 0, 8158: 1, 8169: 1, 8171: 0, 8181: 0, 8197: 0, 8199: 0, 8208: 1, 8209: 1, 8211: 1, 8217: 0, 8221: 0, 8241: 0, 8247: 0, 8254: 0, 8271: 0, 8273: 0, 8291: 0, 8296: 1, 8313: 1, 8340: 0, 8357: 0, 8370: 0, 8380: 0, 8409: 0, 8412: 0, 8425: 1, 8431: 1, 8435: 0, 8447: 0, 8457: 0, 8466: 1, 8482: 1, 8487: 0, 8518: 0, 8522: 1, 8526: 0, 8534: 1, 8543: 0, 8565: 1, 8568: 1, 8577: 0, 8592: 1, 8617: 0, 8673: 1, 8707: 1, 8720: 1, 8755: 1, 8793: 0, 8794: 1, 8815: 0, 8825: 0, 8835: 0, 8846: 0, 8855: 0, 8858: 0, 8866: 0, 8878: 0, 8900: 1, 8901: 0, 8903: 0, 8927: 0, 8931: 0, 8946: 0, 8949: 0, 8955: 0, 8963: 0, 8970: 0, 8988: 0, 9025: 0, 9036: 0, 9038: 0, 9039: 1, 9047: 1, 9049: 1, 9055: 1, 9067: 0, 9072: 1, 9087: 1, 9091: 1, 9094: 0, 9095: 0, 9101: 0, 9106: 0, 9109: 1, 9122: 0, 9134: 0, 9150: 0, 9162: 0, 9172: 1, 9174: 0, 9176: 0, 9178: 1, 9189: 1, 9193: 0, 9210: 0, 9215: 1, 9225: 0, 9231: 1, 9238: 0, 9246: 1, 9255: 0, 9258: 1, 9260: 0, 9282: 1, 9283: 1, 9301: 1, 9330: 0, 9343: 0, 9347: 1, 9349: 1, 9351: 1, 9352: 1, 9366: 0, 9399: 1, 9418: 0, 9434: 0, 9435: 1, 9437: 1, 9443: 0, 9445: 0, 9457: 0, 9482: 1, 9508: 1, 9509: 1, 9510: 0, 9516: 1, 9528: 0, 9533: 0, 9546: 0, 9548: 0, 9574: 0, 9576: 0, 9584: 1, 9598: 1, 9607: 1, 9616: 0, 9619: 0, 9629: 1, 9630: 0, 9639: 0, 9643: 1, 9647: 1, 9650: 0, 9651: 0, 9670: 0, 9683: 1, 9706: 0, 9707: 1, 9709: 1, 9721: 0, 9722: 1, 9727: 0, 9744: 0, 9754: 0, 9761: 1, 9772: 0, 9781: 1, 9787: 0, 9789: 0, 9805: 1, 9817: 1, 9842: 0, 9845: 0, 9846: 1, 9864: 0, 9870: 0, 9896: 1, 9913: 1, 9922: 0, 9929: 1, 9934: 1, 9943: 0, 9956: 0, 9961: 0, 9977: 0, 10000: 0, 10026: 0, 10049: 0, 10055: 0, 10064: 0, 10081: 0, 10104: 0, 10128: 0, 10161: 1, 10175: 1, 10180: 1, 10190: 0, 10192: 0, 10194: 1, 10213: 0, 10233: 0, 10244: 0, 10253: 0, 10266: 0, 10268: 0, 10269: 0, 10278: 0, 10282: 0, 10291: 0, 10295: 1, 10308: 0, 10316: 0, 10322: 0, 10327: 0, 10333: 0, 10338: 1, 10351: 0, 10355: 0, 10364: 0, 10370: 0, 10374: 0, 10385: 0, 10406: 0, 10410: 0, 10414: 0, 10416: 0, 10429: 0, 10449: 0, 10478: 0, 10480: 0, 10485: 0, 10498: 0, 10502: 1, 10504: 0, 10513: 1, 10520: 1, 10539: 1, 10547: 1, 10554: 0, 10556: 1, 10564: 0, 10583: 0, 10594: 0, 10609: 1, 10620: 0, 10640: 1, 10648: 1, 10665: 1, 10670: 1, 10671: 1, 10672: 1, 10699: 1, 10721: 0, 10723: 1, 10727: 1, 10730: 0, 10735: 0, 10738: 0, 10741: 1, 10744: 1, 10750: 1, 10765: 1, 10767: 0, 10772: 0, 10773: 0, 10801: 1, 10836: 0, 10842: 1, 10847: 0, 10849: 1, 10857: 0, 10868: 1, 10869: 0, 10875: 0, 10877: 0, 10899: 0, 10914: 1, 10950: 0, 10962: 1, 10971: 1, 10974: 0, 10982: 1, 10984: 1, 10992: 0, 10999: 0, 11016: 0, 11026: 0, 11046: 1, 11070: 0, 11080: 0, 11084: 0, 11113: 0, 11117: 0, 11126: 0, 11127: 0, 11128: 0, 11140: 0, 11141: 0, 11142: 1, 11143: 0, 11167: 0, 11193: 0, 11202: 1, 11235: 0, 11268: 0, 11303: 0, 11316: 0, 11328: 0, 11334: 0, 11359: 1, 11361: 0, 11368: 1, 11381: 0, 11383: 1, 11400: 0, 11423: 1, 11427: 1, 11428: 0, 11433: 1, 11439: 1, 11444: 0, 11449: 1, 11455: 0, 11468: 1, 11488: 0, 11501: 0, 11516: 0, 11524: 1, 11527: 0, 11529: 0, 11535: 0, 11543: 1, 11546: 1, 11553: 1, 11566: 0, 11592: 0, 11608: 1, 11624: 0, 11631: 0, 11635: 0, 11641: 0, 11642: 1, 11646: 1, 11662: 1, 11665: 0, 11674: 0, 11685: 0, 11712: 1, 11714: 0, 11742: 1, 11748: 0, 11749: 1, 11781: 0, 11793: 1, 11795: 0, 11806: 1, 11810: 0, 11813: 0, 11833: 0, 11834: 0, 11840: 0, 11843: 0, 11844: 0, 11852: 0, 11853: 0, 11854: 0, 11861: 0, 11865: 0, 11877: 1, 11885: 1, 11911: 0, 11919: 0, 11933: 1, 11936: 0, 11957: 0, 11958: 1, 11969: 0, 11975: 1, 11978: 1, 11979: 1, 11980: 1, 11983: 1, 11985: 0, 11988: 0, 11998: 0, 12023: 0, 12026: 0, 12036: 0, 12038: 0, 12075: 0, 12079: 0, 12083: 0, 12086: 1, 12095: 1, 12099: 0, 12106: 0, 12111: 0, 12130: 0, 12133: 0, 12134: 0, 12142: 0, 12145: 1, 12182: 1, 12190: 0, 12192: 1, 12200: 1, 12205: 1, 12215: 1, 12216: 0, 12243: 0, 12245: 0, 12255: 1, 12257: 0, 12273: 0, 12278: 1, 12281: 0, 12305: 1, 12307: 0, 12314: 0, 12320: 1, 12326: 0, 12329: 0, 12347: 0, 12353: 0, 12357: 0, 12362: 1, 12365: 0, 12367: 0, 12376: 0, 12377: 0, 12378: 0, 12383: 0, 12384: 0, 12395: 0, 12402: 0, 12409: 1, 12412: 1, 12429: 0, 12434: 0, 12451: 0, 12452: 1, 12470: 0, 12477: 0, 12493: 1, 12499: 1, 12544: 0, 12545: 0, 12548: 1, 12556: 0, 12558: 0, 12585: 1, 12596: 0, 12607: 1, 12616: 0, 12624: 0, 12635: 0, 12642: 0, 12645: 0, 12663: 0, 12667: 0, 12668: 0, 12672: 0, 12686: 0, 12701: 0, 12704: 0, 12710: 0, 12724: 0, 12730: 0, 12741: 0, 12777: 0, 12780: 1, 12785: 1, 12786: 1, 12787: 0, 12789: 0, 12799: 0, 12805: 1, 12809: 0, 12810: 1, 12814: 0, 12828: 0, 12846: 1, 12853: 0, 12887: 0, 12894: 0, 12916: 0, 12927: 0, 12940: 1, 12946: 0, 12949: 1, 12951: 1, 12968: 1, 12984: 0, 13001: 0, 13002: 0, 13012: 0, 13024: 1, 13031: 1, 13035: 0, 13040: 0, 13050: 0, 13051: 0, 13068: 1, 13077: 0, 13081: 1, 13097: 0, 13100: 1, 13114: 1, 13118: 0, 13130: 0, 13136: 1, 13137: 0, 13140: 0, 13149: 1, 13154: 0, 13155: 0, 13156: 0, 13163: 0, 13172: 0, 13204: 1, 13205: 0, 13230: 1, 13236: 0, 13268: 1, 13273: 0, 13311: 1, 13316: 0, 13339: 0, 13347: 1, 13357: 1, 13363: 0, 13365: 0, 13366: 0, 13388: 0, 13415: 0, 13426: 0, 13429: 0, 13437: 0, 13442: 1, 13448: 0, 13462: 1, 13468: 0, 13488: 1, 13494: 0, 13504: 0, 13513: 0, 13517: 0, 13524: 0, 13548: 0, 13554: 1, 13555: 0, 13556: 1, 13571: 0, 13589: 0, 13604: 0, 13635: 1, 13636: 1, 13667: 0, 13672: 0, 13706: 0, 13712: 0, 13726: 0, 13728: 1, 13734: 0, 13736: 0, 13739: 1, 13740: 1, 13748: 1, 13754: 0, 13768: 0, 13772: 0, 13784: 0, 13809: 0, 13829: 0, 13855: 1, 13859: 1, 13867: 0, 13888: 0, 13890: 0, 13897: 0, 13899: 1, 13905: 0, 13906: 1, 13915: 0, 13943: 0, 13951: 0, 13969: 0, 13988: 0, 14014: 1, 14022: 0, 14023: 0, 14024: 0, 14025: 0, 14031: 0, 14056: 1, 14076: 0, 14090: 1, 14108: 0, 14126: 0, 14141: 0, 14144: 1, 14162: 0, 14168: 1, 14199: 1, 14220: 0, 14228: 0, 14248: 0, 14263: 0, 14289: 0, 14300: 1, 14306: 1, 14308: 1, 14309: 0, 14324: 0, 14350: 0, 14356: 0, 14359: 0, 14362: 1, 14366: 0, 14372: 0, 14376: 1, 14379: 1, 14387: 0, 14388: 0, 14393: 1, 14413: 0, 14442: 0, 14459: 1, 14469: 0, 14476: 1, 14499: 1, 14508: 0, 14521: 1, 14531: 0, 14557: 0, 14566: 0, 14588: 1, 14589: 0, 14591: 0, 14599: 0, 14612: 0, 14639: 1, 14654: 1, 14658: 1, 14665: 1, 14673: 1, 14679: 0, 14680: 1, 14694: 0, 14716: 0, 14723: 0, 14741: 0, 14745: 0, 14750: 0, 14774: 1, 14775: 0, 14777: 0, 14813: 1, 14814: 1, 14816: 1, 14822: 1, 14823: 1, 14840: 0, 14842: 0, 14846: 0, 14848: 1, 14865: 1, 14872: 0, 14884: 1, 14904: 0, 14911: 0, 14913: 0, 14936: 0, 14942: 1, 14951: 0, 14982: 1, 15001: 0, 15002: 0, 15016: 0, 15051: 0, 15055: 1, 15061: 0, 15066: 0, 15067: 0, 15077: 0, 15082: 0, 15094: 1, 15106: 0, 15108: 1, 15115: 0, 15124: 1, 15125: 0, 15132: 1, 15133: 1, 15136: 0, 15147: 0, 15173: 0, 15201: 1, 15206: 1, 15209: 1, 15239: 0, 15249: 0, 15252: 1, 15260: 1, 15288: 0, 15290: 0, 15301: 1, 15321: 0, 15341: 0, 15368: 1, 15373: 0, 15388: 0, 15389: 0, 15401: 0, 15411: 0, 15420: 1, 15434: 0, 15449: 0, 15457: 0, 15482: 1, 15486: 0, 15492: 0, 15495: 0, 15515: 0, 15517: 0, 15520: 0, 15521: 0, 15524: 0, 15530: 0, 15534: 0, 15535: 0, 15537: 0, 15549: 0, 15552: 0, 15555: 1, 15582: 0, 15589: 1, 15594: 1, 15615: 0, 15634: 0, 15644: 0, 15653: 0, 15654: 1, 15655: 0, 15664: 0, 15679: 0, 15690: 0, 15696: 1, 15723: 0, 15728: 0, 15775: 0, 15779: 0, 15788: 0, 15791: 0, 15804: 0, 15811: 1, 15818: 0, 15823: 0, 15833: 0, 15840: 0, 15846: 0, 15879: 0, 15883: 1, 15885: 0, 15890: 0, 15897: 0, 15906: 1, 15911: 0, 15924: 0, 15929: 0, 15943: 0, 15962: 0, 15965: 0, 15977: 0, 15980: 0, 15985: 0, 15987: 1, 15999: 0, 16020: 0, 16047: 0, 16057: 1, 16068: 0, 16083: 0, 16089: 0, 16090: 0, 16093: 0, 16112: 0, 16135: 1, 16147: 0, 16155: 0, 16163: 0, 16164: 0, 16177: 0, 16183: 0, 16190: 1, 16197: 0, 16203: 1, 16204: 1, 16205: 1, 16207: 1, 16211: 0, 16216: 1, 16227: 0, 16237: 0, 16246: 0, 16255: 0, 16256: 1, 16274: 1, 16276: 0, 16281: 1, 16293: 1, 16318: 0, 16335: 0, 16352: 0, 16360: 1, 16365: 0, 16370: 0, 16385: 0, 16406: 0, 16410: 0, 16412: 0, 16415: 0, 16419: 0, 16422: 0, 16431: 0, 16437: 0, 16449: 1, 16452: 1, 16465: 0, 16483: 0, 16498: 0, 16501: 0, 16507: 0, 16521: 0, 16524: 0, 16536: 0, 16542: 0, 16566: 0, 16585: 0, 16602: 1, 16614: 1, 16628: 0, 16651: 0, 16664: 0, 16666: 1, 16693: 0, 16700: 0, 16708: 0, 16717: 0, 16723: 1, 16724: 0, 16727: 1, 16728: 0, 16735: 1, 16752: 0, 16755: 0, 16767: 1, 16771: 0, 16780: 0, 16783: 0, 16787: 0, 16792: 0, 16794: 0, 16795: 1, 16808: 1, 16812: 0, 16829: 0, 16842: 0, 16862: 0, 16870: 0, 16879: 1, 16888: 0, 16890: 0, 16924: 1, 16930: 0, 16933: 1, 16984: 1, 16986: 1, 16999: 0, 17004: 0, 17009: 1, 17012: 0, 17021: 0, 17030: 0, 17043: 1, 17048: 0, 17072: 0, 17082: 0, 17085: 0, 17092: 0, 17101: 1, 17113: 1, 17118: 0, 17120: 0, 17124: 0, 17128: 0, 17133: 0, 17141: 1, 17152: 0, 17172: 1, 17199: 0, 17203: 0, 17206: 0, 17240: 0, 17242: 0, 17246: 0, 17258: 0, 17266: 0, 17267: 0, 17274: 0, 17280: 1, 17288: 0, 17301: 0, 17307: 0, 17308: 0, 17314: 1, 17325: 0, 17328: 1, 17329: 1, 17337: 0, 17341: 1, 17350: 1, 17353: 0, 17357: 0, 17362: 0, 17370: 0, 17381: 1, 17411: 1, 17412: 1, 17413: 1, 17428: 0, 17439: 0, 17449: 1, 17452: 0, 17480: 1, 17482: 0, 17513: 1, 17518: 0, 17534: 0, 17548: 1, 17553: 1, 17554: 0, 17576: 0, 17581: 0, 17587: 0, 17596: 1, 17597: 1, 17611: 0, 17615: 1, 17627: 1, 17641: 0, 17653: 0, 17664: 0, 17670: 0, 17678: 0, 17682: 0, 17699: 0, 17700: 0, 17710: 0, 17723: 1, 17735: 0, 17737: 0, 17742: 0, 17752: 1, 17765: 0, 17766: 1, 17786: 1, 17787: 1, 17792: 0, 17803: 0, 17805: 0, 17807: 0, 17808: 0, 17833: 1, 17877: 1, 17883: 0, 17885: 0, 17893: 0, 17904: 1, 17908: 1, 17909: 1, 17913: 0, 17929: 1, 17932: 0, 17953: 0, 17954: 0, 17972: 0, 17981: 0, 18015: 0, 18020: 0, 18038: 1, 18044: 0, 18067: 0, 18077: 1, 18095: 1, 18138: 0, 18142: 0, 18150: 0, 18159: 0, 18161: 0, 18171: 1, 18175: 1, 18187: 0, 18194: 1, 18195: 0, 18200: 1, 18202: 1, 18203: 1, 18211: 1, 18220: 0, 18231: 0, 18254: 0, 18267: 0, 18268: 0, 18272: 0, 18279: 0, 18282: 0, 18285: 0, 18304: 0, 18311: 1, 18323: 1, 18324: 0, 18326: 0, 18329: 1, 18344: 0, 18345: 0, 18351: 0, 18371: 0, 18384: 0, 18409: 0, 18412: 1, 18426: 1, 18437: 0, 18438: 0, 18439: 1, 18447: 1, 18457: 0, 18462: 1, 18474: 1, 18477: 0, 18493: 0, 18512: 0, 18513: 0, 18518: 1, 18523: 1, 18529: 1, 18545: 1, 18556: 0, 18559: 0, 18562: 1, 18578: 1, 18583: 0, 18596: 0, 18597: 0, 18598: 0, 18614: 0, 18619: 0, 18620: 0, 18624: 1, 18629: 1, 18640: 0, 18646: 1, 18648: 1, 18649: 1, 18673: 0, 18675: 0, 18696: 0, 18700: 1, 18719: 0, 18724: 0, 18727: 0, 18741: 0, 18744: 0, 18759: 0, 18773: 0, 18781: 0, 18799: 1, 18812: 0, 18819: 0, 18820: 1, 18830: 0, 18833: 0, 18838: 1, 18853: 0, 18892: 0, 18893: 1, 18915: 0, 18931: 0, 18942: 0, 18963: 1, 18969: 0, 18988: 0, 19003: 0, 19005: 1, 19011: 0, 19023: 1, 19027: 1, 19041: 0, 19075: 0, 19082: 0, 19090: 0, 19102: 1, 19108: 0, 19115: 0, 19116: 0, 19119: 0, 19126: 0, 19128: 1, 19129: 0, 19133: 0, 19160: 0, 19184: 1, 19198: 0, 19204: 0, 19216: 0, 19223: 0, 19237: 1, 19238: 0, 19243: 0, 19245: 0, 19253: 1, 19256: 0, 19274: 0, 19290: 0, 19291: 0, 19301: 0, 19307: 1, 19322: 0, 19353: 1, 19373: 0, 19380: 0, 19389: 0, 19403: 1, 19408: 0, 19411: 1, 19431: 0, 19434: 0, 19441: 0, 19469: 1, 19473: 0, 19490: 0, 19492: 0, 19494: 0, 19538: 1, 19554: 1, 19557: 0, 19567: 0, 19574: 0, 19576: 0, 19593: 0, 19595: 1, 19612: 0, 19633: 1, 19643: 1, 19650: 1, 19654: 0, 19665: 1, 19667: 0, 19684: 1, 19685: 1, 19709: 0, 19716: 1, 19721: 0, 19724: 0, 19728: 0, 19759: 0, 19782: 1, 19808: 1, 19809: 1, 19827: 1, 19834: 1, 19886: 0, 19889: 1, 19892: 1, 19908: 1, 19912: 0, 19916: 0, 19927: 0, 19962: 0, 19965: 0, 19966: 1, 19976: 0, 19987: 1, 19998: 1, 19999: 1, 20000: 0, 20005: 0, 20019: 0, 20022: 1, 20026: 0, 20032: 1, 20035: 0, 20054: 0, 20070: 0, 20086: 0, 20095: 1, 20102: 0, 20105: 0, 20109: 1, 20110: 0, 20129: 0, 20131: 1, 20148: 0, 20151: 1, 20158: 0, 20189: 0, 20197: 0, 20199: 0, 20200: 1, 20213: 0, 20233: 0, 20237: 1, 20238: 0, 20248: 1, 20257: 0, 20282: 0, 20283: 0, 20299: 0, 20301: 0, 20305: 0, 20320: 0, 20327: 0, 20328: 0, 20338: 0, 20345: 1, 20352: 0, 20365: 0, 20368: 0, 20370: 0, 20398: 0, 20410: 0, 20422: 1, 20425: 0, 20433: 0, 20434: 0, 20457: 0, 20467: 1, 20471: 0, 20480: 0, 20485: 0, 20495: 0, 20507: 0, 20518: 0, 20520: 0, 20531: 0, 20534: 0, 20541: 0, 20548: 0, 20549: 0, 20553: 1, 20562: 0, 20576: 0, 20581: 0, 20600: 0, 20606: 0, 20613: 1, 20617: 0, 20618: 1, 20620: 0, 20623: 0, 20631: 1, 20643: 1, 20644: 0, 20647: 1, 20659: 0, 20662: 0, 20697: 0, 20698: 1, 20716: 1, 20722: 1, 20728: 0, 20738: 0, 20741: 0, 20743: 0, 20751: 0, 20761: 0, 20766: 0, 20797: 0, 20802: 0, 20803: 0, 20811: 0, 20812: 0, 20831: 0, 20835: 1, 20840: 0, 20856: 0, 20902: 0, 20903: 1, 20908: 0, 20917: 0, 20918: 0, 20938: 0, 20945: 0, 20958: 0, 20961: 0, 20970: 0, 20975: 0, 20994: 0, 20996: 0, 21007: 1, 21012: 1, 21030: 0, 21034: 0, 21037: 0, 21050: 0, 21061: 0, 21070: 1, 21092: 0, 21100: 0, 21102: 0, 21106: 1, 21110: 0, 21118: 1, 21135: 0, 21155: 1, 21166: 1, 21168: 0, 21202: 0, 21218: 1, 21219: 0, 21250: 0, 21256: 0, 21261: 0, 21267: 0, 21281: 1, 21284: 1, 21296: 0, 21302: 0, 21306: 0, 21311: 0, 21324: 1, 21335: 0, 21348: 0, 21374: 0, 21383: 0, 21385: 1, 21386: 0, 21387: 0, 21392: 0, 21411: 0, 21413: 0, 21427: 0, 21430: 0, 21435: 0, 21450: 0, 21459: 0, 21466: 1, 21473: 0, 21487: 0, 21492: 0, 21508: 0, 21511: 0, 21513: 0, 21538: 1, 21549: 0, 21567: 0, 21569: 1, 21576: 0, 21583: 1, 21584: 0, 21585: 0, 21612: 0, 21622: 0, 21641: 1, 21665: 0, 21670: 1, 21694: 1, 21708: 1, 21723: 0, 21731: 0, 21739: 0, 21740: 0, 21750: 0, 21762: 1, 21766: 0, 21767: 0, 21776: 0, 21779: 1, 21794: 1, 21796: 0, 21820: 0, 21822: 1, 21828: 0, 21836: 0, 21841: 0, 21851: 0, 21863: 0, 21889: 1, 21899: 0, 21919: 1, 21925: 0, 21938: 1, 21957: 1, 21958: 0, 21962: 0, 21967: 1, 21969: 0, 21971: 0, 21995: 0, 22003: 0, 22006: 1, 22009: 1, 22013: 1, 22016: 1, 22034: 1, 22037: 0, 22047: 1, 22058: 1, 22065: 1, 22082: 0, 22086: 1, 22089: 0, 22093: 0, 22094: 0, 22132: 0, 22137: 1, 22140: 0, 22151: 0, 22155: 0, 22167: 1, 22201: 0, 22250: 1, 22265: 0, 22270: 0, 22276: 0, 22279: 0, 22280: 0, 22300: 0, 22316: 1, 22330: 0, 22361: 1, 22364: 0, 22365: 0, 22369: 1, 22379: 0, 22381: 0, 22387: 0, 22389: 0, 22392: 0, 22399: 0, 22413: 0, 22417: 0, 22418: 0, 22421: 1, 22425: 1, 22426: 1, 22429: 1, 22431: 1, 22436: 1, 22459: 0, 22462: 0, 22465: 0, 22503: 0, 22531: 0, 22534: 0, 22545: 0, 22552: 0, 22559: 0, 22597: 0, 22601: 0, 22615: 0, 22637: 0, 22652: 0, 22655: 0, 22662: 0, 22683: 1, 22693: 0, 22702: 1, 22705: 0, 22709: 0, 22718: 1, 22741: 0, 22752: 0, 22759: 0, 22801: 0, 22815: 1, 22826: 0, 22833: 1, 22834: 1, 22844: 0, 22875: 0, 22876: 0, 22906: 1, 22931: 1, 22944: 1, 22949: 0, 22955: 1, 22956: 0, 22959: 0, 22966: 0, 22969: 1, 22970: 0, 22976: 0, 22980: 0, 22994: 0, 23016: 0, 23049: 0, 23050: 1, 23052: 0, 23066: 0, 23074: 0, 23076: 0, 23088: 0, 23104: 0, 23105: 0, 23108: 0, 23116: 0, 23123: 0, 23136: 0, 23140: 0, 23145: 0, 23155: 0, 23159: 1, 23161: 0, 23163: 0, 23174: 0, 23184: 0, 23186: 0, 23193: 0, 23206: 0, 23213: 0, 23237: 0, 23244: 0, 23245: 0, 23247: 1, 23250: 0, 23256: 1, 23259: 0, 23274: 1, 23277: 1, 23299: 0, 23307: 0, 23309: 1, 23323: 1, 23339: 1, 23344: 1, 23354: 1, 23361: 0, 23371: 0, 23374: 0, 23386: 1, 23393: 0, 23405: 0, 23411: 0, 23425: 1, 23429: 0, 23455: 0, 23465: 1, 23470: 0, 23491: 0, 23495: 0, 23504: 0, 23508: 1, 23516: 0, 23540: 0, 23555: 0, 23560: 0, 23576: 1, 23587: 1, 23622: 0, 23626: 1, 23627: 1, 23636: 0, 23643: 1, 23656: 0, 23668: 0, 23680: 0, 23688: 0, 23692: 1, 23696: 0, 23704: 0, 23714: 0, 23744: 0, 23747: 0, 23751: 0, 23758: 0, 23762: 1, 23769: 1, 23771: 0, 23779: 0, 23786: 1, 23809: 0, 23816: 0, 23854: 0, 23855: 0, 23870: 0, 23872: 1, 23877: 0, 23888: 1, 23895: 1, 23899: 1, 23912: 1, 23916: 0, 23918: 0, 23922: 0, 23924: 0, 23933: 0, 23938: 0, 23942: 0, 23947: 0, 23956: 1, 23965: 0, 24009: 1, 24018: 0, 24044: 0, 24047: 0, 24050: 0, 24072: 0, 24075: 0, 24084: 0, 24085: 0, 24087: 1, 24090: 0, 24100: 0, 24103: 1, 24123: 0, 24141: 0, 24148: 1, 24162: 0, 24164: 1, 24179: 1, 24200: 0, 24201: 0, 24205: 0, 24206: 1, 24212: 0, 24213: 0, 24222: 0, 24230: 0, 24231: 1, 24244: 1, 24269: 1, 24280: 0, 24283: 0, 24289: 0, 24291: 1, 24292: 0, 24294: 0, 24311: 0, 24312: 0, 24315: 0, 24328: 1, 24331: 1, 24351: 1, 24356: 1, 24364: 1, 24368: 0, 24371: 0, 24375: 0, 24400: 0, 24424: 0, 24426: 0, 24433: 0, 24472: 1, 24478: 1, 24483: 1, 24484: 1, 24485: 0, 24486: 1, 24488: 0, 24501: 0, 24508: 0, 24540: 0, 24542: 0, 24555: 1, 24559: 1, 24578: 0, 24588: 0, 24603: 0, 24606: 0, 24621: 1, 24625: 1, 24626: 0, 24629: 0, 24631: 0, 24648: 0, 24655: 0, 24668: 1, 24677: 0, 24720: 0, 24730: 1, 24732: 1, 24742: 0, 24744: 0, 24748: 0, 24754: 0, 24756: 0, 24759: 1, 24761: 0, 24768: 1, 24771: 1, 24787: 0, 24794: 0, 24818: 1, 24824: 0, 24829: 0, 24847: 1, 24853: 0, 24855: 0, 24880: 0, 24881: 0, 24895: 1, 24896: 1, 24897: 0, 24899: 0, 24902: 1, 24921: 1, 24933: 0, 24968: 0, 25005: 0, 25024: 0, 25066: 0, 25075: 1, 25081: 1, 25091: 0, 25095: 0, 25103: 1, 25113: 0, 25119: 1, 25130: 0, 25134: 1, 25135: 0, 25149: 0, 25163: 0, 25167: 0, 25179: 0, 25181: 1, 25182: 0, 25185: 0, 25189: 0, 25223: 1, 25245: 0, 25247: 0, 25252: 1, 25260: 1, 25263: 0, 25265: 0, 25284: 0, 25310: 0, 25344: 1, 25353: 0, 25357: 0, 25370: 0, 25382: 1, 25401: 1, 25404: 1, 25413: 1, 25448: 1, 25459: 1, 25472: 0, 25492: 1, 25501: 0, 25505: 0, 25510: 0, 25515: 0, 25526: 0, 25530: 1, 25549: 0, 25550: 1, 25557: 0, 25566: 0, 25571: 0, 25574: 0, 25578: 0, 25580: 0, 25583: 0, 25593: 0, 25602: 0, 25619: 0, 25636: 0, 25669: 0, 25670: 0, 25672: 1, 25693: 0, 25704: 0, 25711: 0, 25729: 1, 25734: 0, 25737: 1, 25738: 0, 25741: 0, 25748: 1, 25753: 0, 25787: 0, 25810: 0, 25813: 0, 25814: 0, 25828: 1, 25831: 0, 25854: 1, 25859: 1, 25862: 0, 25865: 1, 25868: 0, 25869: 1, 25872: 1, 25925: 0, 25932: 0, 25936: 0, 25937: 1, 25947: 0, 25948: 0, 25958: 0, 25997: 0, 26003: 0, 26008: 0, 26030: 1, 26031: 1, 26038: 0, 26059: 0, 26061: 1, 26069: 1, 26075: 1, 26087: 1, 26090: 0, 26100: 1, 26110: 1, 26113: 0, 26117: 0, 26136: 0, 26152: 0, 26154: 1, 26158: 1, 26160: 0, 26173: 0, 26175: 1, 26183: 0, 26191: 1, 26225: 0, 26226: 1, 26234: 0, 26242: 0, 26243: 0, 26245: 1, 26251: 0, 26257: 0, 26259: 0, 26291: 0, 26294: 1, 26306: 1, 26315: 0, 26320: 0, 26330: 1, 26333: 0, 26360: 0, 26367: 0, 26388: 1, 26390: 0, 26396: 0, 26428: 0, 26435: 1, 26437: 0, 26443: 0, 26451: 0, 26458: 0, 26468: 0, 26472: 1, 26480: 0, 26481: 0, 26485: 1, 26489: 1, 26496: 0, 26512: 1, 26530: 1, 26531: 1, 26535: 0, 26538: 0, 26540: 0, 26543: 0, 26552: 0, 26559: 1, 26568: 1, 26587: 0, 26595: 1, 26599: 0, 26620: 0, 26642: 0, 26653: 0, 26663: 0, 26671: 0, 26673: 1, 26680: 0, 26701: 1, 26711: 0, 26725: 1, 26726: 0, 26730: 0, 26734: 0, 26738: 0, 26745: 0, 26749: 1, 26774: 0, 26776: 0, 26777: 0, 26780: 0, 26792: 0, 26819: 1, 26836: 0, 26841: 0, 26848: 1, 26862: 1, 26873: 1, 26880: 1, 26884: 0, 26886: 1, 26904: 0, 26935: 1, 26941: 0, 26945: 1, 26946: 0, 26947: 0, 26971: 0, 26987: 1, 26988: 0, 26993: 0, 27000: 0, 27007: 0, 27021: 0, 27045: 0, 27046: 0, 27048: 0, 27056: 0, 27058: 0, 27081: 1, 27083: 0, 27088: 1, 27100: 0, 27107: 1, 27129: 1, 27148: 1, 27151: 0, 27169: 0, 27171: 1, 27201: 0, 27203: 1, 27237: 1, 27254: 0, 27256: 0, 27257: 0, 27261: 0, 27266: 0, 27272: 0, 27296: 0, 27311: 0, 27317: 0}\n",
            "{'Acc': 0.6420204978038068}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CODE2VEC"
      ],
      "metadata": {
        "id": "CPOKvPRQnP5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ01gEK1KiAe",
        "outputId": "09ac51e0-b627-4610-ecb2-445d63d4df8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21854, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "NBpnXlxBnOZa",
        "outputId": "125a5652-5c50-4388-f574-9b93223b28b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      project                                 commit_id  target  \\\n",
              "0      FFmpeg  973b1a6b9070e2bf17d17568cbaf4043ce931f51       0   \n",
              "1      FFmpeg  321b2a9ded0468670b7678b7c098886930ae16b2       0   \n",
              "2      FFmpeg  5d5de3eba4c7890c2e8077f5b4ae569671d11cf8       0   \n",
              "3      FFmpeg  57d77b3963ce1023eaf5ada8cba58b9379405cc8       0   \n",
              "4      FFmpeg  aba232cfa9b193604ed98f3fa505378d006b1b3b       1   \n",
              "...       ...                                       ...     ...   \n",
              "21849    qemu  a8170e5e97ad17ca169c64ba87ae2f53850dab4c       0   \n",
              "21850    qemu  1ea879e5580f63414693655fcf0328559cdce138       0   \n",
              "21851    qemu  f74990a5d019751c545e9800a3376b6336e77d38       0   \n",
              "21852    qemu  a89f364ae8740dfc31b321eed9ee454e996dc3c1       0   \n",
              "21853    qemu  39fb730aed8c5f7b0058845cb9feac0d4b177985       0   \n",
              "\n",
              "                                                    func    idx  \n",
              "0      static av_cold int vdadec_init(AVCodecContext ...      0  \n",
              "1      static int transcode(AVFormatContext **output_...      1  \n",
              "2      static void v4l2_free_buffer(void *opaque, uin...      2  \n",
              "3      int av_opencl_buffer_write(cl_mem dst_cl_buf, ...      4  \n",
              "4      static int r3d_read_rdvo(AVFormatContext *s, A...      5  \n",
              "...                                                  ...    ...  \n",
              "21849  static void exynos4210_mct_write(void *opaque,...  27312  \n",
              "21850  static int no_init_in (HWVoiceIn *hw, audsetti...  27313  \n",
              "21851  uint32_t HELPER(stfle)(CPUS390XState *env, uin...  27314  \n",
              "21852  static void pxa2xx_fir_write(void *opaque, hwa...  27315  \n",
              "21853  static void disas_thumb_insn(CPUARMState *env,...  27316  \n",
              "\n",
              "[21854 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25d55bb1-b963-4cf0-8ebf-057e7bae5287\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project</th>\n",
              "      <th>commit_id</th>\n",
              "      <th>target</th>\n",
              "      <th>func</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>973b1a6b9070e2bf17d17568cbaf4043ce931f51</td>\n",
              "      <td>0</td>\n",
              "      <td>static av_cold int vdadec_init(AVCodecContext ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>321b2a9ded0468670b7678b7c098886930ae16b2</td>\n",
              "      <td>0</td>\n",
              "      <td>static int transcode(AVFormatContext **output_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>5d5de3eba4c7890c2e8077f5b4ae569671d11cf8</td>\n",
              "      <td>0</td>\n",
              "      <td>static void v4l2_free_buffer(void *opaque, uin...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>57d77b3963ce1023eaf5ada8cba58b9379405cc8</td>\n",
              "      <td>0</td>\n",
              "      <td>int av_opencl_buffer_write(cl_mem dst_cl_buf, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FFmpeg</td>\n",
              "      <td>aba232cfa9b193604ed98f3fa505378d006b1b3b</td>\n",
              "      <td>1</td>\n",
              "      <td>static int r3d_read_rdvo(AVFormatContext *s, A...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21849</th>\n",
              "      <td>qemu</td>\n",
              "      <td>a8170e5e97ad17ca169c64ba87ae2f53850dab4c</td>\n",
              "      <td>0</td>\n",
              "      <td>static void exynos4210_mct_write(void *opaque,...</td>\n",
              "      <td>27312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21850</th>\n",
              "      <td>qemu</td>\n",
              "      <td>1ea879e5580f63414693655fcf0328559cdce138</td>\n",
              "      <td>0</td>\n",
              "      <td>static int no_init_in (HWVoiceIn *hw, audsetti...</td>\n",
              "      <td>27313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21851</th>\n",
              "      <td>qemu</td>\n",
              "      <td>f74990a5d019751c545e9800a3376b6336e77d38</td>\n",
              "      <td>0</td>\n",
              "      <td>uint32_t HELPER(stfle)(CPUS390XState *env, uin...</td>\n",
              "      <td>27314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21852</th>\n",
              "      <td>qemu</td>\n",
              "      <td>a89f364ae8740dfc31b321eed9ee454e996dc3c1</td>\n",
              "      <td>0</td>\n",
              "      <td>static void pxa2xx_fir_write(void *opaque, hwa...</td>\n",
              "      <td>27315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21853</th>\n",
              "      <td>qemu</td>\n",
              "      <td>39fb730aed8c5f7b0058845cb9feac0d4b177985</td>\n",
              "      <td>0</td>\n",
              "      <td>static void disas_thumb_insn(CPUARMState *env,...</td>\n",
              "      <td>27316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21854 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25d55bb1-b963-4cf0-8ebf-057e7bae5287')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25d55bb1-b963-4cf0-8ebf-057e7bae5287 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25d55bb1-b963-4cf0-8ebf-057e7bae5287');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/devign-CodeVul/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7AhRWbqnWlv",
        "outputId": "144846c2-07e5-482c-e074-a5ab729f4974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devign-CodeVul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tech-srl/code2vec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiR5n2CGV5Au",
        "outputId": "84409e97-0fa1-42f5-daa4-f38e944f2471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'code2vec' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd code2vec/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6HaDV8gV8JE",
        "outputId": "e90b2b4f-c458-471d-a4b6-28c6abccd0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devign-CodeVul/code2vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/code2vec/model/java14m_model.tar.gz\n",
        "!tar -xvzf java14m_model.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syMasFzVp6Ya",
        "outputId": "402d8c49-1727-40fc-caaf-e8e78801aabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-26 23:09:25--  https://s3.amazonaws.com/code2vec/model/java14m_model.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.228.168, 52.216.213.232, 52.216.218.56, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.228.168|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1440921240 (1.3G) [application/x-tar]\n",
            "Saving to: ‘java14m_model.tar.gz’\n",
            "\n",
            "java14m_model.tar.g 100%[===================>]   1.34G  34.1MB/s    in 31s     \n",
            "\n",
            "2023-01-26 23:09:56 (44.8 MB/s) - ‘java14m_model.tar.gz’ saved [1440921240/1440921240]\n",
            "\n",
            "models/java14_model/saved_model_iter8.release.data-00000-of-00001\n",
            "models/java14_model/saved_model_iter8.release.index\n",
            "models/java14_model/saved_model_iter8.release.meta\n",
            "models/java14_model/dictionaries.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHQ1BoDdqJN4",
        "outputId": "a1f43be7-104e-4f2f-99ad-6d489f40401e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!clang -v\n",
        "!python -c\"import clang.cindex; import inspect; print(inspect.getfile(clang.cindex))\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGLoRE4Vq1gD",
        "outputId": "a0a5509a-bb21-4c24-c4ae-6febcbeb793b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang version 10.0.0-4ubuntu1 \n",
            "Target: x86_64-pc-linux-gnu\n",
            "Thread model: posix\n",
            "InstalledDir: /usr/bin\n",
            "Found candidate GCC installation: /usr/bin/../lib/gcc/x86_64-linux-gnu/9\n",
            "Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/9\n",
            "Selected GCC installation: /usr/bin/../lib/gcc/x86_64-linux-gnu/9\n",
            "Candidate multilib: .;@m64\n",
            "Selected multilib: .;@m64\n",
            "Found CUDA installation: /usr/local/cuda-11.2, version 7.0\n",
            "/usr/local/lib/python3.8/dist-packages/clang/cindex.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!awk --version\n",
        "!curl --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD60RPrNq66Q",
        "outputId": "29552160-c82b-4171-dfa1-982b28fa9e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "awk: not an option: --version\n",
            "curl 7.68.0 (x86_64-pc-linux-gnu) libcurl/7.68.0 OpenSSL/1.1.1f zlib/1.2.11 brotli/1.0.7 libidn2/2.2.0 libpsl/0.21.0 (+libidn2/2.2.0) libssh/0.9.3/openssl/zlib nghttp2/1.40.0 librtmp/2.3\n",
            "Release-Date: 2020-01-08\n",
            "Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtmp rtsp scp sftp smb smbs smtp smtps telnet tftp \n",
            "Features: AsynchDNS brotli GSS-API HTTP2 HTTPS-proxy IDN IPv6 Kerberos Largefile libz NTLM NTLM_WB PSL SPNEGO SSL TLS-SRP UnixSockets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rhLP7Gzrq-rr",
        "outputId": "81f9ef3b-3a22-44ba-e17f-e2fdab641ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/devign-CodeVul/code2vec'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AmeerHajAli/code2vec_c.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPzB13jvrUmt",
        "outputId": "e79f6818-e21d-4a7f-c70c-4619b8a0ad09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code2vec_c'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 26 (delta 3), reused 26 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), 44.49 KiB | 168.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsfInuvbrX6b",
        "outputId": "54cc8caa-d3fb-449d-ca89-558f9b1fabee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build_extractor.sh  Input.java\n",
            "CITATION.cff        interactive_predict.py\n",
            "\u001b[0m\u001b[01;34mcode2vec_c\u001b[0m/         \u001b[01;34mJavaExtractor\u001b[0m/\n",
            "code2vec.py         keras_attention_layer.py\n",
            "common.py           keras_checkpoint_saver_callback.py\n",
            "config.py           keras_model.py\n",
            "\u001b[01;34mCSharpExtractor\u001b[0m/    keras_topk_word_predictions_layer.py\n",
            "extractor.py        LICENSE\n",
            "\u001b[01;34mimages\u001b[0m/             README.md\n",
            "__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd code2vec_c/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6Mv3WvkjpyH",
        "outputId": "19ec94c8-01e0-4272-c507-5bed595f1f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'code2vec_c/'\n",
            "/content/drive/MyDrive/devign-CodeVul/code2vec/code2vec_c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qOqnSHjojsKY",
        "outputId": "ffc4dab4-cf2c-493c-bdd2-a66214ed6fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/devign-CodeVul/code2vec/code2vec_c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/devign-CodeVul/code2vec-code"
      ],
      "metadata": {
        "id": "nBaYase9z5Wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7b4a33-8d7e-467d-bc46-c7d5cdbd6bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devign-CodeVul/code2vec-code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-sd0jgTr-oq",
        "outputId": "7dd8e5dc-b053-4123-d6e0-e5eaa03c5d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/devign-CodeVul/code2vec-code/astminer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77CrxamdM1Z0",
        "outputId": "7a81fe69-9558-4986-f984-a263a0570b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devign-CodeVul/code2vec-code/astminer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./gradlew shadowJar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQqZnNzGpkLe",
        "outputId": "eadf37a9-dd42-4869-f61c-4c75948426d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Cell magic `%%!./gradlew` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDpbervdM7lg",
        "outputId": "f0726c1d-d4dd-420b-c01f-306f308c5e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dos2unix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHghxBvvw-e-",
        "outputId": "f6130ece-a624-48e9-d122-1388ebb1e63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dos2unix\n",
            "  Downloading dos2unix-1.zip (992 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: dos2unix\n",
            "  Building wheel for dos2unix (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dos2unix: filename=dos2unix-1-py3-none-any.whl size=1515 sha256=d6e91352b2a280ef1294ced7188dd17c38e453fd5bca91ddfc95e51dcb50f7ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/51/61/ed824be933dc079a669a77af99b90808edd35dbfb4b5bd22bf\n",
            "Successfully built dos2unix\n",
            "Installing collected packages: dos2unix\n",
            "Successfully installed dos2unix-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRNfwQuw7nV2",
        "outputId": "3b856c59-018b-4bda-a466-7e875cf70807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source preprocess.sh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABlNLpS37Mfx",
        "outputId": "bc636d11-0530-4b31-85ca-de8efe44a5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating histograms from the training data\n",
            "2023-02-16 23:49:21.957831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-16 23:49:22.833640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 23:49:22.833752: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 23:49:22.833773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "File: devign.test.raw.txt\n",
            "Average total contexts: 186.23955431754874\n",
            "Average final (after sampling) contexts: 186.23955431754874\n",
            "Total examples: 359\n",
            "Empty examples: 0\n",
            "Max number of contexts per word: 200\n",
            "File: devign.valid.raw.txt\n",
            "Average total contexts: 184.925\n",
            "Average final (after sampling) contexts: 184.925\n",
            "Total examples: 520\n",
            "Empty examples: 0\n",
            "Max number of contexts per word: 200\n",
            "File: devign.train.raw.txt\n",
            "Average total contexts: 188.75527426160338\n",
            "Average final (after sampling) contexts: 188.75527426160338\n",
            "Total examples: 237\n",
            "Empty examples: 0\n",
            "Max number of contexts per word: 200\n",
            "Dictionaries saved to: data/devign/devign.dict.c2v\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffLSMsd4OuED",
        "outputId": "0a3331d6-366d-45d0-e588-f021f54948be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " code2vec.py            \u001b[0m\u001b[01;34mimages\u001b[0m/                  prediction_outputter.py\n",
            " common.py              __init__.py              preprocess.py\n",
            " config.py              input.js                 preprocess.sh\n",
            " \u001b[01;34mdata\u001b[0m/                  interactive_predict.py   \u001b[01;34m__pycache__\u001b[0m/\n",
            "\u001b[01;34m'data'$'\\r'\u001b[0m/            LICENSE                  README.md\n",
            " devign.test.raw.txt    log.txt                  requirements.txt\n",
            " devign.train.raw.txt   model_base.py            tensorflow_model.py\n",
            " devign.valid.raw.txt   \u001b[01;34mmodels\u001b[0m/                  train.sh\n",
            " extractor_js.py        path_context_reader.py   vocabularies.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source train.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h61kQtDmxMim",
        "outputId": "311dbe3d-1929-4d7b-f8b9-03b93abd8644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-06 18:20:50,450 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:20:50,450 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-06 18:20:50,450 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:20:50,450 INFO     Checking number of examples ...\n",
            "2023-02-06 18:20:50,459 INFO         Number of train examples: 237\n",
            "2023-02-06 18:20:50,459 INFO     Path: data/devign/devign.val.c2v\n",
            "2023-02-06 18:20:50,472 INFO         Number of test examples: 520\n",
            "2023-02-06 18:20:50,472 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:20:50,472 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-06 18:20:50,472 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-06 18:20:50,472 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-06 18:20:50,473 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-06 18:20:50,473 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-06 18:20:50,473 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-06 18:20:50,473 INFO     EXPORT_CODE_VECTORS                       False\n",
            "2023-02-06 18:20:50,473 INFO     LOGS_PATH                                 None\n",
            "2023-02-06 18:20:50,473 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-06 18:20:50,473 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-06 18:20:50,473 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-06 18:20:50,473 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-06 18:20:50,473 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-06 18:20:50,473 INFO     MODEL_LOAD_PATH                           None\n",
            "2023-02-06 18:20:50,473 INFO     MODEL_SAVE_PATH                           models/devign/saved_model\n",
            "2023-02-06 18:20:50,473 INFO     NEGATIVE                                  safe\n",
            "2023-02-06 18:20:50,473 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-06 18:20:50,473 INFO     NUM_TEST_EXAMPLES                         520\n",
            "2023-02-06 18:20:50,473 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-06 18:20:50,473 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-06 18:20:50,473 INFO     NUM_TRAIN_EXAMPLES                        237\n",
            "2023-02-06 18:20:50,473 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-06 18:20:50,473 INFO     POSITIVE                                  vuln\n",
            "2023-02-06 18:20:50,473 INFO     PREDICT                                   False\n",
            "2023-02-06 18:20:50,473 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-06 18:20:50,473 INFO     RELEASE                                   False\n",
            "2023-02-06 18:20:50,473 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-06 18:20:50,473 INFO     SAVE_T2V                                  None\n",
            "2023-02-06 18:20:50,473 INFO     SAVE_W2V                                  None\n",
            "2023-02-06 18:20:50,473 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-06 18:20:50,473 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-06 18:20:50,473 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-06 18:20:50,473 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-06 18:20:50,474 INFO     TEST_DATA_PATH                            data/devign/devign.val.c2v\n",
            "2023-02-06 18:20:50,474 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-06 18:20:50,474 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-06 18:20:50,474 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-06 18:20:50,474 INFO     TRAIN_DATA_PATH_PREFIX                    data/devign/devign\n",
            "2023-02-06 18:20:50,474 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-06 18:20:50,474 INFO     VERBOSE_MODE                              1\n",
            "2023-02-06 18:20:50,474 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-06 18:20:50,474 INFO     context_vector_size                       384\n",
            "2023-02-06 18:20:50,474 INFO     entire_model_load_path                    None\n",
            "2023-02-06 18:20:50,474 INFO     entire_model_save_path                    models/devign/saved_model__entire-model\n",
            "2023-02-06 18:20:50,474 INFO     is_loading                                False\n",
            "2023-02-06 18:20:50,474 INFO     is_saving                                 True\n",
            "2023-02-06 18:20:50,474 INFO     is_testing                                True\n",
            "2023-02-06 18:20:50,474 INFO     is_training                               True\n",
            "2023-02-06 18:20:50,474 INFO     model_load_dir                            None\n",
            "2023-02-06 18:20:50,474 INFO     model_weights_load_path                   None\n",
            "2023-02-06 18:20:50,474 INFO     model_weights_save_path                   models/devign/saved_model__only-weights\n",
            "2023-02-06 18:20:50,474 INFO     test_steps                                1\n",
            "2023-02-06 18:20:50,474 INFO     train_data_path                           data/devign/devign.train.c2v\n",
            "2023-02-06 18:20:50,474 INFO     train_steps_per_epoch                     1\n",
            "2023-02-06 18:20:50,474 INFO     word_freq_dict_path                       data/devign/devign.dict.c2v\n",
            "2023-02-06 18:20:50,474 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:20:50,474 INFO     Loading word frequencies dictionaries from: data/devign/devign.dict.c2v ... \n",
            "2023-02-06 18:20:50,478 INFO     Done loading word frequencies dictionaries.\n",
            "2023-02-06 18:20:50,478 INFO     Word frequencies dictionaries loaded. Now creating vocabularies.\n",
            "2023-02-06 18:20:50,479 INFO     Created token vocab. size: 2778\n",
            "2023-02-06 18:20:50,482 INFO     Created path vocab. size: 10187\n",
            "2023-02-06 18:20:50,482 INFO     Created target vocab. size: 3\n",
            "2023-02-06 18:20:50,492 INFO     Done creating code2vec model\n",
            "2023-02-06 18:20:50,492 INFO     Starting training\n",
            "2023-02-06 18:20:51,375 INFO     Number of trainable params: 1808512\n",
            "2023-02-06 18:20:51,375 INFO     variable name: model/WORDS_VOCAB:0 -- shape: (2778, 128) -- #params: 355584\n",
            "2023-02-06 18:20:51,375 INFO     variable name: model/TARGET_WORDS_VOCAB:0 -- shape: (3, 384) -- #params: 1152\n",
            "2023-02-06 18:20:51,375 INFO     variable name: model/ATTENTION:0 -- shape: (384, 1) -- #params: 384\n",
            "2023-02-06 18:20:51,376 INFO     variable name: model/PATHS_VOCAB:0 -- shape: (10187, 128) -- #params: 1303936\n",
            "2023-02-06 18:20:51,376 INFO     variable name: model/TRANSFORM:0 -- shape: (384, 384) -- #params: 147456\n",
            "2023-02-06 18:20:51,613 INFO     Initalized variables\n",
            "2023-02-06 18:20:52,762 INFO     Started reader...\n",
            "2023-02-06 18:20:56,243 INFO     Saved after 1 epochs in: models/devign/saved_model_iter1\n",
            "2023-02-06 18:20:57,454 INFO     Starting evaluation\n",
            "2023-02-06 18:20:57,926 INFO     Done evaluating, epoch reached\n",
            "2023-02-06 18:20:57,927 INFO     Evaluation time: 0H:0M:1S\n",
            "2023-02-06 18:20:57,928 INFO     After 1 epochs -- Precision: 0.4524793388429752, Sensitivity/Recall: 0.9279661016949152, Accuracy: 0.45664739884393063, Error Rate: 0.5433526011560693, F1: 0.6083333333333333, #TPs=219, #TNs=18, #FPs=265, #FNs=17, TNR=0.0636042402826855, FPR=0.9363957597173145\n",
            "2023-02-06 18:20:58,203 INFO     Saved after 2 epochs in: models/devign/saved_model_iter2\n",
            "2023-02-06 18:20:58,285 INFO     Starting evaluation\n",
            "2023-02-06 18:20:58,492 INFO     Done evaluating, epoch reached\n",
            "2023-02-06 18:20:58,493 INFO     Evaluation time: 0H:0M:0S\n",
            "2023-02-06 18:20:58,494 INFO     After 2 epochs -- Precision: 0.44842105263157894, Sensitivity/Recall: 0.902542372881356, Accuracy: 0.4508670520231214, Error Rate: 0.5491329479768786, F1: 0.59915611814346, #TPs=213, #TNs=21, #FPs=262, #FNs=23, TNR=0.07420494699646643, FPR=0.9257950530035336\n",
            "2023-02-06 18:20:58,744 INFO     Saved after 3 epochs in: models/devign/saved_model_iter3\n",
            "2023-02-06 18:20:58,839 INFO     Starting evaluation\n",
            "2023-02-06 18:20:59,039 INFO     Done evaluating, epoch reached\n",
            "2023-02-06 18:20:59,040 INFO     Evaluation time: 0H:0M:0S\n",
            "2023-02-06 18:20:59,041 INFO     After 3 epochs -- Precision: 0.44782608695652176, Sensitivity/Recall: 0.8728813559322034, Accuracy: 0.4527938342967245, Error Rate: 0.5472061657032755, F1: 0.5919540229885059, #TPs=206, #TNs=29, #FPs=254, #FNs=30, TNR=0.10247349823321555, FPR=0.8975265017667845\n",
            "2023-02-06 18:20:59,305 INFO     Saved after 4 epochs in: models/devign/saved_model_iter4\n",
            "2023-02-06 18:20:59,388 INFO     Starting evaluation\n",
            "2023-02-06 18:20:59,573 INFO     Done evaluating, epoch reached\n",
            "2023-02-06 18:20:59,574 INFO     Evaluation time: 0H:0M:0S\n",
            "2023-02-06 18:20:59,575 INFO     After 4 epochs -- Precision: 0.4467120181405896, Sensitivity/Recall: 0.8347457627118644, Accuracy: 0.45472061657032753, Error Rate: 0.5452793834296724, F1: 0.5819793205317578, #TPs=197, #TNs=39, #FPs=244, #FNs=39, TNR=0.13780918727915195, FPR=0.8621908127208481\n",
            "2023-02-06 18:20:59,847 INFO     Saved after 5 epochs in: models/devign/saved_model_iter5\n",
            "2023-02-06 18:20:59,941 INFO     Starting evaluation\n",
            "2023-02-06 18:21:00,146 INFO     Done evaluating, epoch reached\n",
            "2023-02-06 18:21:00,147 INFO     Evaluation time: 0H:0M:0S\n",
            "2023-02-06 18:21:00,148 INFO     After 5 epochs -- Precision: 0.44554455445544555, Sensitivity/Recall: 0.7627118644067796, Accuracy: 0.4605009633911368, Error Rate: 0.5394990366088632, F1: 0.5625, #TPs=180, #TNs=59, #FPs=224, #FNs=56, TNR=0.20848056537102475, FPR=0.7915194346289752\n",
            "2023-02-06 18:21:00,151 INFO     Done training\n",
            "2023-02-06 18:21:00,290 INFO     Model saved in file: models/devign/saved_model\n",
            "2023-02-06 18:21:00,290 INFO     Training time: 0H:0M:9S\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !python3 code2vec.py --load models/devign/saved_model_iter5 --release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhMX3jVl9X8Q",
        "outputId": "c05ff016-84b1-4a5c-b367-a6b7277bf68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-06 18:22:07,994 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:22:07,994 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-06 18:22:07,994 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:22:07,994 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:22:07,994 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-06 18:22:07,995 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-06 18:22:07,995 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-06 18:22:07,995 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-06 18:22:07,995 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-06 18:22:07,995 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-06 18:22:07,995 INFO     EXPORT_CODE_VECTORS                       False\n",
            "2023-02-06 18:22:07,995 INFO     LOGS_PATH                                 None\n",
            "2023-02-06 18:22:07,995 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-06 18:22:07,995 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-06 18:22:07,995 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-06 18:22:07,995 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-06 18:22:07,995 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-06 18:22:07,995 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5\n",
            "2023-02-06 18:22:07,995 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-06 18:22:07,995 INFO     NEGATIVE                                  safe\n",
            "2023-02-06 18:22:07,995 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-06 18:22:07,995 INFO     NUM_TEST_EXAMPLES                         0\n",
            "2023-02-06 18:22:07,995 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-06 18:22:07,995 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-06 18:22:07,995 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-06 18:22:07,995 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-06 18:22:07,995 INFO     POSITIVE                                  vuln\n",
            "2023-02-06 18:22:07,995 INFO     PREDICT                                   False\n",
            "2023-02-06 18:22:07,995 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-06 18:22:07,995 INFO     RELEASE                                   True\n",
            "2023-02-06 18:22:07,995 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-06 18:22:07,995 INFO     SAVE_T2V                                  None\n",
            "2023-02-06 18:22:07,996 INFO     SAVE_W2V                                  None\n",
            "2023-02-06 18:22:07,996 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-06 18:22:07,996 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-06 18:22:07,996 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-06 18:22:07,996 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-06 18:22:07,996 INFO     TEST_DATA_PATH                            \n",
            "2023-02-06 18:22:07,996 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-06 18:22:07,996 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-06 18:22:07,996 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-06 18:22:07,996 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-06 18:22:07,996 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-06 18:22:07,996 INFO     VERBOSE_MODE                              1\n",
            "2023-02-06 18:22:07,996 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-06 18:22:07,996 INFO     context_vector_size                       384\n",
            "2023-02-06 18:22:07,996 INFO     entire_model_load_path                    models/devign/saved_model_iter5__entire-model\n",
            "2023-02-06 18:22:07,996 INFO     entire_model_save_path                    None\n",
            "2023-02-06 18:22:07,996 INFO     is_loading                                True\n",
            "2023-02-06 18:22:07,996 INFO     is_saving                                 False\n",
            "2023-02-06 18:22:07,996 INFO     is_testing                                False\n",
            "2023-02-06 18:22:07,996 INFO     is_training                               False\n",
            "2023-02-06 18:22:07,996 INFO     model_load_dir                            models/devign\n",
            "2023-02-06 18:22:07,996 INFO     model_weights_load_path                   models/devign/saved_model_iter5__only-weights\n",
            "2023-02-06 18:22:07,996 INFO     model_weights_save_path                   None\n",
            "2023-02-06 18:22:07,996 INFO     test_steps                                0\n",
            "2023-02-06 18:22:07,996 INFO     train_data_path                           None\n",
            "2023-02-06 18:22:07,996 INFO     train_steps_per_epoch                     0\n",
            "2023-02-06 18:22:07,996 INFO     word_freq_dict_path                       None\n",
            "2023-02-06 18:22:07,997 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:22:07,997 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-06 18:22:08,005 INFO     Done loading model vocabularies.\n",
            "2023-02-06 18:22:08,008 INFO     Done creating code2vec model\n",
            "DEBUG: Evaluating...\n",
            "2023-02-06 18:22:08,769 INFO     Initalized variables\n",
            "2023-02-06 18:22:08,769 INFO     Loading model weights from: models/devign/saved_model_iter5\n",
            "2023-02-06 18:22:08,810 INFO     Done loading model weights\n",
            "2023-02-06 18:22:08,810 INFO     Releasing model, output model: models/devign/saved_model_iter5.release\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code2vec.py --load models/devign/saved_model_iter5.release --test data/devign/devign.test.c2v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn6yUVfd9qFD",
        "outputId": "ff9b0bc6-31d7-4674-8177-454b803f4992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-06 18:23:18,222 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:23:18,222 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-06 18:23:18,222 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:23:18,222 INFO     Checking number of examples ...\n",
            "2023-02-06 18:23:18,222 INFO     Path: data/devign/devign.test.c2v\n",
            "2023-02-06 18:23:18,224 INFO         Number of test examples: 359\n",
            "2023-02-06 18:23:18,224 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:23:18,224 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-06 18:23:18,224 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-06 18:23:18,224 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-06 18:23:18,224 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-06 18:23:18,224 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-06 18:23:18,224 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-06 18:23:18,224 INFO     EXPORT_CODE_VECTORS                       False\n",
            "2023-02-06 18:23:18,224 INFO     LOGS_PATH                                 None\n",
            "2023-02-06 18:23:18,224 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-06 18:23:18,224 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-06 18:23:18,224 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-06 18:23:18,224 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-06 18:23:18,224 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-06 18:23:18,224 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5.release\n",
            "2023-02-06 18:23:18,224 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-06 18:23:18,225 INFO     NEGATIVE                                  safe\n",
            "2023-02-06 18:23:18,225 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-06 18:23:18,225 INFO     NUM_TEST_EXAMPLES                         359\n",
            "2023-02-06 18:23:18,225 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-06 18:23:18,225 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-06 18:23:18,225 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-06 18:23:18,225 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-06 18:23:18,225 INFO     POSITIVE                                  vuln\n",
            "2023-02-06 18:23:18,225 INFO     PREDICT                                   False\n",
            "2023-02-06 18:23:18,225 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-06 18:23:18,225 INFO     RELEASE                                   False\n",
            "2023-02-06 18:23:18,225 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-06 18:23:18,225 INFO     SAVE_T2V                                  None\n",
            "2023-02-06 18:23:18,225 INFO     SAVE_W2V                                  None\n",
            "2023-02-06 18:23:18,225 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-06 18:23:18,225 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-06 18:23:18,225 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-06 18:23:18,225 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-06 18:23:18,225 INFO     TEST_DATA_PATH                            data/devign/devign.test.c2v\n",
            "2023-02-06 18:23:18,225 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-06 18:23:18,225 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-06 18:23:18,225 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-06 18:23:18,225 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-06 18:23:18,225 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-06 18:23:18,225 INFO     VERBOSE_MODE                              1\n",
            "2023-02-06 18:23:18,225 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-06 18:23:18,225 INFO     context_vector_size                       384\n",
            "2023-02-06 18:23:18,225 INFO     entire_model_load_path                    models/devign/saved_model_iter5.release__entire-model\n",
            "2023-02-06 18:23:18,226 INFO     entire_model_save_path                    None\n",
            "2023-02-06 18:23:18,226 INFO     is_loading                                True\n",
            "2023-02-06 18:23:18,226 INFO     is_saving                                 False\n",
            "2023-02-06 18:23:18,226 INFO     is_testing                                True\n",
            "2023-02-06 18:23:18,226 INFO     is_training                               False\n",
            "2023-02-06 18:23:18,226 INFO     model_load_dir                            models/devign\n",
            "2023-02-06 18:23:18,226 INFO     model_weights_load_path                   models/devign/saved_model_iter5.release__only-weights\n",
            "2023-02-06 18:23:18,226 INFO     model_weights_save_path                   None\n",
            "2023-02-06 18:23:18,226 INFO     test_steps                                1\n",
            "2023-02-06 18:23:18,226 INFO     train_data_path                           None\n",
            "2023-02-06 18:23:18,226 INFO     train_steps_per_epoch                     0\n",
            "2023-02-06 18:23:18,226 INFO     word_freq_dict_path                       None\n",
            "2023-02-06 18:23:18,226 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:23:18,226 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-06 18:23:18,235 INFO     Done loading model vocabularies.\n",
            "2023-02-06 18:23:18,239 INFO     Done creating code2vec model\n",
            "DEBUG: Evaluating...\n",
            "2023-02-06 18:23:18,968 INFO     Initalized variables\n",
            "2023-02-06 18:23:18,968 INFO     Loading model weights from: models/devign/saved_model_iter5.release\n",
            "2023-02-06 18:23:19,002 INFO     Done loading model weights\n",
            "2023-02-06 18:23:19,145 INFO     Starting evaluation\n",
            "2023-02-06 18:23:20,008 INFO     Done evaluating, epoch reached\n",
            "2023-02-06 18:23:20,009 INFO     Evaluation time: 0H:0M:1S\n",
            "2023-02-06 18:23:20,010 INFO     Precision: 0.5925925925925926, Sensitivity/Recall: 0.7804878048780488, Accuracy: 0.5658263305322129, Error Rate: 0.4341736694677871, F1: 0.6736842105263158, #TPs=160, #TNs=42, #FPs=110, #FNs=45, TNR=0.27631578947368424, FPR=0.7236842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Precision: 0.5925925925925926, Sensitivity/Recall: 0.7804878048780488, Accuracy: 0.5658263305322129, Error Rate: 0.4341736694677871, F1: 0.6736842105263158, #TPs=160, #TNs=42, #FPs=110, #FNs=45, TNR=0.27631578947368424, FPR=0.7236842105263158\n"
      ],
      "metadata": {
        "id": "E6QTYEQQHzWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code2vec.py --load models/devign/saved_model_iter5.release --save_w2v models/embeddings/tokens.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAlyZeP09wIQ",
        "outputId": "c7d1db14-5b73-409e-a99d-3d8fda5cd0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-06 18:26:11,192 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:26:11,193 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-06 18:26:11,193 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:26:11,193 INFO     Checking number of examples ...\n",
            "2023-02-06 18:26:11,193 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:26:11,193 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-06 18:26:11,193 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-06 18:26:11,193 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-06 18:26:11,193 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-06 18:26:11,193 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-06 18:26:11,193 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-06 18:26:11,193 INFO     EXPORT_CODE_VECTORS                       False\n",
            "2023-02-06 18:26:11,193 INFO     LOGS_PATH                                 None\n",
            "2023-02-06 18:26:11,193 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-06 18:26:11,193 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-06 18:26:11,193 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-06 18:26:11,194 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-06 18:26:11,194 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-06 18:26:11,194 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5.release\n",
            "2023-02-06 18:26:11,194 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-06 18:26:11,194 INFO     NEGATIVE                                  safe\n",
            "2023-02-06 18:26:11,194 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-06 18:26:11,194 INFO     NUM_TEST_EXAMPLES                         0\n",
            "2023-02-06 18:26:11,194 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-06 18:26:11,194 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-06 18:26:11,194 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-06 18:26:11,194 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-06 18:26:11,194 INFO     POSITIVE                                  vuln\n",
            "2023-02-06 18:26:11,194 INFO     PREDICT                                   False\n",
            "2023-02-06 18:26:11,194 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-06 18:26:11,194 INFO     RELEASE                                   False\n",
            "2023-02-06 18:26:11,195 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-06 18:26:11,195 INFO     SAVE_T2V                                  None\n",
            "2023-02-06 18:26:11,195 INFO     SAVE_W2V                                  models/embeddings/tokens.txt\n",
            "2023-02-06 18:26:11,195 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-06 18:26:11,195 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-06 18:26:11,195 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-06 18:26:11,195 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-06 18:26:11,195 INFO     TEST_DATA_PATH                            \n",
            "2023-02-06 18:26:11,195 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-06 18:26:11,195 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-06 18:26:11,195 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-06 18:26:11,195 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-06 18:26:11,195 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-06 18:26:11,195 INFO     VERBOSE_MODE                              1\n",
            "2023-02-06 18:26:11,195 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-06 18:26:11,195 INFO     context_vector_size                       384\n",
            "2023-02-06 18:26:11,195 INFO     entire_model_load_path                    models/devign/saved_model_iter5.release__entire-model\n",
            "2023-02-06 18:26:11,195 INFO     entire_model_save_path                    None\n",
            "2023-02-06 18:26:11,195 INFO     is_loading                                True\n",
            "2023-02-06 18:26:11,195 INFO     is_saving                                 False\n",
            "2023-02-06 18:26:11,195 INFO     is_testing                                False\n",
            "2023-02-06 18:26:11,195 INFO     is_training                               False\n",
            "2023-02-06 18:26:11,196 INFO     model_load_dir                            models/devign\n",
            "2023-02-06 18:26:11,196 INFO     model_weights_load_path                   models/devign/saved_model_iter5.release__only-weights\n",
            "2023-02-06 18:26:11,196 INFO     model_weights_save_path                   None\n",
            "2023-02-06 18:26:11,196 INFO     test_steps                                0\n",
            "2023-02-06 18:26:11,196 INFO     train_data_path                           None\n",
            "2023-02-06 18:26:11,196 INFO     train_steps_per_epoch                     0\n",
            "2023-02-06 18:26:11,196 INFO     word_freq_dict_path                       None\n",
            "2023-02-06 18:26:11,196 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:26:11,196 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-06 18:26:11,206 INFO     Done loading model vocabularies.\n",
            "2023-02-06 18:26:11,210 INFO     Done creating code2vec model\n",
            "2023-02-06 18:26:11,923 INFO     Initalized variables\n",
            "2023-02-06 18:26:11,923 INFO     Loading model weights from: models/devign/saved_model_iter5.release\n",
            "2023-02-06 18:26:11,955 INFO     Done loading model weights\n",
            "2023-02-06 18:26:12,181 INFO     Origin word vectors saved in word2vec text format in: models/embeddings/tokens.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code2vec.py --load models/devign/saved_model_iter5.release --save_t2v models/embeddings/targets.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1Y6ZPg--au-",
        "outputId": "c8cc9b7b-7484-4be0-ddcf-786ebb090c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-06 18:28:47,522 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:28:47,522 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-06 18:28:47,523 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:28:47,523 INFO     Checking number of examples ...\n",
            "2023-02-06 18:28:47,523 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:28:47,523 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-06 18:28:47,523 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-06 18:28:47,523 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-06 18:28:47,523 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-06 18:28:47,523 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-06 18:28:47,523 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-06 18:28:47,523 INFO     EXPORT_CODE_VECTORS                       False\n",
            "2023-02-06 18:28:47,523 INFO     LOGS_PATH                                 None\n",
            "2023-02-06 18:28:47,523 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-06 18:28:47,523 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-06 18:28:47,523 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-06 18:28:47,523 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-06 18:28:47,523 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-06 18:28:47,523 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5.release\n",
            "2023-02-06 18:28:47,523 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-06 18:28:47,523 INFO     NEGATIVE                                  safe\n",
            "2023-02-06 18:28:47,523 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-06 18:28:47,523 INFO     NUM_TEST_EXAMPLES                         0\n",
            "2023-02-06 18:28:47,523 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-06 18:28:47,524 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-06 18:28:47,524 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-06 18:28:47,524 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-06 18:28:47,524 INFO     POSITIVE                                  vuln\n",
            "2023-02-06 18:28:47,524 INFO     PREDICT                                   False\n",
            "2023-02-06 18:28:47,524 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-06 18:28:47,524 INFO     RELEASE                                   False\n",
            "2023-02-06 18:28:47,524 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-06 18:28:47,524 INFO     SAVE_T2V                                  models/embeddings/targets.txt\n",
            "2023-02-06 18:28:47,524 INFO     SAVE_W2V                                  None\n",
            "2023-02-06 18:28:47,524 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-06 18:28:47,524 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-06 18:28:47,524 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-06 18:28:47,524 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-06 18:28:47,524 INFO     TEST_DATA_PATH                            \n",
            "2023-02-06 18:28:47,524 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-06 18:28:47,524 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-06 18:28:47,524 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-06 18:28:47,524 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-06 18:28:47,524 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-06 18:28:47,524 INFO     VERBOSE_MODE                              1\n",
            "2023-02-06 18:28:47,524 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-06 18:28:47,524 INFO     context_vector_size                       384\n",
            "2023-02-06 18:28:47,524 INFO     entire_model_load_path                    models/devign/saved_model_iter5.release__entire-model\n",
            "2023-02-06 18:28:47,524 INFO     entire_model_save_path                    None\n",
            "2023-02-06 18:28:47,524 INFO     is_loading                                True\n",
            "2023-02-06 18:28:47,524 INFO     is_saving                                 False\n",
            "2023-02-06 18:28:47,524 INFO     is_testing                                False\n",
            "2023-02-06 18:28:47,524 INFO     is_training                               False\n",
            "2023-02-06 18:28:47,525 INFO     model_load_dir                            models/devign\n",
            "2023-02-06 18:28:47,525 INFO     model_weights_load_path                   models/devign/saved_model_iter5.release__only-weights\n",
            "2023-02-06 18:28:47,525 INFO     model_weights_save_path                   None\n",
            "2023-02-06 18:28:47,525 INFO     test_steps                                0\n",
            "2023-02-06 18:28:47,525 INFO     train_data_path                           None\n",
            "2023-02-06 18:28:47,525 INFO     train_steps_per_epoch                     0\n",
            "2023-02-06 18:28:47,525 INFO     word_freq_dict_path                       None\n",
            "2023-02-06 18:28:47,525 INFO     ---------------------------------------------------------------------\n",
            "2023-02-06 18:28:47,525 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-06 18:28:47,534 INFO     Done loading model vocabularies.\n",
            "2023-02-06 18:28:47,538 INFO     Done creating code2vec model\n",
            "2023-02-06 18:28:48,328 INFO     Initalized variables\n",
            "2023-02-06 18:28:48,329 INFO     Loading model weights from: models/devign/saved_model_iter5.release\n",
            "2023-02-06 18:28:48,362 INFO     Done loading model weights\n",
            "2023-02-06 18:28:48,380 INFO     Target word vectors saved in word2vec text format in: models/embeddings/targets.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HFP11xCF_EFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python code2vec.py --load models/devign/saved_model_iter5.release --predict --export_code_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO44jZ6R9Te3",
        "outputId": "2d541275-f6a0-4098-915e-a9c1978e846c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-08 17:52:38,337 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 17:52:38,337 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-08 17:52:38,337 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 17:52:38,337 INFO     Checking number of examples ...\n",
            "2023-02-08 17:52:38,337 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 17:52:38,337 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-08 17:52:38,337 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-08 17:52:38,337 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-08 17:52:38,337 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-08 17:52:38,337 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-08 17:52:38,337 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-08 17:52:38,337 INFO     EXPORT_CODE_VECTORS                       True\n",
            "2023-02-08 17:52:38,338 INFO     LOGS_PATH                                 None\n",
            "2023-02-08 17:52:38,338 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-08 17:52:38,338 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-08 17:52:38,338 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-08 17:52:38,338 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-08 17:52:38,338 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-08 17:52:38,338 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5.release\n",
            "2023-02-08 17:52:38,338 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-08 17:52:38,338 INFO     NEGATIVE                                  safe\n",
            "2023-02-08 17:52:38,338 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-08 17:52:38,338 INFO     NUM_TEST_EXAMPLES                         0\n",
            "2023-02-08 17:52:38,338 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-08 17:52:38,338 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-08 17:52:38,338 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-08 17:52:38,338 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-08 17:52:38,338 INFO     POSITIVE                                  vuln\n",
            "2023-02-08 17:52:38,338 INFO     PREDICT                                   True\n",
            "2023-02-08 17:52:38,338 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-08 17:52:38,338 INFO     RELEASE                                   False\n",
            "2023-02-08 17:52:38,338 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-08 17:52:38,338 INFO     SAVE_T2V                                  None\n",
            "2023-02-08 17:52:38,338 INFO     SAVE_W2V                                  None\n",
            "2023-02-08 17:52:38,338 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-08 17:52:38,338 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-08 17:52:38,338 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-08 17:52:38,338 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-08 17:52:38,338 INFO     TEST_DATA_PATH                            \n",
            "2023-02-08 17:52:38,338 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-08 17:52:38,339 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-08 17:52:38,339 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-08 17:52:38,339 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-08 17:52:38,339 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-08 17:52:38,339 INFO     VERBOSE_MODE                              1\n",
            "2023-02-08 17:52:38,339 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-08 17:52:38,339 INFO     context_vector_size                       384\n",
            "2023-02-08 17:52:38,339 INFO     entire_model_load_path                    models/devign/saved_model_iter5.release__entire-model\n",
            "2023-02-08 17:52:38,339 INFO     entire_model_save_path                    None\n",
            "2023-02-08 17:52:38,339 INFO     is_loading                                True\n",
            "2023-02-08 17:52:38,339 INFO     is_saving                                 False\n",
            "2023-02-08 17:52:38,339 INFO     is_testing                                False\n",
            "2023-02-08 17:52:38,339 INFO     is_training                               False\n",
            "2023-02-08 17:52:38,339 INFO     model_load_dir                            models/devign\n",
            "2023-02-08 17:52:38,339 INFO     model_weights_load_path                   models/devign/saved_model_iter5.release__only-weights\n",
            "2023-02-08 17:52:38,339 INFO     model_weights_save_path                   None\n",
            "2023-02-08 17:52:38,339 INFO     test_steps                                0\n",
            "2023-02-08 17:52:38,339 INFO     train_data_path                           None\n",
            "2023-02-08 17:52:38,339 INFO     train_steps_per_epoch                     0\n",
            "2023-02-08 17:52:38,339 INFO     word_freq_dict_path                       None\n",
            "2023-02-08 17:52:38,339 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 17:52:38,340 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-08 17:52:38,348 INFO     Done loading model vocabularies.\n",
            "2023-02-08 17:52:38,351 INFO     Done creating code2vec model\n",
            "2023-02-08 17:52:39,330 INFO     Initalized variables\n",
            "2023-02-08 17:52:39,343 INFO     Loading model weights from: models/devign/saved_model_iter5.release\n",
            "2023-02-08 17:52:39,420 INFO     Done loading model weights\n",
            "Starting interactive prediction...\n",
            "Modify the file: \"input.js\" and press any key when ready, or \"q\" / \"quit\" / \"exit\" to exit\n",
            " \n",
            "[]\n",
            "internal/modules/cjs/loader.js:883\n",
            "  throw err;\n",
            "  ^\n",
            "\n",
            "Error: Cannot find module '/content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/JSExtractor/build/index.js'\n",
            "    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:880:15)\n",
            "    at Function.Module._load (internal/modules/cjs/loader.js:725:27)\n",
            "    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:72:12)\n",
            "    at internal/main/run_main_module.js:17:47 {\n",
            "  code: 'MODULE_NOT_FOUND',\n",
            "  requireStack: []\n",
            "}\n",
            "\n",
            "Modify the file: \"input.js\" and press any key when ready, or \"q\" / \"quit\" / \"exit\" to exit\n",
            " \n",
            "[]\n",
            "internal/modules/cjs/loader.js:883\n",
            "  throw err;\n",
            "  ^\n",
            "\n",
            "Error: Cannot find module '/content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/JSExtractor/build/index.js'\n",
            "    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:880:15)\n",
            "    at Function.Module._load (internal/modules/cjs/loader.js:725:27)\n",
            "    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:72:12)\n",
            "    at internal/main/run_main_module.js:17:47 {\n",
            "  code: 'MODULE_NOT_FOUND',\n",
            "  requireStack: []\n",
            "}\n",
            "\n",
            "Modify the file: \"input.js\" and press any key when ready, or \"q\" / \"quit\" / \"exit\" to exit\n",
            "q\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python prediction_outputter.py --load models/devign/saved_model_iter5.release --predict --export_code_vectors\n",
        "# or your chosen iteration\n",
        "# !python /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/prediction_outputter.py -a /content/drive/MyDrive/devign-CodeVul/code2vec-code/astminer/dataset/test.jsonl -p models/devign/saved_model_iter5.release "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSzEdkka_IKh",
        "outputId": "4d43d573-9723-4c13-d8bd-09845daf25a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-08 17:13:14.621146: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-02-08 17:13:14,622 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 17:13:14,622 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-08 17:13:14,622 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 17:13:14,622 INFO     Checking number of examples ...\n",
            "2023-02-08 17:13:14,622 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 17:13:14,622 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-08 17:13:14,622 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-08 17:13:14,622 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-08 17:13:14,622 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-08 17:13:14,622 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-08 17:13:14,623 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-08 17:13:14,623 INFO     EXPORT_CODE_VECTORS                       True\n",
            "2023-02-08 17:13:14,623 INFO     LOGS_PATH                                 None\n",
            "2023-02-08 17:13:14,623 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-08 17:13:14,623 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-08 17:13:14,623 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-08 17:13:14,623 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-08 17:13:14,623 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-08 17:13:14,623 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5.release\n",
            "2023-02-08 17:13:14,623 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-08 17:13:14,623 INFO     NEGATIVE                                  safe\n",
            "2023-02-08 17:13:14,623 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-08 17:13:14,623 INFO     NUM_TEST_EXAMPLES                         0\n",
            "2023-02-08 17:13:14,623 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-08 17:13:14,623 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-08 17:13:14,623 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-08 17:13:14,623 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-08 17:13:14,623 INFO     POSITIVE                                  vuln\n",
            "2023-02-08 17:13:14,623 INFO     PREDICT                                   True\n",
            "2023-02-08 17:13:14,623 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-08 17:13:14,623 INFO     RELEASE                                   False\n",
            "2023-02-08 17:13:14,623 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-08 17:13:14,623 INFO     SAVE_T2V                                  None\n",
            "2023-02-08 17:13:14,623 INFO     SAVE_W2V                                  None\n",
            "2023-02-08 17:13:14,623 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-08 17:13:14,623 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-08 17:13:14,623 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-08 17:13:14,623 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-08 17:13:14,624 INFO     TEST_DATA_PATH                            \n",
            "2023-02-08 17:13:14,624 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-08 17:13:14,624 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-08 17:13:14,624 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-08 17:13:14,624 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-08 17:13:14,624 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-08 17:13:14,624 INFO     VERBOSE_MODE                              1\n",
            "2023-02-08 17:13:14,624 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-08 17:13:14,624 INFO     context_vector_size                       384\n",
            "2023-02-08 17:13:14,624 INFO     entire_model_load_path                    models/devign/saved_model_iter5.release__entire-model\n",
            "2023-02-08 17:13:14,624 INFO     entire_model_save_path                    None\n",
            "2023-02-08 17:13:14,624 INFO     is_loading                                True\n",
            "2023-02-08 17:13:14,624 INFO     is_saving                                 False\n",
            "2023-02-08 17:13:14,624 INFO     is_testing                                False\n",
            "2023-02-08 17:13:14,624 INFO     is_training                               False\n",
            "2023-02-08 17:13:14,624 INFO     model_load_dir                            models/devign\n",
            "2023-02-08 17:13:14,624 INFO     model_weights_load_path                   models/devign/saved_model_iter5.release__only-weights\n",
            "2023-02-08 17:13:14,624 INFO     model_weights_save_path                   None\n",
            "2023-02-08 17:13:14,624 INFO     test_steps                                0\n",
            "2023-02-08 17:13:14,624 INFO     train_data_path                           None\n",
            "2023-02-08 17:13:14,624 INFO     train_steps_per_epoch                     0\n",
            "2023-02-08 17:13:14,624 INFO     word_freq_dict_path                       None\n",
            "2023-02-08 17:13:14,624 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 17:13:14,625 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-08 17:13:14,634 INFO     Done loading model vocabularies.\n",
            "2023-02-08 17:13:15,319 INFO     Initalized variables\n",
            "2023-02-08 17:13:15,328 INFO     Loading model weights from: models/devign/saved_model_iter5.release\n",
            "2023-02-08 17:13:15,384 INFO     Done loading model weights\n",
            "Traceback (most recent call last):\n",
            "  File \"prediction_outputter.py\", line 30, in <module>\n",
            "    context_word2 = context_parts[2]\n",
            "IndexError: list index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code2vec.py --load models/devign/saved_model_iter5.release --export_code_vectors --test /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.test.c2v\n",
        "\n"
      ],
      "metadata": {
        "id": "kLRloh4QIDok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cd9a0e-485a-4c54-f1cc-5063ebfe81b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-08 18:01:50,473 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:01:50,473 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-08 18:01:50,473 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:01:50,473 INFO     Checking number of examples ...\n",
            "2023-02-08 18:01:50,473 INFO     Path: /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.test.c2v\n",
            "2023-02-08 18:01:51,247 INFO         Number of test examples: 359\n",
            "2023-02-08 18:01:51,247 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:01:51,247 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-08 18:01:51,247 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-08 18:01:51,247 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-08 18:01:51,247 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-08 18:01:51,247 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-08 18:01:51,247 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-08 18:01:51,247 INFO     EXPORT_CODE_VECTORS                       True\n",
            "2023-02-08 18:01:51,247 INFO     LOGS_PATH                                 None\n",
            "2023-02-08 18:01:51,247 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-08 18:01:51,247 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-08 18:01:51,247 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-08 18:01:51,247 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-08 18:01:51,247 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-08 18:01:51,247 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5.release\n",
            "2023-02-08 18:01:51,248 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-08 18:01:51,248 INFO     NEGATIVE                                  safe\n",
            "2023-02-08 18:01:51,248 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-08 18:01:51,248 INFO     NUM_TEST_EXAMPLES                         359\n",
            "2023-02-08 18:01:51,248 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-08 18:01:51,248 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-08 18:01:51,248 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-08 18:01:51,248 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-08 18:01:51,248 INFO     POSITIVE                                  vuln\n",
            "2023-02-08 18:01:51,248 INFO     PREDICT                                   False\n",
            "2023-02-08 18:01:51,248 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-08 18:01:51,248 INFO     RELEASE                                   False\n",
            "2023-02-08 18:01:51,248 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-08 18:01:51,248 INFO     SAVE_T2V                                  None\n",
            "2023-02-08 18:01:51,248 INFO     SAVE_W2V                                  None\n",
            "2023-02-08 18:01:51,248 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-08 18:01:51,248 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-08 18:01:51,248 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-08 18:01:51,248 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-08 18:01:51,248 INFO     TEST_DATA_PATH                            /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.test.c2v\n",
            "2023-02-08 18:01:51,248 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-08 18:01:51,248 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-08 18:01:51,248 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-08 18:01:51,248 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-08 18:01:51,248 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-08 18:01:51,248 INFO     VERBOSE_MODE                              1\n",
            "2023-02-08 18:01:51,248 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-08 18:01:51,248 INFO     context_vector_size                       384\n",
            "2023-02-08 18:01:51,248 INFO     entire_model_load_path                    models/devign/saved_model_iter5.release__entire-model\n",
            "2023-02-08 18:01:51,249 INFO     entire_model_save_path                    None\n",
            "2023-02-08 18:01:51,249 INFO     is_loading                                True\n",
            "2023-02-08 18:01:51,249 INFO     is_saving                                 False\n",
            "2023-02-08 18:01:51,249 INFO     is_testing                                True\n",
            "2023-02-08 18:01:51,249 INFO     is_training                               False\n",
            "2023-02-08 18:01:51,249 INFO     model_load_dir                            models/devign\n",
            "2023-02-08 18:01:51,249 INFO     model_weights_load_path                   models/devign/saved_model_iter5.release__only-weights\n",
            "2023-02-08 18:01:51,249 INFO     model_weights_save_path                   None\n",
            "2023-02-08 18:01:51,249 INFO     test_steps                                1\n",
            "2023-02-08 18:01:51,249 INFO     train_data_path                           None\n",
            "2023-02-08 18:01:51,249 INFO     train_steps_per_epoch                     0\n",
            "2023-02-08 18:01:51,249 INFO     word_freq_dict_path                       None\n",
            "2023-02-08 18:01:51,249 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:01:51,250 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-08 18:01:51,258 INFO     Done loading model vocabularies.\n",
            "2023-02-08 18:01:51,262 INFO     Done creating code2vec model\n",
            "DEBUG: Evaluating...\n",
            "2023-02-08 18:01:52,086 INFO     Initalized variables\n",
            "2023-02-08 18:01:52,086 INFO     Loading model weights from: models/devign/saved_model_iter5.release\n",
            "2023-02-08 18:01:52,128 INFO     Done loading model weights\n",
            "2023-02-08 18:01:52,324 INFO     Starting evaluation\n",
            "2023-02-08 18:01:53,980 INFO     Done evaluating, epoch reached\n",
            "2023-02-08 18:01:53,983 INFO     Evaluation time: 0H:0M:2S\n",
            "2023-02-08 18:01:53,984 INFO     Precision: 0.5925925925925926, Sensitivity/Recall: 0.7804878048780488, Accuracy: 0.5658263305322129, Error Rate: 0.4341736694677871, F1: 0.6736842105263158, #TPs=160, #TNs=42, #FPs=110, #FNs=45, TNR=0.27631578947368424, FPR=0.7236842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2023-02-08 18:01:53,984 INFO     Precision: 0.5925925925925926, Sensitivity/Recall: 0.7804878048780488, Accuracy: 0.5658263305322129, Error Rate: 0.4341736694677871, F1: 0.6736842105263158, #TPs=160, #TNs=42, #FPs=110, #FNs=45, TNR=0.27631578947368424, FPR=0.7236842105263158\n",
        "\n"
      ],
      "metadata": {
        "id": "bIWOEAhivXHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code2vec.py --load models/devign/saved_model_iter5.release --test /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.train.c2v --export_code_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l_hl6-IMNEe",
        "outputId": "9a68a089-4536-4378-a37f-aeecb2250ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-08 18:48:46,829 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:48:46,829 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-08 18:48:46,829 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:48:46,829 INFO     Checking number of examples ...\n",
            "2023-02-08 18:48:46,829 INFO     Path: /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.train.c2v\n",
            "2023-02-08 18:48:46,830 INFO         Number of test examples: 237\n",
            "2023-02-08 18:48:46,830 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:48:46,830 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-08 18:48:46,831 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-08 18:48:46,831 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-08 18:48:46,831 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-08 18:48:46,831 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-08 18:48:46,831 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-08 18:48:46,831 INFO     EXPORT_CODE_VECTORS                       True\n",
            "2023-02-08 18:48:46,831 INFO     LOGS_PATH                                 None\n",
            "2023-02-08 18:48:46,831 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-08 18:48:46,831 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-08 18:48:46,831 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-08 18:48:46,831 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-08 18:48:46,831 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-08 18:48:46,831 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5.release\n",
            "2023-02-08 18:48:46,831 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-08 18:48:46,831 INFO     NEGATIVE                                  safe\n",
            "2023-02-08 18:48:46,831 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-08 18:48:46,831 INFO     NUM_TEST_EXAMPLES                         237\n",
            "2023-02-08 18:48:46,832 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-08 18:48:46,832 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-08 18:48:46,832 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-08 18:48:46,832 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-08 18:48:46,832 INFO     POSITIVE                                  vuln\n",
            "2023-02-08 18:48:46,832 INFO     PREDICT                                   False\n",
            "2023-02-08 18:48:46,832 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-08 18:48:46,832 INFO     RELEASE                                   False\n",
            "2023-02-08 18:48:46,832 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-08 18:48:46,832 INFO     SAVE_T2V                                  None\n",
            "2023-02-08 18:48:46,832 INFO     SAVE_W2V                                  None\n",
            "2023-02-08 18:48:46,832 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-08 18:48:46,832 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-08 18:48:46,832 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-08 18:48:46,832 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-08 18:48:46,832 INFO     TEST_DATA_PATH                            /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.train.c2v\n",
            "2023-02-08 18:48:46,832 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-08 18:48:46,832 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-08 18:48:46,832 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-08 18:48:46,832 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-08 18:48:46,832 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-08 18:48:46,832 INFO     VERBOSE_MODE                              1\n",
            "2023-02-08 18:48:46,832 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-08 18:48:46,832 INFO     context_vector_size                       384\n",
            "2023-02-08 18:48:46,832 INFO     entire_model_load_path                    models/devign/saved_model_iter5.release__entire-model\n",
            "2023-02-08 18:48:46,832 INFO     entire_model_save_path                    None\n",
            "2023-02-08 18:48:46,832 INFO     is_loading                                True\n",
            "2023-02-08 18:48:46,833 INFO     is_saving                                 False\n",
            "2023-02-08 18:48:46,833 INFO     is_testing                                True\n",
            "2023-02-08 18:48:46,833 INFO     is_training                               False\n",
            "2023-02-08 18:48:46,833 INFO     model_load_dir                            models/devign\n",
            "2023-02-08 18:48:46,833 INFO     model_weights_load_path                   models/devign/saved_model_iter5.release__only-weights\n",
            "2023-02-08 18:48:46,833 INFO     model_weights_save_path                   None\n",
            "2023-02-08 18:48:46,833 INFO     test_steps                                1\n",
            "2023-02-08 18:48:46,833 INFO     train_data_path                           None\n",
            "2023-02-08 18:48:46,833 INFO     train_steps_per_epoch                     0\n",
            "2023-02-08 18:48:46,833 INFO     word_freq_dict_path                       None\n",
            "2023-02-08 18:48:46,833 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:48:46,833 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-08 18:48:46,840 INFO     Done loading model vocabularies.\n",
            "2023-02-08 18:48:46,844 INFO     Done creating code2vec model\n",
            "DEBUG: Evaluating...\n",
            "2023-02-08 18:48:47,657 INFO     Initalized variables\n",
            "2023-02-08 18:48:47,657 INFO     Loading model weights from: models/devign/saved_model_iter5.release\n",
            "2023-02-08 18:48:47,701 INFO     Done loading model weights\n",
            "2023-02-08 18:48:47,884 INFO     Starting evaluation\n",
            "2023-02-08 18:48:49,465 INFO     Done evaluating, epoch reached\n",
            "2023-02-08 18:48:49,469 INFO     Evaluation time: 0H:0M:2S\n",
            "2023-02-08 18:48:49,469 INFO     Precision: 0.7720588235294118, Sensitivity/Recall: 0.9210526315789473, Accuracy: 0.8312236286919831, Error Rate: 0.16877637130801687, F1: 0.8400000000000001, #TPs=105, #TNs=92, #FPs=31, #FNs=9, TNR=0.7479674796747967, FPR=0.25203252032520324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2023-02-08 18:48:49,469 INFO     Precision: 0.7720588235294118, Sensitivity/Recall: 0.9210526315789473, Accuracy: 0.8312236286919831, Error Rate: 0.16877637130801687, F1: 0.8400000000000001, #TPs=105, #TNs=92, #FPs=31, #FNs=9, TNR=0.7479674796747967, FPR=0.25203252032520324\n"
      ],
      "metadata": {
        "id": "zodX7m4WXUC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code2vec.py --load models/devign/saved_model_iter5.release --test /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.val.c2v --export_code_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb4gtATFXGq-",
        "outputId": "63082a26-0187-4011-dca3-2beed1862241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-08 18:49:52,516 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:49:52,517 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-08 18:49:52,517 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:49:52,517 INFO     Checking number of examples ...\n",
            "2023-02-08 18:49:52,517 INFO     Path: /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.val.c2v\n",
            "2023-02-08 18:49:52,518 INFO         Number of test examples: 520\n",
            "2023-02-08 18:49:52,518 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:49:52,518 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-08 18:49:52,519 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-08 18:49:52,519 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-08 18:49:52,519 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-08 18:49:52,519 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-08 18:49:52,519 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-08 18:49:52,519 INFO     EXPORT_CODE_VECTORS                       True\n",
            "2023-02-08 18:49:52,519 INFO     LOGS_PATH                                 None\n",
            "2023-02-08 18:49:52,519 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-08 18:49:52,519 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-08 18:49:52,519 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-08 18:49:52,519 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-08 18:49:52,519 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-08 18:49:52,519 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5.release\n",
            "2023-02-08 18:49:52,519 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-08 18:49:52,519 INFO     NEGATIVE                                  safe\n",
            "2023-02-08 18:49:52,519 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-08 18:49:52,519 INFO     NUM_TEST_EXAMPLES                         520\n",
            "2023-02-08 18:49:52,519 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-08 18:49:52,519 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-08 18:49:52,519 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-08 18:49:52,519 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-08 18:49:52,519 INFO     POSITIVE                                  vuln\n",
            "2023-02-08 18:49:52,519 INFO     PREDICT                                   False\n",
            "2023-02-08 18:49:52,520 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-08 18:49:52,520 INFO     RELEASE                                   False\n",
            "2023-02-08 18:49:52,520 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-08 18:49:52,520 INFO     SAVE_T2V                                  None\n",
            "2023-02-08 18:49:52,520 INFO     SAVE_W2V                                  None\n",
            "2023-02-08 18:49:52,520 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-08 18:49:52,520 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-08 18:49:52,520 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-08 18:49:52,520 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-08 18:49:52,520 INFO     TEST_DATA_PATH                            /content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.val.c2v\n",
            "2023-02-08 18:49:52,520 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-08 18:49:52,520 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-08 18:49:52,520 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-08 18:49:52,520 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-08 18:49:52,520 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-08 18:49:52,520 INFO     VERBOSE_MODE                              1\n",
            "2023-02-08 18:49:52,520 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-08 18:49:52,520 INFO     context_vector_size                       384\n",
            "2023-02-08 18:49:52,520 INFO     entire_model_load_path                    models/devign/saved_model_iter5.release__entire-model\n",
            "2023-02-08 18:49:52,520 INFO     entire_model_save_path                    None\n",
            "2023-02-08 18:49:52,520 INFO     is_loading                                True\n",
            "2023-02-08 18:49:52,520 INFO     is_saving                                 False\n",
            "2023-02-08 18:49:52,520 INFO     is_testing                                True\n",
            "2023-02-08 18:49:52,520 INFO     is_training                               False\n",
            "2023-02-08 18:49:52,520 INFO     model_load_dir                            models/devign\n",
            "2023-02-08 18:49:52,521 INFO     model_weights_load_path                   models/devign/saved_model_iter5.release__only-weights\n",
            "2023-02-08 18:49:52,521 INFO     model_weights_save_path                   None\n",
            "2023-02-08 18:49:52,521 INFO     test_steps                                1\n",
            "2023-02-08 18:49:52,521 INFO     train_data_path                           None\n",
            "2023-02-08 18:49:52,521 INFO     train_steps_per_epoch                     0\n",
            "2023-02-08 18:49:52,521 INFO     word_freq_dict_path                       None\n",
            "2023-02-08 18:49:52,521 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:49:52,521 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-08 18:49:52,530 INFO     Done loading model vocabularies.\n",
            "2023-02-08 18:49:52,533 INFO     Done creating code2vec model\n",
            "DEBUG: Evaluating...\n",
            "2023-02-08 18:49:53,347 INFO     Initalized variables\n",
            "2023-02-08 18:49:53,347 INFO     Loading model weights from: models/devign/saved_model_iter5.release\n",
            "2023-02-08 18:49:53,387 INFO     Done loading model weights\n",
            "2023-02-08 18:49:53,570 INFO     Starting evaluation\n",
            "2023-02-08 18:49:55,278 INFO     Done evaluating, epoch reached\n",
            "2023-02-08 18:49:55,281 INFO     Evaluation time: 0H:0M:2S\n",
            "2023-02-08 18:49:55,281 INFO     Precision: 0.44554455445544555, Sensitivity/Recall: 0.7627118644067796, Accuracy: 0.4605009633911368, Error Rate: 0.5394990366088632, F1: 0.5625, #TPs=180, #TNs=59, #FPs=224, #FNs=56, TNR=0.20848056537102475, FPR=0.7915194346289752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2023-02-08 18:49:55,281 INFO     Precision: 0.44554455445544555, Sensitivity/Recall: 0.7627118644067796, Accuracy: 0.4605009633911368, Error Rate: 0.5394990366088632, F1: 0.5625, #TPs=180, #TNs=59, #FPs=224, #FNs=56, TNR=0.20848056537102475, FPR=0.7915194346289752\n"
      ],
      "metadata": {
        "id": "pvMaCovtXRuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code2vec.py --load models/devign/saved_model_iter5.release --export_code_vectors --predict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH3tZaDIMiF6",
        "outputId": "efeda952-7332-40d8-ed84-fcbb38bc3832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-08 18:23:06,617 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:23:06,617 INFO     ---------------------- Creating code2vec model ----------------------\n",
            "2023-02-08 18:23:06,617 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:23:06,617 INFO     Checking number of examples ...\n",
            "2023-02-08 18:23:06,617 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:23:06,617 INFO     ----------------- Configuration - Hyper Parameters ------------------\n",
            "2023-02-08 18:23:06,617 INFO     CODE_VECTOR_SIZE                          384\n",
            "2023-02-08 18:23:06,617 INFO     CSV_BUFFER_SIZE                           104857600\n",
            "2023-02-08 18:23:06,617 INFO     DEFAULT_EMBEDDINGS_SIZE                   128\n",
            "2023-02-08 18:23:06,617 INFO     DL_FRAMEWORK                              tensorflow\n",
            "2023-02-08 18:23:06,617 INFO     DROPOUT_KEEP_RATE                         0.75\n",
            "2023-02-08 18:23:06,617 INFO     EXPORT_CODE_VECTORS                       True\n",
            "2023-02-08 18:23:06,617 INFO     LOGS_PATH                                 None\n",
            "2023-02-08 18:23:06,618 INFO     MAX_CONTEXTS                              200\n",
            "2023-02-08 18:23:06,618 INFO     MAX_PATH_VOCAB_SIZE                       911417\n",
            "2023-02-08 18:23:06,618 INFO     MAX_TARGET_VOCAB_SIZE                     261245\n",
            "2023-02-08 18:23:06,618 INFO     MAX_TOKEN_VOCAB_SIZE                      1301136\n",
            "2023-02-08 18:23:06,618 INFO     MAX_TO_KEEP                               10\n",
            "2023-02-08 18:23:06,618 INFO     MODEL_LOAD_PATH                           models/devign/saved_model_iter5.release\n",
            "2023-02-08 18:23:06,618 INFO     MODEL_SAVE_PATH                           None\n",
            "2023-02-08 18:23:06,618 INFO     NEGATIVE                                  safe\n",
            "2023-02-08 18:23:06,618 INFO     NUM_BATCHES_TO_LOG_PROGRESS               100\n",
            "2023-02-08 18:23:06,618 INFO     NUM_TEST_EXAMPLES                         0\n",
            "2023-02-08 18:23:06,618 INFO     NUM_TRAIN_BATCHES_TO_EVALUATE             1800\n",
            "2023-02-08 18:23:06,618 INFO     NUM_TRAIN_EPOCHS                          20\n",
            "2023-02-08 18:23:06,618 INFO     NUM_TRAIN_EXAMPLES                        0\n",
            "2023-02-08 18:23:06,618 INFO     PATH_EMBEDDINGS_SIZE                      128\n",
            "2023-02-08 18:23:06,618 INFO     POSITIVE                                  vuln\n",
            "2023-02-08 18:23:06,618 INFO     PREDICT                                   True\n",
            "2023-02-08 18:23:06,618 INFO     READER_NUM_PARALLEL_BATCHES               6\n",
            "2023-02-08 18:23:06,618 INFO     RELEASE                                   False\n",
            "2023-02-08 18:23:06,618 INFO     SAVE_EVERY_EPOCHS                         1\n",
            "2023-02-08 18:23:06,618 INFO     SAVE_T2V                                  None\n",
            "2023-02-08 18:23:06,618 INFO     SAVE_W2V                                  None\n",
            "2023-02-08 18:23:06,618 INFO     SEPARATE_OOV_AND_PAD                      False\n",
            "2023-02-08 18:23:06,618 INFO     SHUFFLE_BUFFER_SIZE                       10000\n",
            "2023-02-08 18:23:06,618 INFO     TARGET_EMBEDDINGS_SIZE                    384\n",
            "2023-02-08 18:23:06,618 INFO     TEST_BATCH_SIZE                           1024\n",
            "2023-02-08 18:23:06,618 INFO     TEST_DATA_PATH                            \n",
            "2023-02-08 18:23:06,618 INFO     TOKEN_EMBEDDINGS_SIZE                     128\n",
            "2023-02-08 18:23:06,618 INFO     TOP_K_WORDS_CONSIDERED_DURING_PREDICTION  10\n",
            "2023-02-08 18:23:06,618 INFO     TRAIN_BATCH_SIZE                          1024\n",
            "2023-02-08 18:23:06,619 INFO     TRAIN_DATA_PATH_PREFIX                    None\n",
            "2023-02-08 18:23:06,619 INFO     USE_TENSORBOARD                           False\n",
            "2023-02-08 18:23:06,619 INFO     VERBOSE_MODE                              1\n",
            "2023-02-08 18:23:06,619 INFO     _Config__logger                           <Logger code2vec (INFO)>\n",
            "2023-02-08 18:23:06,619 INFO     context_vector_size                       384\n",
            "2023-02-08 18:23:06,619 INFO     entire_model_load_path                    models/devign/saved_model_iter5.release__entire-model\n",
            "2023-02-08 18:23:06,619 INFO     entire_model_save_path                    None\n",
            "2023-02-08 18:23:06,619 INFO     is_loading                                True\n",
            "2023-02-08 18:23:06,619 INFO     is_saving                                 False\n",
            "2023-02-08 18:23:06,619 INFO     is_testing                                False\n",
            "2023-02-08 18:23:06,619 INFO     is_training                               False\n",
            "2023-02-08 18:23:06,619 INFO     model_load_dir                            models/devign\n",
            "2023-02-08 18:23:06,619 INFO     model_weights_load_path                   models/devign/saved_model_iter5.release__only-weights\n",
            "2023-02-08 18:23:06,619 INFO     model_weights_save_path                   None\n",
            "2023-02-08 18:23:06,619 INFO     test_steps                                0\n",
            "2023-02-08 18:23:06,619 INFO     train_data_path                           None\n",
            "2023-02-08 18:23:06,619 INFO     train_steps_per_epoch                     0\n",
            "2023-02-08 18:23:06,619 INFO     word_freq_dict_path                       None\n",
            "2023-02-08 18:23:06,619 INFO     ---------------------------------------------------------------------\n",
            "2023-02-08 18:23:06,620 INFO     Loading model vocabularies from: `models/devign/dictionaries.bin` ... \n",
            "2023-02-08 18:23:06,627 INFO     Done loading model vocabularies.\n",
            "2023-02-08 18:23:06,631 INFO     Done creating code2vec model\n",
            "2023-02-08 18:23:07,288 INFO     Initalized variables\n",
            "2023-02-08 18:23:07,297 INFO     Loading model weights from: models/devign/saved_model_iter5.release\n",
            "2023-02-08 18:23:07,347 INFO     Done loading model weights\n",
            "Starting interactive prediction...\n",
            "Modify the file: \"input.js\" and press any key when ready, or \"q\" / \"quit\" / \"exit\" to exit\n",
            "g\n",
            "[]\n",
            "internal/modules/cjs/loader.js:883\n",
            "  throw err;\n",
            "  ^\n",
            "\n",
            "Error: Cannot find module '/content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/JSExtractor/build/index.js'\n",
            "    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:880:15)\n",
            "    at Function.Module._load (internal/modules/cjs/loader.js:725:27)\n",
            "    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:72:12)\n",
            "    at internal/main/run_main_module.js:17:47 {\n",
            "  code: 'MODULE_NOT_FOUND',\n",
            "  requireStack: []\n",
            "}\n",
            "\n",
            "Modify the file: \"input.js\" and press any key when ready, or \"q\" / \"quit\" / \"exit\" to exit\n",
            "exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/data/devign/devign.test.c2v.vectors','r') as firstfile, open('/content/drive/MyDrive/devign-CodeVul/code2vec-code/vector_results.txt','w') as secondfile:\n",
        "    for line in firstfile:\n",
        "             secondfile.write(line)"
      ],
      "metadata": {
        "id": "BqbQj_L6NOGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "vectors_table = pd.read_csv('/content/drive/MyDrive/devign-CodeVul/code2vec-code/vector_results.txt', sep=\" \", header=None)"
      ],
      "metadata": {
        "id": "toLE4WXqVqfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ZYCh4JULVxtz",
        "outputId": "482128fc-bb6b-4423-f54e-557b383a7b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6    \\\n",
              "0    0.027397 -0.019585 -0.013053 -0.019990 -0.000280  0.018346  0.010392   \n",
              "1   -0.022493  0.034752 -0.019768 -0.008014 -0.032480  0.008879  0.103854   \n",
              "2    0.024675  0.043641 -0.044374 -0.045136 -0.018894 -0.011160  0.073667   \n",
              "3   -0.019524  0.026950 -0.011974 -0.013604 -0.012386  0.006614  0.041252   \n",
              "4   -0.022803  0.041887 -0.025068 -0.030957 -0.021506  0.001983  0.010321   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "352 -0.009736  0.047279  0.005255  0.013753 -0.008843  0.007202  0.074640   \n",
              "353 -0.018987  0.020552 -0.029790 -0.029172  0.004728  0.002650  0.050022   \n",
              "354  0.018854  0.040439 -0.029264 -0.021056 -0.032004  0.015466  0.065553   \n",
              "355  0.007958 -0.002836 -0.009997 -0.022277 -0.026563  0.003658  0.090518   \n",
              "356  0.013366  0.052146 -0.008595 -0.045030 -0.001026 -0.027820  0.019919   \n",
              "\n",
              "          7         8         9    ...       374       375       376  \\\n",
              "0    0.035380 -0.008344  0.075914  ... -0.027436 -0.018418  0.004052   \n",
              "1    0.022706 -0.060262  0.036250  ... -0.058376 -0.032297 -0.035698   \n",
              "2    0.031929 -0.047267  0.019654  ... -0.015139 -0.022987 -0.015272   \n",
              "3    0.014665 -0.032114  0.029717  ... -0.055452  0.012167 -0.041464   \n",
              "4    0.039018 -0.059125 -0.002012  ... -0.020411 -0.026096 -0.056039   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "352  0.039383 -0.080710  0.029368  ... -0.083585  0.011601 -0.027306   \n",
              "353  0.032604 -0.046397  0.029236  ... -0.020794 -0.024058  0.001452   \n",
              "354  0.035427 -0.029733  0.024650  ... -0.045160 -0.034835 -0.039974   \n",
              "355  0.020016 -0.045624  0.037074  ... -0.058789 -0.009086 -0.015466   \n",
              "356  0.036319 -0.026608  0.033969  ... -0.044899 -0.062364 -0.036412   \n",
              "\n",
              "          377       378       379       380       381       382       383  \n",
              "0   -0.014924 -0.022526 -0.017346 -0.043375 -0.015443 -0.010276  0.063321  \n",
              "1   -0.029021  0.026015  0.033951  0.020788  0.018774 -0.042694  0.011068  \n",
              "2   -0.012139 -0.020569  0.042732 -0.015291 -0.015469 -0.060082  0.040120  \n",
              "3   -0.032086  0.016695 -0.024321  0.030963  0.009650 -0.007788  0.016668  \n",
              "4    0.005714 -0.005483  0.002489  0.004314 -0.001680 -0.064337  0.023834  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "352 -0.014982  0.021017  0.034008  0.005772  0.028297 -0.019645 -0.014497  \n",
              "353 -0.019228 -0.039378  0.026591 -0.044416  0.015559 -0.033816  0.024650  \n",
              "354  0.002712 -0.017800  0.049537  0.000398 -0.014715 -0.046561  0.003249  \n",
              "355 -0.031261  0.009568  0.031238  0.017694  0.043526 -0.034827 -0.000089  \n",
              "356 -0.010349  0.002528  0.035826 -0.032699 -0.005173 -0.053789  0.026182  \n",
              "\n",
              "[357 rows x 384 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd33118a-39d7-44cc-b44a-88582ebec3cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>374</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.027397</td>\n",
              "      <td>-0.019585</td>\n",
              "      <td>-0.013053</td>\n",
              "      <td>-0.019990</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>0.018346</td>\n",
              "      <td>0.010392</td>\n",
              "      <td>0.035380</td>\n",
              "      <td>-0.008344</td>\n",
              "      <td>0.075914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027436</td>\n",
              "      <td>-0.018418</td>\n",
              "      <td>0.004052</td>\n",
              "      <td>-0.014924</td>\n",
              "      <td>-0.022526</td>\n",
              "      <td>-0.017346</td>\n",
              "      <td>-0.043375</td>\n",
              "      <td>-0.015443</td>\n",
              "      <td>-0.010276</td>\n",
              "      <td>0.063321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.022493</td>\n",
              "      <td>0.034752</td>\n",
              "      <td>-0.019768</td>\n",
              "      <td>-0.008014</td>\n",
              "      <td>-0.032480</td>\n",
              "      <td>0.008879</td>\n",
              "      <td>0.103854</td>\n",
              "      <td>0.022706</td>\n",
              "      <td>-0.060262</td>\n",
              "      <td>0.036250</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058376</td>\n",
              "      <td>-0.032297</td>\n",
              "      <td>-0.035698</td>\n",
              "      <td>-0.029021</td>\n",
              "      <td>0.026015</td>\n",
              "      <td>0.033951</td>\n",
              "      <td>0.020788</td>\n",
              "      <td>0.018774</td>\n",
              "      <td>-0.042694</td>\n",
              "      <td>0.011068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.024675</td>\n",
              "      <td>0.043641</td>\n",
              "      <td>-0.044374</td>\n",
              "      <td>-0.045136</td>\n",
              "      <td>-0.018894</td>\n",
              "      <td>-0.011160</td>\n",
              "      <td>0.073667</td>\n",
              "      <td>0.031929</td>\n",
              "      <td>-0.047267</td>\n",
              "      <td>0.019654</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015139</td>\n",
              "      <td>-0.022987</td>\n",
              "      <td>-0.015272</td>\n",
              "      <td>-0.012139</td>\n",
              "      <td>-0.020569</td>\n",
              "      <td>0.042732</td>\n",
              "      <td>-0.015291</td>\n",
              "      <td>-0.015469</td>\n",
              "      <td>-0.060082</td>\n",
              "      <td>0.040120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.019524</td>\n",
              "      <td>0.026950</td>\n",
              "      <td>-0.011974</td>\n",
              "      <td>-0.013604</td>\n",
              "      <td>-0.012386</td>\n",
              "      <td>0.006614</td>\n",
              "      <td>0.041252</td>\n",
              "      <td>0.014665</td>\n",
              "      <td>-0.032114</td>\n",
              "      <td>0.029717</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.055452</td>\n",
              "      <td>0.012167</td>\n",
              "      <td>-0.041464</td>\n",
              "      <td>-0.032086</td>\n",
              "      <td>0.016695</td>\n",
              "      <td>-0.024321</td>\n",
              "      <td>0.030963</td>\n",
              "      <td>0.009650</td>\n",
              "      <td>-0.007788</td>\n",
              "      <td>0.016668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.022803</td>\n",
              "      <td>0.041887</td>\n",
              "      <td>-0.025068</td>\n",
              "      <td>-0.030957</td>\n",
              "      <td>-0.021506</td>\n",
              "      <td>0.001983</td>\n",
              "      <td>0.010321</td>\n",
              "      <td>0.039018</td>\n",
              "      <td>-0.059125</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020411</td>\n",
              "      <td>-0.026096</td>\n",
              "      <td>-0.056039</td>\n",
              "      <td>0.005714</td>\n",
              "      <td>-0.005483</td>\n",
              "      <td>0.002489</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>-0.001680</td>\n",
              "      <td>-0.064337</td>\n",
              "      <td>0.023834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>-0.009736</td>\n",
              "      <td>0.047279</td>\n",
              "      <td>0.005255</td>\n",
              "      <td>0.013753</td>\n",
              "      <td>-0.008843</td>\n",
              "      <td>0.007202</td>\n",
              "      <td>0.074640</td>\n",
              "      <td>0.039383</td>\n",
              "      <td>-0.080710</td>\n",
              "      <td>0.029368</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.083585</td>\n",
              "      <td>0.011601</td>\n",
              "      <td>-0.027306</td>\n",
              "      <td>-0.014982</td>\n",
              "      <td>0.021017</td>\n",
              "      <td>0.034008</td>\n",
              "      <td>0.005772</td>\n",
              "      <td>0.028297</td>\n",
              "      <td>-0.019645</td>\n",
              "      <td>-0.014497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>-0.018987</td>\n",
              "      <td>0.020552</td>\n",
              "      <td>-0.029790</td>\n",
              "      <td>-0.029172</td>\n",
              "      <td>0.004728</td>\n",
              "      <td>0.002650</td>\n",
              "      <td>0.050022</td>\n",
              "      <td>0.032604</td>\n",
              "      <td>-0.046397</td>\n",
              "      <td>0.029236</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020794</td>\n",
              "      <td>-0.024058</td>\n",
              "      <td>0.001452</td>\n",
              "      <td>-0.019228</td>\n",
              "      <td>-0.039378</td>\n",
              "      <td>0.026591</td>\n",
              "      <td>-0.044416</td>\n",
              "      <td>0.015559</td>\n",
              "      <td>-0.033816</td>\n",
              "      <td>0.024650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>0.018854</td>\n",
              "      <td>0.040439</td>\n",
              "      <td>-0.029264</td>\n",
              "      <td>-0.021056</td>\n",
              "      <td>-0.032004</td>\n",
              "      <td>0.015466</td>\n",
              "      <td>0.065553</td>\n",
              "      <td>0.035427</td>\n",
              "      <td>-0.029733</td>\n",
              "      <td>0.024650</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.045160</td>\n",
              "      <td>-0.034835</td>\n",
              "      <td>-0.039974</td>\n",
              "      <td>0.002712</td>\n",
              "      <td>-0.017800</td>\n",
              "      <td>0.049537</td>\n",
              "      <td>0.000398</td>\n",
              "      <td>-0.014715</td>\n",
              "      <td>-0.046561</td>\n",
              "      <td>0.003249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>0.007958</td>\n",
              "      <td>-0.002836</td>\n",
              "      <td>-0.009997</td>\n",
              "      <td>-0.022277</td>\n",
              "      <td>-0.026563</td>\n",
              "      <td>0.003658</td>\n",
              "      <td>0.090518</td>\n",
              "      <td>0.020016</td>\n",
              "      <td>-0.045624</td>\n",
              "      <td>0.037074</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058789</td>\n",
              "      <td>-0.009086</td>\n",
              "      <td>-0.015466</td>\n",
              "      <td>-0.031261</td>\n",
              "      <td>0.009568</td>\n",
              "      <td>0.031238</td>\n",
              "      <td>0.017694</td>\n",
              "      <td>0.043526</td>\n",
              "      <td>-0.034827</td>\n",
              "      <td>-0.000089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>0.013366</td>\n",
              "      <td>0.052146</td>\n",
              "      <td>-0.008595</td>\n",
              "      <td>-0.045030</td>\n",
              "      <td>-0.001026</td>\n",
              "      <td>-0.027820</td>\n",
              "      <td>0.019919</td>\n",
              "      <td>0.036319</td>\n",
              "      <td>-0.026608</td>\n",
              "      <td>0.033969</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.044899</td>\n",
              "      <td>-0.062364</td>\n",
              "      <td>-0.036412</td>\n",
              "      <td>-0.010349</td>\n",
              "      <td>0.002528</td>\n",
              "      <td>0.035826</td>\n",
              "      <td>-0.032699</td>\n",
              "      <td>-0.005173</td>\n",
              "      <td>-0.053789</td>\n",
              "      <td>0.026182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>357 rows × 384 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd33118a-39d7-44cc-b44a-88582ebec3cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd33118a-39d7-44cc-b44a-88582ebec3cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd33118a-39d7-44cc-b44a-88582ebec3cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_table = pd.read_csv('/content/drive/MyDrive/devign-CodeVul/code2vec-code/code2vec/devign.train.raw.txt', sep=\" \", header=None)\n"
      ],
      "metadata": {
        "id": "sOG5hK-G-eMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "yQ5mlqLslMCK",
        "outputId": "0347ac5d-d02d-4f12-e4c1-2b675297aae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0                                                  1    \\\n",
              "0    safe  av|codec|context|*,c4b44d57c510ae50e3f1f4c368b...   \n",
              "1    safe  av|format|context|*|*,c4b44d57c510ae50e3f1f4c3...   \n",
              "2    safe     void|*,c4b44d57c510ae50e3f1f4c368b9e232,opaque   \n",
              "3    safe  cl|mem,c4b44d57c510ae50e3f1f4c368b9e232,dst|cl...   \n",
              "4    vuln  av|format|context|*,c4b44d57c510ae50e3f1f4c368...   \n",
              "..    ...                                                ...   \n",
              "232  safe  data,ef0f501e85af13c3f3106da4bf2906e0,test|out...   \n",
              "233  safe  s,ef0f501e85af13c3f3106da4bf2906e0,ac|encode|c...   \n",
              "234  safe     sd|state|*,c4b44d57c510ae50e3f1f4c368b9e232,sd   \n",
              "235  safe  e,ef0f501e85af13c3f3106da4bf2906e0,event|notif...   \n",
              "236  safe       visitor|*,c4b44d57c510ae50e3f1f4c368b9e232,v   \n",
              "\n",
              "                                                   2    \\\n",
              "0    ctx,7287fb7dd01a251fda0dbd3ae74001c1,vda|decod...   \n",
              "1    int,c4b44d57c510ae50e3f1f4c368b9e232,nb|output...   \n",
              "2     unused,ef0f501e85af13c3f3106da4bf2906e0,uint|t|*   \n",
              "3    uint|t|*,c4b44d57c510ae50e3f1f4c368b9e232,src|buf   \n",
              "4         atom,ef0f501e85af13c3f3106da4bf2906e0,atom|*   \n",
              "..                                                 ...   \n",
              "232  const|void|*,c4b44d57c510ae50e3f1f4c368b9e232,...   \n",
              "233           blk,7287fb7dd01a251fda0dbd3ae74001c1,int   \n",
              "234      uint|t,c4b44d57c510ae50e3f1f4c368b9e232,value   \n",
              "235  e,06f1bd4eabc1f73da38b772edea29dca,event|notif...   \n",
              "236  name,ef0f501e85af13c3f3106da4bf2906e0,const|ch...   \n",
              "\n",
              "                                                   3    \\\n",
              "0    ctx,06f1bd4eabc1f73da38b772edea29dca,vda|decod...   \n",
              "1    input|file|*,c4b44d57c510ae50e3f1f4c368b9e232,...   \n",
              "2    v|l|buffer|*,8a2b9543a7267ced6831ca9e368e2149,...   \n",
              "3     size|t,c4b44d57c510ae50e3f1f4c368b9e232,buf|size   \n",
              "4    r|d,7287fb7dd01a251fda0dbd3ae74001c1,r|d|conte...   \n",
              "..                                                 ...   \n",
              "232  test|output|visitor|data|*,be3b43d7f4a43891e03...   \n",
              "233            ch,7287fb7dd01a251fda0dbd3ae74001c1,int   \n",
              "234             int,8a2b9543a7267ced6831ca9e368e2149,i   \n",
              "235              e,4f27c208767e095fd30422fc396d9a65,fd   \n",
              "236      uint|t|*,c4b44d57c510ae50e3f1f4c368b9e232,obj   \n",
              "\n",
              "                                                   4    \\\n",
              "0    av|codec|context|*,be3b43d7f4a43891e0385f2eca2...   \n",
              "1    nb|input|files,ef0f501e85af13c3f3106da4bf2906e...   \n",
              "2    avbuf,06f1bd4eabc1f73da38b772edea29dca,v|l|buf...   \n",
              "3       cl|int,8a2b9543a7267ced6831ca9e368e2149,status   \n",
              "4    r|d|context|*,be3b43d7f4a43891e0385f2eca2cf07f...   \n",
              "..                                                 ...   \n",
              "232  test|output|visitor|data|*,d5ca1a6cadb392e0831...   \n",
              "233             i,7287fb7dd01a251fda0dbd3ae74001c1,int   \n",
              "234     sd|state|*,be3b43d7f4a43891e0385f2eca2cf07f,sd   \n",
              "235  event|notifier|*,d5ca1a6cadb392e083136474a8cab...   \n",
              "236    error|*|*,c4b44d57c510ae50e3f1f4c368b9e232,errp   \n",
              "\n",
              "                                                   5    \\\n",
              "0    av|codec|context|*,d5ca1a6cadb392e083136474a8c...   \n",
              "1    stream|map|*,c4b44d57c510ae50e3f1f4c368b9e232,...   \n",
              "2       void|*,be3b43d7f4a43891e0385f2eca2cf07f,opaque   \n",
              "3       mapped,7287fb7dd01a251fda0dbd3ae74001c1,void|*   \n",
              "4    s,06f1bd4eabc1f73da38b772edea29dca,av|format|c...   \n",
              "..                                                 ...   \n",
              "232          data,4f27c208767e095fd30422fc396d9a65,qov   \n",
              "233    group|size,7287fb7dd01a251fda0dbd3ae74001c1,int   \n",
              "234   sd|state|*,d5ca1a6cadb392e083136474a8cabc30,bdrv   \n",
              "235  event|notifier|get|fd,983bf92b87bd6bebbf29a788...   \n",
              "236  opts|visitor|*,8a2b9543a7267ced6831ca9e368e214...   \n",
              "\n",
              "                                                   6    \\\n",
              "0     avctx,4f27c208767e095fd30422fc396d9a65,priv|data   \n",
              "1    int,c4b44d57c510ae50e3f1f4c368b9e232,nb|stream...   \n",
              "2        avbuf,fb9f9251d9b23ebb99f316967367cfc9,void|*   \n",
              "3       mapped,06f1bd4eabc1f73da38b772edea29dca,void|*   \n",
              "4         s,4f27c208767e095fd30422fc396d9a65,priv|data   \n",
              "..                                                 ...   \n",
              "232  test|output|visitor|data|*,052c0d4821ee0d05bcc...   \n",
              "233     nb|groups,7287fb7dd01a251fda0dbd3ae74001c1,int   \n",
              "234           sd,4f27c208767e095fd30422fc396d9a65,bdrv   \n",
              "235  event|notifier|get|fd,4dcd7965537d2a08f1493560...   \n",
              "236  opts|visitor|*,be3b43d7f4a43891e0385f2eca2cf07...   \n",
              "\n",
              "                                                   7    \\\n",
              "0    ctx,e99fb8c78ec60764eb90dd0829f8d24d,av|codec|...   \n",
              "1             int,8a2b9543a7267ced6831ca9e368e2149,ret   \n",
              "2        avbuf,7572afe878600f9622b95bc8c58c7cc0,opaque   \n",
              "3         any,be3b43d7f4a43891e0385f2eca2cf07f,gpu|env   \n",
              "4    av|format|context|*,d5ca1a6cadb392e083136474a8...   \n",
              "..                                                 ...   \n",
              "232  data,d271abdcd6e33ad941c31d166e68d781,qmp|outp...   \n",
              "233     bit|count,7287fb7dd01a251fda0dbd3ae74001c1,int   \n",
              "234     sd|state|*,be3b43d7f4a43891e0385f2eca2cf07f,sd   \n",
              "235  event|notifier|get|fd,364d0b992a6a1f0a20e4ef02...   \n",
              "236       visitor|*,be3b43d7f4a43891e0385f2eca2cf07f,v   \n",
              "\n",
              "                                                   8    \\\n",
              "0           ctx,f37463348f7d92f9744e6a6961c41783,avctx   \n",
              "1             ret,06f1bd4eabc1f73da38b772edea29dca,int   \n",
              "2    v|l|buffer|*,0ca71374928d20cc4f4d5ebed5e8f2ea,...   \n",
              "3    any,7abd058903aa9bf4884b27ec00a52472,command|q...   \n",
              "4     r|d|context|*,0b46b7d931afa6f3ecf10c618141db9d,s   \n",
              "..                                                 ...   \n",
              "232  qov,a3af7a253373961ecb7bfadda315b38c,qmp|outpu...   \n",
              "233        uint|t|*,8a2b9543a7267ced6831ca9e368e2149,p   \n",
              "234   sd|state|*,d5ca1a6cadb392e083136474a8cabc30,bdrv   \n",
              "235  event|notifier|get|fd,46b7815ae44110c7172b6c56...   \n",
              "236   to|ov,1dbfd33caf135e6c4c08fc7a55af5682,visitor|*   \n",
              "\n",
              "                                                   9    ...  \\\n",
              "0       ctx,6c488522dbe3aabd8a3e396a9ee206d1,priv|data  ...   \n",
              "1                ret,dec237d97608618c9dde47b3d062b847,  ...   \n",
              "2    v|l|buffer|*,6277867cae5a4c1f47e5f83fe53e3e7b,...  ...   \n",
              "3    gpu|env,4271746d4835de435dd1a433861f9573,comma...  ...   \n",
              "4    r|d|context|*,629a2d5ff78f14c6625584db51dc5cff...  ...   \n",
              "..                                                 ...  ...   \n",
              "232  test|output|visitor|data|*,be3b43d7f4a43891e03...  ...   \n",
              "233         int,8a2b9543a7267ced6831ca9e368e2149,delta  ...   \n",
              "234           sd,4f27c208767e095fd30422fc396d9a65,bdrv  ...   \n",
              "235  event|notifier|get|fd,19cc19733c7469a9dfce5373...  ...   \n",
              "236           to|ov,111f072b31664dc52f36bbafdf999c3a,v  ...   \n",
              "\n",
              "                                                   191  \\\n",
              "0           ctx,e15c1893190783ad518fdb41f601785a,codec   \n",
              "1    nb|streams,9a11cd55d78f579f46ebcb0dd145c0a3,flags   \n",
              "2      v|l|buffer|*,3f3e8b26a4169560191f26ae2ef1aa2c,s   \n",
              "3             any,abde9a40e05e3f7a393f0b0ad2cb0f95,any   \n",
              "4               s,dc1193eb0b075d165844bab511cdd881,r|d   \n",
              "..                                                 ...   \n",
              "232  test|output|visitor|data|*,d7b61745b69100da0f8...   \n",
              "233           int,16dc3585c345e9feab633f0d3131fd46,int   \n",
              "234      sd|state|*,085d0ad56ed681fae4ccc60f67800571,x   \n",
              "235                                                NaN   \n",
              "236                                                NaN   \n",
              "\n",
              "                                                   192  \\\n",
              "0        ctx,0aa845011e37c4b126d437d5ed245c49,pix|fmts   \n",
              "1      nb|streams,69aaa01fe39611c83389a8e5e43a7211,any   \n",
              "2    v|l|buffer|*,a3a3cc478b079fdb7f900fd811857f07,...   \n",
              "3    openclutils,4acf639dcdd3cbe30042100f3b37f732,c...   \n",
              "4     s,8f0207faaedda7b9e900523dee70ff3d,r|d|context|*   \n",
              "..                                                 ...   \n",
              "232  test|output|visitor|data|*,5b2288d17644a65f4ce...   \n",
              "233           int,113e751d9242bb650e3f773d27eb2673,blk   \n",
              "234             csd,3a52d8194c21ba913791148f80a41d36,x   \n",
              "235                                                NaN   \n",
              "236                                                NaN   \n",
              "\n",
              "                                                   193  \\\n",
              "0    vda|decoder|context|*,052c0d4821ee0d05bccf5b41...   \n",
              "1    nb|streams,a94bc6208b0fa49bc470b37376729c74,av...   \n",
              "2    v|l|buffer|*,00bd42598bcbdd8a1930863a3d7b1c32,...   \n",
              "3    any,2a8a0c95ee63aa6a583d5cb84c87af3f,could|not...   \n",
              "4     s,eb36cbdd11a3013f56f8b3ea2ecc1d83,video|offsets   \n",
              "..                                                 ...   \n",
              "232  test|output|visitor|data|*,43b8c5a011720129a20...   \n",
              "233           int,3376801194932f9ef23e2097788d325a,int   \n",
              "234                ,c34752052b1642e7b25c6d60cd609936,x   \n",
              "235                                                NaN   \n",
              "236                                                NaN   \n",
              "\n",
              "                                                   194  \\\n",
              "0    vda|decoder|context|*,23fc39de27eafe42bca4ef46...   \n",
              "1    output|files,06f1bd4eabc1f73da38b772edea29dca,...   \n",
              "2    v|l|buffer|*,f9d217ae782f4f5d586ac0c2fa9dfa84,...   \n",
              "3    openclutils,06f8437e857ac1bef68b6f605c4ebaf3,o...   \n",
              "4                 s,c0219aeaeda54564403eaa82e28e1972,i   \n",
              "..                                                 ...   \n",
              "232  test|output|visitor|data|*,2f5a805de3437678ffd...   \n",
              "233           int,41a6993b2c1079eb65d99dbd9a50538f,int   \n",
              "234     sd|state|*,be3b43d7f4a43891e0385f2eca2cf07f,sd   \n",
              "235                                                NaN   \n",
              "236                                                NaN   \n",
              "\n",
              "                                                   195  \\\n",
              "0    vda|decoder|context|*,7bb562a008817a14b3d7af78...   \n",
              "1               i,06f1bd4eabc1f73da38b772edea29dca,int   \n",
              "2    avbuf,1bfd45a093edf557ec6568bc84a87a84,v|l|m|m...   \n",
              "3    openclutils,3f0f11734f7e9664eb106f8eaf37151e,s...   \n",
              "4               s,b467e17084d7bdbeb975ce478cb15910,int   \n",
              "..                                                 ...   \n",
              "232  test|output|visitor|data|*,fb778d86d3a9ba87b5e...   \n",
              "233           int,118648e549795e4c8457b25a675a9da5,blk   \n",
              "234  sd|state|*,d5ca1a6cadb392e083136474a8cabc30,state   \n",
              "235                                                NaN   \n",
              "236                                                NaN   \n",
              "\n",
              "                                                   196  \\\n",
              "0    vda|decoder|context|*,a5b3f3a21afb08b8d702c725...   \n",
              "1      output|files,5157f5dd8782709c617b5bede9266431,i   \n",
              "2             avbuf,06df215d9fe49c98a1cdab7f555d9c4d,s   \n",
              "3    openclutils,36af88542d649f62398601fbb3af6e93,c...   \n",
              "4    video|offset|d|x,dba5f15202c88fa6a871f7dce62b1...   \n",
              "..                                                 ...   \n",
              "232  data,b5c4fc420686a27ceb019bfc67040cd9,static|void   \n",
              "233           int,b483870b4df9663d7c37ce0e752ec9ba,any   \n",
              "234          sd,4f27c208767e095fd30422fc396d9a65,state   \n",
              "235                                                NaN   \n",
              "236                                                NaN   \n",
              "\n",
              "                                                   197  \\\n",
              "0    vda|decoder|context|*,592148af243bd6a6ab808ba7...   \n",
              "1    output|files,7cead89fdb93686e2c349f0e6e252a52,int   \n",
              "2    avbuf,1d5cf428d5d6fa32a4fa2c6db788f745,buf|to|...   \n",
              "3    any,cc01a8115c46430c6bff2b5c1eee117e,opencl|er...   \n",
              "4    video|offset|d|x,64fc553d6ec409fb5b0b3e10ec55a...   \n",
              "..                                                 ...   \n",
              "232  test|output|visitor|data|*,26d6543deb0400a2c9e...   \n",
              "233         int,643ebf691653119e2f6e93f3ac558b61,exp|d   \n",
              "234  any,be3b43d7f4a43891e0385f2eca2cf07f,sd|transf...   \n",
              "235                                                NaN   \n",
              "236                                                NaN   \n",
              "\n",
              "                                                   198  \\\n",
              "0    pix|fmt,a3af7a253373961ecb7bfadda315b38c,avctx...   \n",
              "1    av|format|context|*|*,e001fa35c5d306f3a39b7e1e...   \n",
              "2    avbuf,0cc12530ad19a1c3bd62bc08c95e6b52,v|l|buf...   \n",
              "3          any,e0b4e9f9d8d55e4f09cd3b2c05e06f50,status   \n",
              "4    video|offset|d|x,6987a88db505c6f8cb1bf9089fd63...   \n",
              "..                                                 ...   \n",
              "232  const|void|*,1b85f36a332822f0b431ac6940e9d137,...   \n",
              "233     int,be3b43d7f4a43891e0385f2eca2cf07f,nb|groups   \n",
              "234    sd|state|*,f6d0b6632b12d412775fe458ab2112d6,any   \n",
              "235                                                NaN   \n",
              "236                                                NaN   \n",
              "\n",
              "                                                   199  \\\n",
              "0    pix|fmt,31b821cdc05967f6119a717532abca83,av|co...   \n",
              "1    av|format|context|*|*,73d8c567b75b9eac95150b60...   \n",
              "2         avbuf,60fe9c8254210c9bde62275b6445d254,avbuf   \n",
              "3          any,40a223d1669ddfd6ff20aeccd7248368,cl|int   \n",
              "4    video|offset|d|x,be9c5fe89a078748f1052f30b464e...   \n",
              "..                                                 ...   \n",
              "232  const|void|*,2de3047218476da6d4d3f863a66e325f,...   \n",
              "233  any,be3b43d7f4a43891e0385f2eca2cf07f,exponent|...   \n",
              "234  sd|state|*,70ee30fea5756e5fa3f6b8afd45fb8aa,sd...   \n",
              "235                                                NaN   \n",
              "236                                                NaN   \n",
              "\n",
              "                                                   200  \n",
              "0       pix|fmt,208578b7214241402dcb541a729212ce,avctx  \n",
              "1               int,be3b43d7f4a43891e0385f2eca2cf07f,i  \n",
              "2             avbuf,71828aa405adde0e626310bb53dae994,s  \n",
              "3    av|log|error,e8b80f42a57ff812a6cf44feaef78935,...  \n",
              "4    video|offset|d|x,2a5ba24a9ae8717045980493c5f64...  \n",
              "..                                                 ...  \n",
              "232  const|void|*,379bb954b74954a4b5c8339426c92d42,qov  \n",
              "233  ac|encode|context|*,be3b43d7f4a43891e0385f2eca...  \n",
              "234            sd,44e895def0d82ba12071ce1059ff9e0e,any  \n",
              "235                                                NaN  \n",
              "236                                                NaN  \n",
              "\n",
              "[237 rows x 201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72497751-f9f4-4dc4-8d33-f167138861a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>safe</td>\n",
              "      <td>av|codec|context|*,c4b44d57c510ae50e3f1f4c368b...</td>\n",
              "      <td>ctx,7287fb7dd01a251fda0dbd3ae74001c1,vda|decod...</td>\n",
              "      <td>ctx,06f1bd4eabc1f73da38b772edea29dca,vda|decod...</td>\n",
              "      <td>av|codec|context|*,be3b43d7f4a43891e0385f2eca2...</td>\n",
              "      <td>av|codec|context|*,d5ca1a6cadb392e083136474a8c...</td>\n",
              "      <td>avctx,4f27c208767e095fd30422fc396d9a65,priv|data</td>\n",
              "      <td>ctx,e99fb8c78ec60764eb90dd0829f8d24d,av|codec|...</td>\n",
              "      <td>ctx,f37463348f7d92f9744e6a6961c41783,avctx</td>\n",
              "      <td>ctx,6c488522dbe3aabd8a3e396a9ee206d1,priv|data</td>\n",
              "      <td>...</td>\n",
              "      <td>ctx,e15c1893190783ad518fdb41f601785a,codec</td>\n",
              "      <td>ctx,0aa845011e37c4b126d437d5ed245c49,pix|fmts</td>\n",
              "      <td>vda|decoder|context|*,052c0d4821ee0d05bccf5b41...</td>\n",
              "      <td>vda|decoder|context|*,23fc39de27eafe42bca4ef46...</td>\n",
              "      <td>vda|decoder|context|*,7bb562a008817a14b3d7af78...</td>\n",
              "      <td>vda|decoder|context|*,a5b3f3a21afb08b8d702c725...</td>\n",
              "      <td>vda|decoder|context|*,592148af243bd6a6ab808ba7...</td>\n",
              "      <td>pix|fmt,a3af7a253373961ecb7bfadda315b38c,avctx...</td>\n",
              "      <td>pix|fmt,31b821cdc05967f6119a717532abca83,av|co...</td>\n",
              "      <td>pix|fmt,208578b7214241402dcb541a729212ce,avctx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>safe</td>\n",
              "      <td>av|format|context|*|*,c4b44d57c510ae50e3f1f4c3...</td>\n",
              "      <td>int,c4b44d57c510ae50e3f1f4c368b9e232,nb|output...</td>\n",
              "      <td>input|file|*,c4b44d57c510ae50e3f1f4c368b9e232,...</td>\n",
              "      <td>nb|input|files,ef0f501e85af13c3f3106da4bf2906e...</td>\n",
              "      <td>stream|map|*,c4b44d57c510ae50e3f1f4c368b9e232,...</td>\n",
              "      <td>int,c4b44d57c510ae50e3f1f4c368b9e232,nb|stream...</td>\n",
              "      <td>int,8a2b9543a7267ced6831ca9e368e2149,ret</td>\n",
              "      <td>ret,06f1bd4eabc1f73da38b772edea29dca,int</td>\n",
              "      <td>ret,dec237d97608618c9dde47b3d062b847,</td>\n",
              "      <td>...</td>\n",
              "      <td>nb|streams,9a11cd55d78f579f46ebcb0dd145c0a3,flags</td>\n",
              "      <td>nb|streams,69aaa01fe39611c83389a8e5e43a7211,any</td>\n",
              "      <td>nb|streams,a94bc6208b0fa49bc470b37376729c74,av...</td>\n",
              "      <td>output|files,06f1bd4eabc1f73da38b772edea29dca,...</td>\n",
              "      <td>i,06f1bd4eabc1f73da38b772edea29dca,int</td>\n",
              "      <td>output|files,5157f5dd8782709c617b5bede9266431,i</td>\n",
              "      <td>output|files,7cead89fdb93686e2c349f0e6e252a52,int</td>\n",
              "      <td>av|format|context|*|*,e001fa35c5d306f3a39b7e1e...</td>\n",
              "      <td>av|format|context|*|*,73d8c567b75b9eac95150b60...</td>\n",
              "      <td>int,be3b43d7f4a43891e0385f2eca2cf07f,i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>safe</td>\n",
              "      <td>void|*,c4b44d57c510ae50e3f1f4c368b9e232,opaque</td>\n",
              "      <td>unused,ef0f501e85af13c3f3106da4bf2906e0,uint|t|*</td>\n",
              "      <td>v|l|buffer|*,8a2b9543a7267ced6831ca9e368e2149,...</td>\n",
              "      <td>avbuf,06f1bd4eabc1f73da38b772edea29dca,v|l|buf...</td>\n",
              "      <td>void|*,be3b43d7f4a43891e0385f2eca2cf07f,opaque</td>\n",
              "      <td>avbuf,fb9f9251d9b23ebb99f316967367cfc9,void|*</td>\n",
              "      <td>avbuf,7572afe878600f9622b95bc8c58c7cc0,opaque</td>\n",
              "      <td>v|l|buffer|*,0ca71374928d20cc4f4d5ebed5e8f2ea,...</td>\n",
              "      <td>v|l|buffer|*,6277867cae5a4c1f47e5f83fe53e3e7b,...</td>\n",
              "      <td>...</td>\n",
              "      <td>v|l|buffer|*,3f3e8b26a4169560191f26ae2ef1aa2c,s</td>\n",
              "      <td>v|l|buffer|*,a3a3cc478b079fdb7f900fd811857f07,...</td>\n",
              "      <td>v|l|buffer|*,00bd42598bcbdd8a1930863a3d7b1c32,...</td>\n",
              "      <td>v|l|buffer|*,f9d217ae782f4f5d586ac0c2fa9dfa84,...</td>\n",
              "      <td>avbuf,1bfd45a093edf557ec6568bc84a87a84,v|l|m|m...</td>\n",
              "      <td>avbuf,06df215d9fe49c98a1cdab7f555d9c4d,s</td>\n",
              "      <td>avbuf,1d5cf428d5d6fa32a4fa2c6db788f745,buf|to|...</td>\n",
              "      <td>avbuf,0cc12530ad19a1c3bd62bc08c95e6b52,v|l|buf...</td>\n",
              "      <td>avbuf,60fe9c8254210c9bde62275b6445d254,avbuf</td>\n",
              "      <td>avbuf,71828aa405adde0e626310bb53dae994,s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>safe</td>\n",
              "      <td>cl|mem,c4b44d57c510ae50e3f1f4c368b9e232,dst|cl...</td>\n",
              "      <td>uint|t|*,c4b44d57c510ae50e3f1f4c368b9e232,src|buf</td>\n",
              "      <td>size|t,c4b44d57c510ae50e3f1f4c368b9e232,buf|size</td>\n",
              "      <td>cl|int,8a2b9543a7267ced6831ca9e368e2149,status</td>\n",
              "      <td>mapped,7287fb7dd01a251fda0dbd3ae74001c1,void|*</td>\n",
              "      <td>mapped,06f1bd4eabc1f73da38b772edea29dca,void|*</td>\n",
              "      <td>any,be3b43d7f4a43891e0385f2eca2cf07f,gpu|env</td>\n",
              "      <td>any,7abd058903aa9bf4884b27ec00a52472,command|q...</td>\n",
              "      <td>gpu|env,4271746d4835de435dd1a433861f9573,comma...</td>\n",
              "      <td>...</td>\n",
              "      <td>any,abde9a40e05e3f7a393f0b0ad2cb0f95,any</td>\n",
              "      <td>openclutils,4acf639dcdd3cbe30042100f3b37f732,c...</td>\n",
              "      <td>any,2a8a0c95ee63aa6a583d5cb84c87af3f,could|not...</td>\n",
              "      <td>openclutils,06f8437e857ac1bef68b6f605c4ebaf3,o...</td>\n",
              "      <td>openclutils,3f0f11734f7e9664eb106f8eaf37151e,s...</td>\n",
              "      <td>openclutils,36af88542d649f62398601fbb3af6e93,c...</td>\n",
              "      <td>any,cc01a8115c46430c6bff2b5c1eee117e,opencl|er...</td>\n",
              "      <td>any,e0b4e9f9d8d55e4f09cd3b2c05e06f50,status</td>\n",
              "      <td>any,40a223d1669ddfd6ff20aeccd7248368,cl|int</td>\n",
              "      <td>av|log|error,e8b80f42a57ff812a6cf44feaef78935,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vuln</td>\n",
              "      <td>av|format|context|*,c4b44d57c510ae50e3f1f4c368...</td>\n",
              "      <td>atom,ef0f501e85af13c3f3106da4bf2906e0,atom|*</td>\n",
              "      <td>r|d,7287fb7dd01a251fda0dbd3ae74001c1,r|d|conte...</td>\n",
              "      <td>r|d|context|*,be3b43d7f4a43891e0385f2eca2cf07f...</td>\n",
              "      <td>s,06f1bd4eabc1f73da38b772edea29dca,av|format|c...</td>\n",
              "      <td>s,4f27c208767e095fd30422fc396d9a65,priv|data</td>\n",
              "      <td>av|format|context|*,d5ca1a6cadb392e083136474a8...</td>\n",
              "      <td>r|d|context|*,0b46b7d931afa6f3ecf10c618141db9d,s</td>\n",
              "      <td>r|d|context|*,629a2d5ff78f14c6625584db51dc5cff...</td>\n",
              "      <td>...</td>\n",
              "      <td>s,dc1193eb0b075d165844bab511cdd881,r|d</td>\n",
              "      <td>s,8f0207faaedda7b9e900523dee70ff3d,r|d|context|*</td>\n",
              "      <td>s,eb36cbdd11a3013f56f8b3ea2ecc1d83,video|offsets</td>\n",
              "      <td>s,c0219aeaeda54564403eaa82e28e1972,i</td>\n",
              "      <td>s,b467e17084d7bdbeb975ce478cb15910,int</td>\n",
              "      <td>video|offset|d|x,dba5f15202c88fa6a871f7dce62b1...</td>\n",
              "      <td>video|offset|d|x,64fc553d6ec409fb5b0b3e10ec55a...</td>\n",
              "      <td>video|offset|d|x,6987a88db505c6f8cb1bf9089fd63...</td>\n",
              "      <td>video|offset|d|x,be9c5fe89a078748f1052f30b464e...</td>\n",
              "      <td>video|offset|d|x,2a5ba24a9ae8717045980493c5f64...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>safe</td>\n",
              "      <td>data,ef0f501e85af13c3f3106da4bf2906e0,test|out...</td>\n",
              "      <td>const|void|*,c4b44d57c510ae50e3f1f4c368b9e232,...</td>\n",
              "      <td>test|output|visitor|data|*,be3b43d7f4a43891e03...</td>\n",
              "      <td>test|output|visitor|data|*,d5ca1a6cadb392e0831...</td>\n",
              "      <td>data,4f27c208767e095fd30422fc396d9a65,qov</td>\n",
              "      <td>test|output|visitor|data|*,052c0d4821ee0d05bcc...</td>\n",
              "      <td>data,d271abdcd6e33ad941c31d166e68d781,qmp|outp...</td>\n",
              "      <td>qov,a3af7a253373961ecb7bfadda315b38c,qmp|outpu...</td>\n",
              "      <td>test|output|visitor|data|*,be3b43d7f4a43891e03...</td>\n",
              "      <td>...</td>\n",
              "      <td>test|output|visitor|data|*,d7b61745b69100da0f8...</td>\n",
              "      <td>test|output|visitor|data|*,5b2288d17644a65f4ce...</td>\n",
              "      <td>test|output|visitor|data|*,43b8c5a011720129a20...</td>\n",
              "      <td>test|output|visitor|data|*,2f5a805de3437678ffd...</td>\n",
              "      <td>test|output|visitor|data|*,fb778d86d3a9ba87b5e...</td>\n",
              "      <td>data,b5c4fc420686a27ceb019bfc67040cd9,static|void</td>\n",
              "      <td>test|output|visitor|data|*,26d6543deb0400a2c9e...</td>\n",
              "      <td>const|void|*,1b85f36a332822f0b431ac6940e9d137,...</td>\n",
              "      <td>const|void|*,2de3047218476da6d4d3f863a66e325f,...</td>\n",
              "      <td>const|void|*,379bb954b74954a4b5c8339426c92d42,qov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>safe</td>\n",
              "      <td>s,ef0f501e85af13c3f3106da4bf2906e0,ac|encode|c...</td>\n",
              "      <td>blk,7287fb7dd01a251fda0dbd3ae74001c1,int</td>\n",
              "      <td>ch,7287fb7dd01a251fda0dbd3ae74001c1,int</td>\n",
              "      <td>i,7287fb7dd01a251fda0dbd3ae74001c1,int</td>\n",
              "      <td>group|size,7287fb7dd01a251fda0dbd3ae74001c1,int</td>\n",
              "      <td>nb|groups,7287fb7dd01a251fda0dbd3ae74001c1,int</td>\n",
              "      <td>bit|count,7287fb7dd01a251fda0dbd3ae74001c1,int</td>\n",
              "      <td>uint|t|*,8a2b9543a7267ced6831ca9e368e2149,p</td>\n",
              "      <td>int,8a2b9543a7267ced6831ca9e368e2149,delta</td>\n",
              "      <td>...</td>\n",
              "      <td>int,16dc3585c345e9feab633f0d3131fd46,int</td>\n",
              "      <td>int,113e751d9242bb650e3f773d27eb2673,blk</td>\n",
              "      <td>int,3376801194932f9ef23e2097788d325a,int</td>\n",
              "      <td>int,41a6993b2c1079eb65d99dbd9a50538f,int</td>\n",
              "      <td>int,118648e549795e4c8457b25a675a9da5,blk</td>\n",
              "      <td>int,b483870b4df9663d7c37ce0e752ec9ba,any</td>\n",
              "      <td>int,643ebf691653119e2f6e93f3ac558b61,exp|d</td>\n",
              "      <td>int,be3b43d7f4a43891e0385f2eca2cf07f,nb|groups</td>\n",
              "      <td>any,be3b43d7f4a43891e0385f2eca2cf07f,exponent|...</td>\n",
              "      <td>ac|encode|context|*,be3b43d7f4a43891e0385f2eca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>safe</td>\n",
              "      <td>sd|state|*,c4b44d57c510ae50e3f1f4c368b9e232,sd</td>\n",
              "      <td>uint|t,c4b44d57c510ae50e3f1f4c368b9e232,value</td>\n",
              "      <td>int,8a2b9543a7267ced6831ca9e368e2149,i</td>\n",
              "      <td>sd|state|*,be3b43d7f4a43891e0385f2eca2cf07f,sd</td>\n",
              "      <td>sd|state|*,d5ca1a6cadb392e083136474a8cabc30,bdrv</td>\n",
              "      <td>sd,4f27c208767e095fd30422fc396d9a65,bdrv</td>\n",
              "      <td>sd|state|*,be3b43d7f4a43891e0385f2eca2cf07f,sd</td>\n",
              "      <td>sd|state|*,d5ca1a6cadb392e083136474a8cabc30,bdrv</td>\n",
              "      <td>sd,4f27c208767e095fd30422fc396d9a65,bdrv</td>\n",
              "      <td>...</td>\n",
              "      <td>sd|state|*,085d0ad56ed681fae4ccc60f67800571,x</td>\n",
              "      <td>csd,3a52d8194c21ba913791148f80a41d36,x</td>\n",
              "      <td>,c34752052b1642e7b25c6d60cd609936,x</td>\n",
              "      <td>sd|state|*,be3b43d7f4a43891e0385f2eca2cf07f,sd</td>\n",
              "      <td>sd|state|*,d5ca1a6cadb392e083136474a8cabc30,state</td>\n",
              "      <td>sd,4f27c208767e095fd30422fc396d9a65,state</td>\n",
              "      <td>any,be3b43d7f4a43891e0385f2eca2cf07f,sd|transf...</td>\n",
              "      <td>sd|state|*,f6d0b6632b12d412775fe458ab2112d6,any</td>\n",
              "      <td>sd|state|*,70ee30fea5756e5fa3f6b8afd45fb8aa,sd...</td>\n",
              "      <td>sd,44e895def0d82ba12071ce1059ff9e0e,any</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>safe</td>\n",
              "      <td>e,ef0f501e85af13c3f3106da4bf2906e0,event|notif...</td>\n",
              "      <td>e,06f1bd4eabc1f73da38b772edea29dca,event|notif...</td>\n",
              "      <td>e,4f27c208767e095fd30422fc396d9a65,fd</td>\n",
              "      <td>event|notifier|*,d5ca1a6cadb392e083136474a8cab...</td>\n",
              "      <td>event|notifier|get|fd,983bf92b87bd6bebbf29a788...</td>\n",
              "      <td>event|notifier|get|fd,4dcd7965537d2a08f1493560...</td>\n",
              "      <td>event|notifier|get|fd,364d0b992a6a1f0a20e4ef02...</td>\n",
              "      <td>event|notifier|get|fd,46b7815ae44110c7172b6c56...</td>\n",
              "      <td>event|notifier|get|fd,19cc19733c7469a9dfce5373...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>safe</td>\n",
              "      <td>visitor|*,c4b44d57c510ae50e3f1f4c368b9e232,v</td>\n",
              "      <td>name,ef0f501e85af13c3f3106da4bf2906e0,const|ch...</td>\n",
              "      <td>uint|t|*,c4b44d57c510ae50e3f1f4c368b9e232,obj</td>\n",
              "      <td>error|*|*,c4b44d57c510ae50e3f1f4c368b9e232,errp</td>\n",
              "      <td>opts|visitor|*,8a2b9543a7267ced6831ca9e368e214...</td>\n",
              "      <td>opts|visitor|*,be3b43d7f4a43891e0385f2eca2cf07...</td>\n",
              "      <td>visitor|*,be3b43d7f4a43891e0385f2eca2cf07f,v</td>\n",
              "      <td>to|ov,1dbfd33caf135e6c4c08fc7a55af5682,visitor|*</td>\n",
              "      <td>to|ov,111f072b31664dc52f36bbafdf999c3a,v</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237 rows × 201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72497751-f9f4-4dc4-8d33-f167138861a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72497751-f9f4-4dc4-8d33-f167138861a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72497751-f9f4-4dc4-8d33-f167138861a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.read_csv('/content/drive/MyDrive/devign-CodeVul/code2vec-code/merge_all.vectors', sep=\" \", header=None)\n"
      ],
      "metadata": {
        "id": "lknNYVNIlQLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "2z8oc4AJld--",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "e521443b-f101-4c52-ba2a-c850cb5168bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0     0.027397 -0.019585 -0.013053 -0.019990 -0.000280  0.018346  0.010392   \n",
              "1    -0.022493  0.034752 -0.019768 -0.008014 -0.032480  0.008879  0.103854   \n",
              "2     0.024675  0.043641 -0.044374 -0.045136 -0.018894 -0.011160  0.073667   \n",
              "3    -0.019524  0.026950 -0.011974 -0.013604 -0.012386  0.006614  0.041252   \n",
              "4    -0.022803  0.041887 -0.025068 -0.030957 -0.021506  0.001983  0.010321   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1108  0.053500  0.035493 -0.017215 -0.009382 -0.033096  0.004248  0.086625   \n",
              "1109 -0.028406  0.025998 -0.053398 -0.014485 -0.011894 -0.019773  0.057710   \n",
              "1110  0.008020  0.058083 -0.049507 -0.021078 -0.011355  0.045467  0.068319   \n",
              "1111  0.024923  0.058456 -0.021010  0.016159 -0.010869  0.008751  0.084613   \n",
              "1112  0.021734 -0.032089 -0.016246 -0.000460 -0.086942 -0.042308  0.014972   \n",
              "\n",
              "           7         8         9    ...       375       376       377  \\\n",
              "0     0.035380 -0.008344  0.075914  ... -0.018418  0.004052 -0.014924   \n",
              "1     0.022706 -0.060262  0.036250  ... -0.032297 -0.035698 -0.029021   \n",
              "2     0.031929 -0.047267  0.019654  ... -0.022987 -0.015272 -0.012139   \n",
              "3     0.014665 -0.032114  0.029717  ...  0.012167 -0.041464 -0.032086   \n",
              "4     0.039018 -0.059125 -0.002012  ... -0.026096 -0.056039  0.005714   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1108  0.040455 -0.034407  0.025079  ... -0.054857 -0.024456 -0.019349   \n",
              "1109  0.012316 -0.056061  0.030213  ... -0.010136 -0.033195 -0.010198   \n",
              "1110  0.007506 -0.042748  0.013853  ... -0.015225 -0.018784 -0.022156   \n",
              "1111  0.021934  0.004572  0.011758  ... -0.014669 -0.028630 -0.032371   \n",
              "1112  0.054032 -0.065831  0.071117  ...  0.032753 -0.038515 -0.029017   \n",
              "\n",
              "           378       379       380       381       382       383  384  \n",
              "0    -0.022526 -0.017346 -0.043375 -0.015443 -0.010276  0.063321    1  \n",
              "1     0.026015  0.033951  0.020788  0.018774 -0.042694  0.011068    0  \n",
              "2    -0.020569  0.042732 -0.015291 -0.015469 -0.060082  0.040120    0  \n",
              "3     0.016695 -0.024321  0.030963  0.009650 -0.007788  0.016668    1  \n",
              "4    -0.005483  0.002489  0.004314 -0.001680 -0.064337  0.023834    1  \n",
              "...        ...       ...       ...       ...       ...       ...  ...  \n",
              "1108 -0.014026  0.019855 -0.045793 -0.014315 -0.049802  0.039327    1  \n",
              "1109  0.021070  0.034495  0.010973  0.009258 -0.047495  0.014458    1  \n",
              "1110 -0.002408  0.040017  0.020709  0.002150 -0.025339  0.003485    1  \n",
              "1111  0.025256  0.052429  0.008627  0.001961 -0.029948  0.013538    1  \n",
              "1112  0.008190  0.009181 -0.042520  0.079037 -0.002422  0.022014    1  \n",
              "\n",
              "[1113 rows x 385 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-152ec1ed-82e5-436b-9160-5e3d3595775c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "      <th>384</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.027397</td>\n",
              "      <td>-0.019585</td>\n",
              "      <td>-0.013053</td>\n",
              "      <td>-0.019990</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>0.018346</td>\n",
              "      <td>0.010392</td>\n",
              "      <td>0.035380</td>\n",
              "      <td>-0.008344</td>\n",
              "      <td>0.075914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018418</td>\n",
              "      <td>0.004052</td>\n",
              "      <td>-0.014924</td>\n",
              "      <td>-0.022526</td>\n",
              "      <td>-0.017346</td>\n",
              "      <td>-0.043375</td>\n",
              "      <td>-0.015443</td>\n",
              "      <td>-0.010276</td>\n",
              "      <td>0.063321</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.022493</td>\n",
              "      <td>0.034752</td>\n",
              "      <td>-0.019768</td>\n",
              "      <td>-0.008014</td>\n",
              "      <td>-0.032480</td>\n",
              "      <td>0.008879</td>\n",
              "      <td>0.103854</td>\n",
              "      <td>0.022706</td>\n",
              "      <td>-0.060262</td>\n",
              "      <td>0.036250</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032297</td>\n",
              "      <td>-0.035698</td>\n",
              "      <td>-0.029021</td>\n",
              "      <td>0.026015</td>\n",
              "      <td>0.033951</td>\n",
              "      <td>0.020788</td>\n",
              "      <td>0.018774</td>\n",
              "      <td>-0.042694</td>\n",
              "      <td>0.011068</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.024675</td>\n",
              "      <td>0.043641</td>\n",
              "      <td>-0.044374</td>\n",
              "      <td>-0.045136</td>\n",
              "      <td>-0.018894</td>\n",
              "      <td>-0.011160</td>\n",
              "      <td>0.073667</td>\n",
              "      <td>0.031929</td>\n",
              "      <td>-0.047267</td>\n",
              "      <td>0.019654</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.022987</td>\n",
              "      <td>-0.015272</td>\n",
              "      <td>-0.012139</td>\n",
              "      <td>-0.020569</td>\n",
              "      <td>0.042732</td>\n",
              "      <td>-0.015291</td>\n",
              "      <td>-0.015469</td>\n",
              "      <td>-0.060082</td>\n",
              "      <td>0.040120</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.019524</td>\n",
              "      <td>0.026950</td>\n",
              "      <td>-0.011974</td>\n",
              "      <td>-0.013604</td>\n",
              "      <td>-0.012386</td>\n",
              "      <td>0.006614</td>\n",
              "      <td>0.041252</td>\n",
              "      <td>0.014665</td>\n",
              "      <td>-0.032114</td>\n",
              "      <td>0.029717</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012167</td>\n",
              "      <td>-0.041464</td>\n",
              "      <td>-0.032086</td>\n",
              "      <td>0.016695</td>\n",
              "      <td>-0.024321</td>\n",
              "      <td>0.030963</td>\n",
              "      <td>0.009650</td>\n",
              "      <td>-0.007788</td>\n",
              "      <td>0.016668</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.022803</td>\n",
              "      <td>0.041887</td>\n",
              "      <td>-0.025068</td>\n",
              "      <td>-0.030957</td>\n",
              "      <td>-0.021506</td>\n",
              "      <td>0.001983</td>\n",
              "      <td>0.010321</td>\n",
              "      <td>0.039018</td>\n",
              "      <td>-0.059125</td>\n",
              "      <td>-0.002012</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026096</td>\n",
              "      <td>-0.056039</td>\n",
              "      <td>0.005714</td>\n",
              "      <td>-0.005483</td>\n",
              "      <td>0.002489</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>-0.001680</td>\n",
              "      <td>-0.064337</td>\n",
              "      <td>0.023834</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1108</th>\n",
              "      <td>0.053500</td>\n",
              "      <td>0.035493</td>\n",
              "      <td>-0.017215</td>\n",
              "      <td>-0.009382</td>\n",
              "      <td>-0.033096</td>\n",
              "      <td>0.004248</td>\n",
              "      <td>0.086625</td>\n",
              "      <td>0.040455</td>\n",
              "      <td>-0.034407</td>\n",
              "      <td>0.025079</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054857</td>\n",
              "      <td>-0.024456</td>\n",
              "      <td>-0.019349</td>\n",
              "      <td>-0.014026</td>\n",
              "      <td>0.019855</td>\n",
              "      <td>-0.045793</td>\n",
              "      <td>-0.014315</td>\n",
              "      <td>-0.049802</td>\n",
              "      <td>0.039327</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1109</th>\n",
              "      <td>-0.028406</td>\n",
              "      <td>0.025998</td>\n",
              "      <td>-0.053398</td>\n",
              "      <td>-0.014485</td>\n",
              "      <td>-0.011894</td>\n",
              "      <td>-0.019773</td>\n",
              "      <td>0.057710</td>\n",
              "      <td>0.012316</td>\n",
              "      <td>-0.056061</td>\n",
              "      <td>0.030213</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010136</td>\n",
              "      <td>-0.033195</td>\n",
              "      <td>-0.010198</td>\n",
              "      <td>0.021070</td>\n",
              "      <td>0.034495</td>\n",
              "      <td>0.010973</td>\n",
              "      <td>0.009258</td>\n",
              "      <td>-0.047495</td>\n",
              "      <td>0.014458</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1110</th>\n",
              "      <td>0.008020</td>\n",
              "      <td>0.058083</td>\n",
              "      <td>-0.049507</td>\n",
              "      <td>-0.021078</td>\n",
              "      <td>-0.011355</td>\n",
              "      <td>0.045467</td>\n",
              "      <td>0.068319</td>\n",
              "      <td>0.007506</td>\n",
              "      <td>-0.042748</td>\n",
              "      <td>0.013853</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015225</td>\n",
              "      <td>-0.018784</td>\n",
              "      <td>-0.022156</td>\n",
              "      <td>-0.002408</td>\n",
              "      <td>0.040017</td>\n",
              "      <td>0.020709</td>\n",
              "      <td>0.002150</td>\n",
              "      <td>-0.025339</td>\n",
              "      <td>0.003485</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1111</th>\n",
              "      <td>0.024923</td>\n",
              "      <td>0.058456</td>\n",
              "      <td>-0.021010</td>\n",
              "      <td>0.016159</td>\n",
              "      <td>-0.010869</td>\n",
              "      <td>0.008751</td>\n",
              "      <td>0.084613</td>\n",
              "      <td>0.021934</td>\n",
              "      <td>0.004572</td>\n",
              "      <td>0.011758</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.014669</td>\n",
              "      <td>-0.028630</td>\n",
              "      <td>-0.032371</td>\n",
              "      <td>0.025256</td>\n",
              "      <td>0.052429</td>\n",
              "      <td>0.008627</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>-0.029948</td>\n",
              "      <td>0.013538</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1112</th>\n",
              "      <td>0.021734</td>\n",
              "      <td>-0.032089</td>\n",
              "      <td>-0.016246</td>\n",
              "      <td>-0.000460</td>\n",
              "      <td>-0.086942</td>\n",
              "      <td>-0.042308</td>\n",
              "      <td>0.014972</td>\n",
              "      <td>0.054032</td>\n",
              "      <td>-0.065831</td>\n",
              "      <td>0.071117</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032753</td>\n",
              "      <td>-0.038515</td>\n",
              "      <td>-0.029017</td>\n",
              "      <td>0.008190</td>\n",
              "      <td>0.009181</td>\n",
              "      <td>-0.042520</td>\n",
              "      <td>0.079037</td>\n",
              "      <td>-0.002422</td>\n",
              "      <td>0.022014</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1113 rows × 385 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-152ec1ed-82e5-436b-9160-5e3d3595775c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-152ec1ed-82e5-436b-9160-5e3d3595775c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-152ec1ed-82e5-436b-9160-5e3d3595775c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from gensim.models import word2vec, FastText\n",
        "import re\n",
        "from sklearn.metrics import ( accuracy_score, roc_auc_score,\n",
        "                             precision_score, recall_score,\n",
        "                             classification_report\n",
        "                             )\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn import cluster, datasets, mixture\n",
        "from sklearn import metrics\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "code = shuffle(result)\n",
        "print(code.head(5))\n",
        "\n",
        "X = code.iloc[:,:].values\n",
        "\n",
        "z=pd.DataFrame(X)\n",
        "z\n",
        "\n",
        "X=z.loc[:,:383]\n",
        "y=code.iloc[:,-1]\n",
        "print(y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(X)\n",
        "print(scaled)\n",
        "X = pd.DataFrame(scaled)\n",
        "print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sl8ON_LY-a_",
        "outputId": "5cee0879-e2dd-4a9e-9a4c-dfb5a8832dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2         3         4         5         6    \\\n",
            "189  0.002040  0.001650 -0.022966  0.004354 -0.019843 -0.003627  0.065163   \n",
            "153  0.042945  0.015525 -0.028666 -0.003570  0.011589 -0.025428  0.047149   \n",
            "349  0.053688  0.051505 -0.026024 -0.039041 -0.034274  0.021735  0.048307   \n",
            "479  0.025126  0.011205 -0.017889  0.001224 -0.018747  0.011061 -0.019184   \n",
            "319  0.049926  0.040590 -0.026192 -0.024015 -0.013040 -0.029761  0.007440   \n",
            "\n",
            "          7         8         9    ...       375       376       377  \\\n",
            "189  0.016677 -0.016221  0.015496  ... -0.047699 -0.037720 -0.015719   \n",
            "153  0.029694  0.013272  0.023179  ... -0.019071 -0.034846 -0.033863   \n",
            "349  0.061047 -0.048755  0.036706  ... -0.051918 -0.066359 -0.030936   \n",
            "479 -0.002597  0.027240  0.012962  ... -0.060000 -0.067572 -0.016253   \n",
            "319  0.063102  0.005340  0.022210  ... -0.040948 -0.024904 -0.011957   \n",
            "\n",
            "          378       379       380       381       382       383  384  \n",
            "189  0.031102  0.026385  0.012570  0.032765 -0.008811  0.007972    1  \n",
            "153 -0.011773  0.008911 -0.008709 -0.001835 -0.003170  0.043158    1  \n",
            "349 -0.004046  0.022032 -0.003463 -0.036453 -0.053624  0.027480    0  \n",
            "479  0.010045  0.001265 -0.040285  0.005565 -0.016961 -0.000009    0  \n",
            "319 -0.026674  0.043188 -0.033141 -0.001904 -0.013542  0.024790    0  \n",
            "\n",
            "[5 rows x 385 columns]\n",
            "189    1\n",
            "153    1\n",
            "349    0\n",
            "479    0\n",
            "319    0\n",
            "      ..\n",
            "600    1\n",
            "878    1\n",
            "463    1\n",
            "63     0\n",
            "945    0\n",
            "Name: 384, Length: 1113, dtype: int64\n",
            "[[-0.09412702 -0.53886785 -0.10637945 ...  1.30235298  0.67108212\n",
            "  -0.66288073]\n",
            " [ 1.37295133  0.03646838 -0.36830031 ... -0.11109934  0.90066308\n",
            "   0.8855567 ]\n",
            " [ 1.75823606  1.52850867 -0.24690805 ... -1.52526835 -1.15280877\n",
            "   0.19561399]\n",
            " ...\n",
            " [ 0.8846183  -0.41171571  0.52650546 ...  0.44932302  1.0288827\n",
            "  -0.0983595 ]\n",
            " [ 0.5136433  -0.9195183  -0.16867917 ...  1.17669477  1.0739191\n",
            "   0.17663829]\n",
            " [-1.06438171 -0.81064035 -0.03572443 ...  0.23662337  0.03902867\n",
            "  -0.01922669]]\n",
            "           0         1         2         3         4         5         6    \\\n",
            "0    -0.094127 -0.538868 -0.106379  0.782284 -0.102523 -0.381108  0.574642   \n",
            "1     1.372951  0.036468 -0.368300  0.466732  1.165189 -1.457160  0.134621   \n",
            "2     1.758236  1.528509 -0.246908 -0.945794 -0.684567  0.870677  0.162909   \n",
            "3     0.733842 -0.142676  0.126889  0.657635 -0.058320  0.343846 -1.485617   \n",
            "4     1.623303  1.075879 -0.254610 -0.347430  0.171834 -1.671017 -0.835309   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "1108 -0.215234 -0.580626 -1.001449 -0.938297  0.004669 -2.398343 -0.098667   \n",
            "1109  0.210058 -0.876805  0.783780  0.612674  0.493084 -1.809581  0.771422   \n",
            "1110  0.884618 -0.411716  0.526505 -0.463770  0.131299 -0.530033 -1.428572   \n",
            "1111  0.513643 -0.919518 -0.168679  0.253929 -0.320294  0.265859 -0.215727   \n",
            "1112 -1.064382 -0.810640 -0.035724 -0.250406  0.358168 -0.670604  1.062699   \n",
            "\n",
            "           7         8         9    ...       374       375       376  \\\n",
            "0    -0.620786  0.218543 -0.323646  ... -2.011495 -0.691611 -0.405938   \n",
            "1     0.015683  1.190863  0.030818  ... -0.752710  0.390984 -0.299827   \n",
            "2     1.548782 -0.854035  0.654962  ... -0.058742 -0.851134 -1.463648   \n",
            "3    -1.563243  1.651371 -0.440589  ...  1.578219 -1.156780 -1.508435   \n",
            "4     1.649229  0.929360 -0.013875  ... -0.076843 -0.436308  0.067365   \n",
            "...        ...       ...       ...  ...       ...       ...       ...   \n",
            "1108  1.482824  0.026571 -1.199827  ...  0.180238 -0.090631  0.096655   \n",
            "1109 -1.098373  1.881536  1.026947  ...  2.252469 -1.776342  1.278090   \n",
            "1110 -0.529856 -0.536875  0.127497  ...  0.735441  0.293918 -0.590984   \n",
            "1111  0.302743  0.522798  0.166075  ... -0.851157 -0.116334 -0.970932   \n",
            "1112  0.541498 -0.775502  0.074965  ...  0.724864  0.458268  0.423765   \n",
            "\n",
            "           377       378       379       380       381       382       383  \n",
            "0     0.058578  1.239925  0.504386  0.541291  1.302353  0.671082 -0.662881  \n",
            "1    -0.740004 -0.798213 -0.239916 -0.322808 -0.111099  0.900663  0.885557  \n",
            "2    -0.611187 -0.430889  0.318971 -0.109769 -1.525268 -1.152809  0.195614  \n",
            "3     0.035042  0.238949 -0.565581 -1.605012  0.191190  0.339369 -1.014129  \n",
            "4     0.224164 -1.506515  1.220076 -1.314908 -0.113934  0.478529  0.077216  \n",
            "...        ...       ...       ...       ...       ...       ...       ...  \n",
            "1108 -0.970849 -0.971804  1.061403 -0.459500  1.107267  0.677914  1.555210  \n",
            "1109 -0.270193 -0.446801  0.183958 -1.226231  1.200600  2.702680  0.275857  \n",
            "1110  0.159764 -2.120120 -0.936442 -0.609812  0.449323  1.028883 -0.098360  \n",
            "1111 -0.414113 -0.326295 -0.069865  0.195182  1.176695  1.073919  0.176638  \n",
            "1112 -0.649413  0.574105  0.342443  0.371451  0.236623  0.039029 -0.019227  \n",
            "\n",
            "[1113 rows x 384 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b5j7jX_aDMw",
        "outputId": "8924485e-cb47-4b09-e4c7-a7a91d83ba38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1113, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "prec_rec = classification_report(y_pred, y_test)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(prec_rec)\n",
        "print(\"precision\", metrics.average_precision_score(y_test, y_pred))\n",
        "print(\"recall\", metrics.recall_score(y_test, y_pred))\n",
        "print(\"f1\", metrics.f1_score(y_test, y_pred))\n",
        "print(\"f2\", metrics.fbeta_score(y_test,y_pred, beta=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAN_wZTMZSA6",
        "outputId": "315b7a7c-5d9e-4bdc-ebc2-caf4f75fee9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5598802395209581\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.55      0.57       176\n",
            "           1       0.53      0.57      0.55       158\n",
            "\n",
            "    accuracy                           0.56       334\n",
            "   macro avg       0.56      0.56      0.56       334\n",
            "weighted avg       0.56      0.56      0.56       334\n",
            "\n",
            "precision 0.539875009923229\n",
            "recall 0.5325443786982249\n",
            "f1 0.5504587155963304\n",
            "f2 0.539568345323741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPROVED RF\n",
        "\n",
        "\n",
        "rfc=RandomForestClassifier(random_state=42)\n",
        "param_grid = { \n",
        "    'n_estimators': [200, 500],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [8, 16, 32],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
        "CV_rfc.fit(X_train, y_train)\n",
        "CV_rfc.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DwA7i4F4zRH",
        "outputId": "ee0a37ae-e53f-409c-a826-6d14d139f1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 8,\n",
              " 'max_features': 'log2',\n",
              " 'n_estimators': 500}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc1=RandomForestClassifier(random_state=42, max_features='log2', n_estimators= 200, max_depth=8, criterion ='entropy')\n",
        "rfc1.fit(X, y)\n",
        "pred=rfc1.predict(X_test)\n",
        "print(\"Accuracy for Random Forest on CV data: \",accuracy_score(y_test,pred))\n",
        "\n",
        "prec_rec = classification_report(pred, y_test)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(prec_rec)\n",
        "print(\"precision\", metrics.average_precision_score(y_test, pred))\n",
        "print(\"recall\", metrics.recall_score(y_test, pred))\n",
        "print(\"f1\", metrics.f1_score(y_test, pred))\n",
        "print(\"f2\", metrics.fbeta_score(y_test,pred, beta=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0ThaeIs5GCG",
        "outputId": "c19dead5-3ca5-4f40-a74e-c8534b838344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Random Forest on CV data:  0.9880239520958084\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       167\n",
            "           1       0.98      0.99      0.99       167\n",
            "\n",
            "    accuracy                           0.99       334\n",
            "   macro avg       0.99      0.99      0.99       334\n",
            "weighted avg       0.99      0.99      0.99       334\n",
            "\n",
            "precision 0.9853488289692803\n",
            "recall 0.9822485207100592\n",
            "f1 0.988095238095238\n",
            "f2 0.9845788849347569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pruning \n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn import cluster, datasets, mixture\n",
        "from sklearn import metrics\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "LHYeRtV6aBvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrunedRandomForest:\n",
        "\n",
        "\n",
        "    def __init__(self, n_clusters = 10 , n_estimators = 500, cv = 5):\n",
        "        \"\"\" this is the unpruned random forest \"\"\"\n",
        "        self.rf = RandomForestClassifier(n_estimators = n_estimators)\n",
        "\n",
        "        \"\"\" this is the final pruned random forest \"\"\"\n",
        "        self.prf = None \n",
        "        self.prf1 = None \n",
        "\n",
        "        \n",
        "        \"\"\"this is a list of decision tree object present in original unpruned random forest\"\"\"\n",
        "        self.decision_trees = None \n",
        "        \n",
        "        \"\"\"number of clusters for pruning\"\"\"\n",
        "        self.n_clusters = n_clusters \n",
        "        \n",
        "        \n",
        "\n",
        "        \"\"\" \n",
        "            this contains dictionary of lists where each element of dictionary represetns a\n",
        "            pair (cluster_idx, tree_idx_list)\n",
        "\n",
        "            where tree_idx_list is list of decision tree indices and cluster_idx is index of cluster \n",
        "            e.g.\n",
        "            \n",
        "            {\n",
        "                0 : [2, 0]\n",
        "                1 : [1, 3]\n",
        "            }\n",
        "            it means decision tree at 2nd index and 0th index \n",
        "            are in same cluster similarly 1st and 3rd in second cluster\n",
        "\n",
        "        \"\"\" \n",
        "        self.clusters = {}\n",
        "        \n",
        "        self.cv = cv\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "            Information about all trees in the random forest present in this \n",
        "            form\n",
        "            {\n",
        "                idx : { \n",
        "                    accuracy : 89.34\n",
        "                    cluster : 2\n",
        "                }\n",
        "\n",
        "                idx1 : {\n",
        "\n",
        "                }\n",
        "            }\n",
        "        \"\"\"\n",
        "        self.info = {}\n",
        "        #self.maxs_accuracy = {}\n",
        "        self.fimps = None\n",
        "\n",
        "    def prune(self):\n",
        "        pass\n",
        "\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.rf.fit(X,y)\n",
        "        self.decision_trees = self.rf.estimators_\n",
        "        self.create_feature_imp_clusters()\n",
        "        self.create_feature_imp_clusters1()\n",
        "        self.create_fimp_agglomerative()\n",
        "        self.create_fimp_gaussian()\n",
        "        self.create_fimp_spectral_clustering()\n",
        "        #self.plot_clusters(X,y)\n",
        "        #self.all_algorithms()\n",
        "\n",
        "        self.fill_info(X, y)\n",
        "        #self.max_accuracy(X,y)\n",
        "        self.prune()\n",
        "\n",
        "    def fill_info(self, X, y):\n",
        "        for idx, tree in enumerate(self.decision_trees):\n",
        "            self.info[idx] = self.fill_for_tree(tree, X, y)\n",
        "\n",
        "        for cluster_idx in self.clusters:\n",
        "            for tree_idx in self.clusters[cluster_idx]:\n",
        "                self.info[tree_idx][\"cluster_idx\"] = cluster_idx \n",
        "       \n",
        "\n",
        "    \"\"\"\n",
        "        {\n",
        "            \"accuracy\" : 98.45,\n",
        "            \n",
        "        } \n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def fill_for_tree(self, tree, X, y):\n",
        "        info = {}\n",
        "        mean_score = cross_val_score(tree, X, y, cv=self.cv).mean()\n",
        "        info[\"accuracy\"] = (mean_score)\n",
        "        return info\n",
        "\n",
        "    def predict(self, X):\n",
        "        if(self.prf is None):\n",
        "            return None\n",
        "        \n",
        "        return self.prf.predict(X)\n",
        "\n",
        "    \n",
        "    def get_decision_trees(self):\n",
        "        return self.decision_trees\n",
        "\n",
        "    def get_feature_imps_from_rf(self):\n",
        "        feature_imp_list = []\n",
        "        dts = self.get_decision_trees()\n",
        "        for tree in dts:\n",
        "            feature_imp_list.append(tree.feature_importances_)\n",
        "        return feature_imp_list\n",
        "\n",
        "    def create_feature_imp_clusters(self):\n",
        "        fimps = self.get_feature_imps_from_rf()\n",
        "        #print(fimps)\n",
        "        #print(\"KMEANS\")\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=0).fit(fimps)\n",
        "\n",
        "        print(\" fimps len = \" + str(len(fimps)))\n",
        "        labels = kmeans.labels_\n",
        "        score = silhouette_score(fimps, labels, metric='euclidean')\n",
        "        print('Silhouetter Score: %.3f' % score)\n",
        "        #print(labels)\n",
        "        print(\" kmeans.labels_ len = \" + str(len(kmeans.labels_)))\n",
        "        for (tree_idx, cluster_idx) in enumerate(kmeans.labels_):\n",
        "            if cluster_idx in self.clusters:\n",
        "                self.clusters[cluster_idx].append(tree_idx)\n",
        "            else:\n",
        "                self.clusters[cluster_idx] = [tree_idx]\n",
        "        \n",
        "    def create_feature_imp_clusters1(self):\n",
        "        fimps = self.get_feature_imps_from_rf()\n",
        "        #print(\"DBSCAN-\")\n",
        "        dbscan = DBSCAN().fit(fimps)\n",
        "\n",
        "        print(\" fimps len = \" + str(len(fimps)))\n",
        "        labels = dbscan.labels_\n",
        "        #print(labels)\n",
        "        print(\" dbscan.labels_ len = \" + str(len(labels)))\n",
        "        \n",
        "\n",
        "    def create_fimp_agglomerative(self):\n",
        "        fimps = self.get_feature_imps_from_rf()\n",
        "        #print(\"AGGLOMERATIVE CLUSTERING-\")\n",
        "        groups = AgglomerativeClustering(n_clusters=self.n_clusters).fit(fimps)\n",
        "        #print(groups.labels_)\n",
        "\n",
        "    def create_fimp_gaussian(self):\n",
        "      fimps = self.get_feature_imps_from_rf()\n",
        "      #print(\"GAUSSIAN CLUSTERING-\")\n",
        "      gmm =GaussianMixture(n_components = 5)\n",
        "      gmm.fit(fimps)\n",
        "      labelsgmm = gmm.predict(fimps)\n",
        "      #print(labelsgmm)\n",
        "      \n",
        "    def create_fimp_spectral_clustering(self):\n",
        "      fimps = self.get_feature_imps_from_rf()\n",
        "      models = SpectralClustering(n_clusters=6, random_state=25, n_neighbors=8, affinity='nearest_neighbors')\n",
        "      models.fit(fimps)\n",
        "      labelsx = models.fit_predict(fimps)\n",
        "      #print(labelsx)\n"
      ],
      "metadata": {
        "id": "YLNA5EPnab9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prf = PrunedRandomForest(10, 100)\n",
        "prf.fit(X, y)\n",
        "print('KMEANS-')\n",
        "for cluster_idx in prf.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf.clusters[cluster_idx])\n",
        "\n",
        "prf1 = PrunedRandomForest()\n",
        "prf1.fit(X, y)\n",
        "print('DBSCAN-')\n",
        "for cluster_idx in prf1.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf1.clusters[cluster_idx])\n",
        "\n",
        "prf2 = PrunedRandomForest()\n",
        "prf2.fit(X, y)\n",
        "print('AGGLO')\n",
        "for cluster_idx in prf2.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf2.clusters[cluster_idx])\n",
        "\n",
        "prf3 = PrunedRandomForest()\n",
        "prf3.fit(X,y)\n",
        "print('Gaussian')\n",
        "for cluster_idx in prf3.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf3.clusters[cluster_idx])\n",
        "\n",
        "prf4 = PrunedRandomForest()\n",
        "prf4.fit(X,y)\n",
        "print('spectral clustering')\n",
        "for cluster_idx in prf4.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf4.clusters[cluster_idx])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yrpb_npai10",
        "outputId": "b1a8f68d-0743-4c76-a9d9-9e9af161b14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " fimps len = 100\n",
            "Silhouetter Score: 0.001\n",
            " kmeans.labels_ len = 100\n",
            " fimps len = 100\n",
            " dbscan.labels_ len = 100\n",
            "KMEANS-\n",
            "1 ==>  [0, 6, 19, 21, 29, 35, 45, 48, 50, 70, 81, 83, 91]\n",
            "5 ==>  [1, 13, 15, 17, 18, 27, 34, 36, 42, 61, 84, 97, 98, 99]\n",
            "9 ==>  [2, 3, 14, 24, 28, 31, 44, 55, 69, 74, 75, 92, 93, 95]\n",
            "2 ==>  [4, 30, 33, 39, 40, 54, 60]\n",
            "8 ==>  [5, 7, 10, 11, 62, 66, 67, 72, 82, 85, 86, 89, 90]\n",
            "4 ==>  [8, 26, 37, 38, 41, 47, 59, 63, 64, 73, 76, 77, 79, 80, 88, 94]\n",
            "3 ==>  [9, 16, 43, 49, 53, 58, 65, 71]\n",
            "6 ==>  [12, 20, 22, 25, 32, 51]\n",
            "7 ==>  [23, 46, 52, 56, 57, 68, 78, 87]\n",
            "0 ==>  [96]\n",
            " fimps len = 500\n",
            "Silhouetter Score: 0.004\n",
            " kmeans.labels_ len = 500\n",
            " fimps len = 500\n",
            " dbscan.labels_ len = 500\n",
            "DBSCAN-\n",
            "6 ==>  [0, 6, 35, 43, 44, 61, 75, 78, 81, 97, 117, 119, 141, 147, 162, 165, 194, 196, 213, 218, 231, 237, 241, 265, 267, 276, 286, 295, 305, 325, 333, 335, 336, 351, 357, 358, 363, 366, 389, 394, 397, 401, 417, 429, 432, 439, 456, 467, 468, 475, 480, 485, 486, 487, 497]\n",
            "9 ==>  [1, 3, 18, 25, 28, 37, 45, 50, 52, 54, 59, 60, 67, 68, 69, 82, 88, 90, 98, 109, 113, 120, 122, 128, 151, 166, 167, 170, 176, 180, 192, 202, 210, 217, 219, 221, 222, 225, 236, 239, 253, 258, 260, 268, 272, 282, 304, 315, 319, 321, 324, 341, 346, 347, 349, 359, 362, 365, 372, 374, 375, 378, 379, 381, 399, 400, 404, 413, 415, 416, 426, 427, 433, 448, 450, 451, 472, 474, 499]\n",
            "0 ==>  [2, 8, 12, 26, 30, 32, 46, 51, 58, 71, 91, 99, 101, 116, 121, 125, 139, 150, 164, 171, 181, 204, 208, 209, 220, 228, 242, 249, 254, 255, 269, 273, 278, 280, 281, 284, 292, 293, 298, 300, 303, 311, 312, 313, 326, 331, 343, 352, 356, 370, 407, 418, 444, 446, 457, 461, 463, 482, 489]\n",
            "2 ==>  [4, 7, 11, 13, 15, 17, 24, 27, 39, 41, 48, 56, 57, 62, 63, 72, 76, 79, 85, 86, 94, 95, 102, 118, 127, 131, 132, 138, 143, 154, 157, 168, 173, 183, 190, 195, 197, 203, 206, 216, 223, 224, 238, 247, 261, 266, 270, 274, 275, 283, 287, 301, 306, 314, 322, 323, 329, 337, 354, 355, 371, 376, 377, 383, 395, 396, 398, 402, 405, 408, 410, 412, 419, 420, 422, 428, 434, 443, 447, 449, 454, 459, 473, 477, 498]\n",
            "8 ==>  [5, 10, 38, 64, 70, 83, 100, 103, 106, 115, 123, 126, 130, 134, 137, 145, 155, 158, 160, 172, 178, 186, 191, 207, 211, 229, 230, 232, 243, 245, 250, 256, 257, 279, 290, 317, 320, 327, 328, 348, 368, 382, 392, 425, 437, 442, 445, 458, 466, 470, 478, 494]\n",
            "4 ==>  [9, 19, 29, 34, 40, 74, 92, 96, 104, 110, 135, 144, 188, 193, 198, 235, 240, 246, 271, 294, 296, 316, 344, 353, 360, 364, 384, 385, 386, 387, 390, 421, 435, 436, 460, 464, 479, 488, 491]\n",
            "1 ==>  [14, 23, 80, 84, 111, 114, 149, 226, 252, 259, 277, 308, 350, 361, 373, 393, 406, 424, 431, 453, 471, 481]\n",
            "5 ==>  [16, 22, 31, 33, 49, 66, 77, 107, 112, 129, 136, 146, 152, 163, 179, 182, 184, 189, 201, 205, 212, 215, 244, 248, 263, 264, 288, 291, 297, 302, 330, 342, 369, 380, 388, 391, 403, 440, 441, 452, 465, 476, 483, 484, 490, 492, 495, 496]\n",
            "3 ==>  [20, 21, 36, 42, 55, 65, 73, 89, 93, 108, 124, 140, 142, 153, 156, 159, 161, 169, 199, 200, 227, 234, 251, 262, 285, 289, 299, 307, 309, 310, 318, 332, 334, 338, 345, 367, 414, 423, 438, 455, 462]\n",
            "7 ==>  [47, 53, 87, 105, 133, 148, 174, 175, 177, 185, 187, 214, 233, 339, 340, 409, 411, 430, 469, 493]\n",
            " fimps len = 500\n",
            "Silhouetter Score: 0.001\n",
            " kmeans.labels_ len = 500\n",
            " fimps len = 500\n",
            " dbscan.labels_ len = 500\n",
            "AGGLO\n",
            "4 ==>  [0, 15, 23, 35, 45, 47, 51, 53, 58, 67, 80, 129, 143, 147, 162, 174, 193, 210, 222, 223, 227, 235, 244, 277, 278, 281, 284, 290, 292, 297, 302, 317, 319, 330, 371, 388, 425, 433, 435, 437, 445, 452, 463, 464, 486, 490, 492, 497]\n",
            "5 ==>  [1, 3, 13, 17, 22, 24, 25, 28, 29, 31, 41, 42, 43, 48, 54, 56, 64, 86, 88, 91, 100, 112, 117, 127, 128, 132, 136, 154, 160, 163, 181, 183, 199, 201, 215, 225, 236, 239, 253, 254, 269, 291, 293, 295, 307, 326, 342, 344, 354, 363, 378, 379, 384, 397, 399, 401, 417, 421, 429, 430, 434, 436, 444, 458, 460, 466, 472, 478, 491]\n",
            "9 ==>  [2, 6, 16, 18, 21, 32, 36, 39, 50, 52, 55, 59, 71, 76, 77, 78, 79, 84, 85, 99, 104, 110, 119, 123, 126, 133, 138, 146, 150, 158, 159, 161, 165, 169, 172, 177, 178, 186, 189, 202, 211, 214, 218, 224, 229, 234, 246, 252, 255, 263, 264, 265, 276, 286, 294, 296, 311, 320, 325, 345, 351, 356, 357, 366, 370, 373, 375, 380, 383, 387, 389, 400, 405, 407, 418, 428, 447, 450, 453, 465, 467, 470, 471, 474, 476, 483, 484, 493]\n",
            "2 ==>  [4, 12, 20, 27, 38, 57, 62, 90, 98, 106, 111, 114, 122, 144, 168, 180, 188, 190, 195, 197, 206, 209, 221, 231, 232, 282, 299, 300, 304, 305, 310, 323, 343, 347, 348, 355, 374, 376, 385, 390, 393, 406, 443, 446, 448, 449, 454, 457, 459, 475, 479, 481, 482, 494, 496, 498]\n",
            "8 ==>  [5, 9, 10, 11, 40, 65, 70, 75, 92, 93, 120, 121, 131, 142, 149, 156, 184, 191, 194, 230, 245, 250, 256, 257, 261, 270, 283, 287, 301, 312, 318, 321, 327, 331, 349, 365, 377, 381, 411, 416, 419, 420, 423, 469, 477]\n",
            "6 ==>  [7, 14, 19, 33, 37, 49, 61, 63, 66, 69, 72, 73, 74, 81, 83, 87, 89, 95, 96, 97, 107, 109, 115, 116, 118, 124, 125, 139, 141, 145, 148, 155, 157, 170, 171, 175, 176, 179, 185, 192, 198, 208, 212, 213, 216, 237, 247, 249, 258, 259, 262, 268, 272, 273, 303, 306, 308, 309, 324, 329, 332, 336, 338, 340, 352, 353, 361, 367, 368, 392, 396, 398, 402, 403, 404, 409, 410, 413, 415, 438, 440, 442, 455, 456, 462, 468, 473, 485, 488, 499]\n",
            "3 ==>  [8, 30, 46, 94, 101, 140, 151, 152, 167, 196, 203, 205, 217, 219, 226, 228, 233, 240, 241, 243, 248, 260, 274, 275, 279, 313, 315, 339, 346, 358, 360, 369, 391, 424, 489]\n",
            "1 ==>  [26, 44, 103, 130, 153, 166, 173, 182, 187, 200, 207, 238, 251, 266, 267, 271, 280, 285, 314, 316, 334, 362, 386, 395, 408, 414, 422, 426, 461, 487]\n",
            "0 ==>  [34, 60, 105, 108, 164, 289, 322, 333, 335, 350, 364, 372, 394, 427, 439]\n",
            "7 ==>  [68, 82, 102, 113, 134, 135, 137, 204, 220, 242, 288, 298, 328, 337, 341, 359, 382, 412, 431, 432, 441, 451, 480, 495]\n",
            " fimps len = 500\n",
            "Silhouetter Score: 0.001\n",
            " kmeans.labels_ len = 500\n",
            " fimps len = 500\n",
            " dbscan.labels_ len = 500\n",
            "Gaussian\n",
            "9 ==>  [0, 5, 6, 18, 26, 35, 37, 46, 67, 74, 83, 90, 94, 95, 96, 103, 105, 106, 124, 125, 134, 148, 161, 173, 174, 179, 190, 196, 204, 208, 210, 212, 215, 222, 227, 231, 239, 245, 254, 265, 267, 274, 283, 286, 288, 291, 298, 300, 303, 305, 321, 329, 333, 335, 338, 344, 345, 347, 349, 360, 369, 371, 383, 387, 389, 403, 405, 410, 414, 416, 418, 419, 421, 434, 435, 436, 437, 440, 442, 446, 454, 464, 466, 470, 478, 491]\n",
            "0 ==>  [1, 9, 12, 20, 27, 28, 32, 33, 34, 38, 39, 43, 47, 49, 54, 60, 65, 66, 81, 86, 88, 93, 100, 111, 112, 128, 129, 153, 158, 164, 176, 186, 187, 188, 191, 193, 197, 200, 201, 205, 223, 225, 226, 229, 238, 248, 260, 271, 277, 280, 296, 299, 306, 309, 318, 327, 330, 334, 337, 339, 340, 341, 350, 353, 359, 361, 364, 368, 370, 378, 382, 390, 391, 396, 398, 400, 409, 411, 412, 422, 426, 427, 433, 439, 443, 444, 448, 452, 455, 456, 461, 462, 463, 477, 481, 482, 485, 487, 492]\n",
            "1 ==>  [2, 7, 10, 78, 84, 92, 108, 118, 133, 142, 143, 145, 159, 198, 199, 230, 232, 240, 270, 294, 315, 381, 417, 438, 441, 450, 472, 483, 490]\n",
            "7 ==>  [3, 30, 42, 44, 62, 70, 72, 85, 102, 113, 114, 121, 140, 154, 156, 183, 203, 206, 207, 224, 228, 234, 243, 251, 266, 284, 289, 304, 328, 346, 363, 365, 366, 386, 393, 413, 415, 420, 425, 428, 429, 453, 458, 460]\n",
            "3 ==>  [4, 79, 138, 167, 219, 310, 320, 352, 379, 457, 465, 474, 476, 497]\n",
            "6 ==>  [8, 19, 31, 40, 41, 61, 63, 68, 77, 101, 104, 117, 123, 130, 139, 141, 150, 155, 163, 168, 170, 182, 184, 185, 211, 235, 264, 279, 293, 297, 308, 351, 354, 356, 367, 372, 374, 384, 392, 397, 404, 430, 431, 451, 467, 475, 480, 488]\n",
            "8 ==>  [11, 21, 22, 45, 52, 98, 99, 120, 136, 144, 162, 165, 166, 171, 172, 202, 221, 241, 249, 256, 258, 262, 263, 269, 282, 301, 302, 307, 314, 319, 323, 325, 331, 332, 342, 362, 376, 377, 385, 395, 399, 407, 445, 449, 468, 479, 484, 494, 496]\n",
            "4 ==>  [13, 14, 15, 24, 29, 50, 55, 58, 64, 69, 76, 82, 87, 89, 97, 107, 116, 189, 195, 217, 242, 252, 255, 281, 285, 311, 313, 355, 375, 401, 406, 423, 432, 489, 493]\n",
            "5 ==>  [16, 17, 23, 48, 53, 57, 59, 71, 73, 75, 91, 109, 110, 126, 131, 132, 137, 146, 149, 157, 160, 175, 177, 180, 181, 194, 213, 214, 216, 218, 220, 244, 246, 250, 253, 261, 268, 275, 276, 278, 287, 290, 292, 312, 317, 322, 326, 336, 373, 380, 388, 394, 408, 424, 471, 473, 486, 495, 498]\n",
            "2 ==>  [25, 36, 51, 56, 80, 115, 119, 122, 127, 135, 147, 151, 152, 169, 178, 192, 209, 233, 236, 237, 247, 257, 259, 272, 273, 295, 316, 324, 343, 348, 357, 358, 402, 447, 459, 469, 499]\n",
            " fimps len = 500\n",
            "Silhouetter Score: -0.000\n",
            " kmeans.labels_ len = 500\n",
            " fimps len = 500\n",
            " dbscan.labels_ len = 500\n",
            "spectral clustering\n",
            "3 ==>  [0, 6, 8, 12, 13, 17, 26, 27, 31, 34, 40, 57, 61, 68, 73, 77, 79, 89, 95, 98, 107, 116, 117, 118, 121, 123, 128, 135, 136, 137, 151, 169, 171, 172, 175, 176, 189, 194, 214, 215, 229, 237, 238, 240, 249, 250, 257, 258, 260, 266, 268, 269, 272, 274, 288, 292, 296, 301, 312, 325, 330, 335, 339, 340, 341, 343, 346, 348, 356, 361, 370, 374, 375, 384, 391, 393, 408, 414, 418, 427, 430, 432, 436, 439, 442, 444, 455, 461, 462, 478, 479, 487, 488, 490]\n",
            "9 ==>  [1, 2, 10, 16, 22, 23, 33, 37, 38, 44, 47, 49, 54, 66, 69, 70, 83, 86, 92, 94, 102, 106, 113, 120, 127, 133, 138, 141, 144, 146, 147, 156, 163, 168, 173, 179, 182, 185, 186, 187, 188, 190, 192, 195, 198, 200, 202, 208, 209, 213, 217, 218, 219, 221, 226, 228, 230, 236, 239, 244, 245, 246, 248, 252, 255, 256, 259, 263, 264, 278, 279, 281, 282, 285, 289, 291, 298, 300, 302, 303, 304, 306, 310, 314, 316, 318, 321, 322, 326, 333, 334, 337, 352, 354, 359, 365, 366, 369, 373, 378, 394, 395, 399, 400, 403, 404, 407, 412, 415, 422, 426, 429, 433, 434, 435, 438, 441, 445, 449, 451, 458, 459, 460, 464, 467, 469, 480, 482, 484, 486, 494, 495, 497]\n",
            "1 ==>  [3, 14, 29, 32, 42, 51, 60, 63, 64, 93, 100, 108, 115, 130, 131, 150, 154, 159, 165, 197, 206, 210, 222, 224, 227, 231, 232, 247, 251, 253, 270, 275, 276, 283, 287, 319, 327, 328, 329, 349, 350, 351, 362, 382, 389, 397, 398, 419, 421, 424, 440, 447, 456, 470, 473, 481, 483]\n",
            "5 ==>  [4, 21, 39, 43, 55, 59, 62, 67, 132, 134, 152, 162, 193, 196, 203, 220, 225, 233, 243, 271, 294, 297, 324, 331, 355, 360, 392, 396, 466, 491, 498]\n",
            "0 ==>  [5, 41, 72, 112, 148, 157, 170, 262, 317, 358, 411, 425]\n",
            "8 ==>  [7, 9, 15, 19, 35, 36, 52, 53, 75, 76, 82, 84, 87, 91, 101, 104, 110, 122, 126, 155, 158, 164, 177, 180, 183, 184, 201, 204, 207, 212, 235, 254, 261, 273, 277, 299, 305, 308, 311, 313, 345, 347, 353, 371, 380, 381, 383, 386, 387, 410, 416, 417, 420, 437, 453, 454, 457, 463, 471, 472, 476, 492, 493, 496, 499]\n",
            "2 ==>  [11, 18, 20, 24, 25, 50, 56, 65, 71, 74, 97, 99, 103, 111, 114, 129, 140, 145, 149, 161, 174, 178, 191, 216, 234, 265, 280, 286, 290, 293, 307, 315, 320, 336, 342, 344, 357, 379, 385, 405, 409, 428, 446, 448, 450, 465, 468, 474, 475, 485, 489]\n",
            "6 ==>  [28, 45, 46, 48, 78, 80, 81, 88, 90, 109, 119, 124, 125, 139, 160, 166, 167, 211, 223, 241, 267, 284, 332, 363, 367, 372, 376, 388, 402, 406, 413, 423, 431, 443, 452]\n",
            "4 ==>  [30, 58, 85, 96, 105, 142, 153, 199, 309, 323, 338, 368, 477]\n",
            "7 ==>  [143, 181, 205, 242, 295, 364, 377, 390, 401]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prf.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aCYDgumanrU",
        "outputId": "0b7aef6c-4a16-4515-cd4c-0435da364d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'accuracy': 0.5210721932695026, 'cluster_idx': 1},\n",
              " 1: {'accuracy': 0.5265664767906919, 'cluster_idx': 5},\n",
              " 2: {'accuracy': 0.5094735991596978, 'cluster_idx': 9},\n",
              " 3: {'accuracy': 0.5139821435785561, 'cluster_idx': 9},\n",
              " 4: {'accuracy': 0.5156789076071588, 'cluster_idx': 2},\n",
              " 5: {'accuracy': 0.5183412111663233, 'cluster_idx': 8},\n",
              " 6: {'accuracy': 0.5345614672968932, 'cluster_idx': 1},\n",
              " 7: {'accuracy': 0.5129721649901022, 'cluster_idx': 8},\n",
              " 8: {'accuracy': 0.5121157031470933, 'cluster_idx': 4},\n",
              " 9: {'accuracy': 0.5265543570476307, 'cluster_idx': 3},\n",
              " 10: {'accuracy': 0.515670827778451, 'cluster_idx': 8},\n",
              " 11: {'accuracy': 0.530949783864582, 'cluster_idx': 8},\n",
              " 12: {'accuracy': 0.49512382337494437, 'cluster_idx': 6},\n",
              " 13: {'accuracy': 0.5112309619036076, 'cluster_idx': 5},\n",
              " 14: {'accuracy': 0.5408960530036764, 'cluster_idx': 9},\n",
              " 15: {'accuracy': 0.5076273583000039, 'cluster_idx': 5},\n",
              " 16: {'accuracy': 0.5058659556417403, 'cluster_idx': 3},\n",
              " 17: {'accuracy': 0.5112956005332687, 'cluster_idx': 5},\n",
              " 18: {'accuracy': 0.5031996121682221, 'cluster_idx': 5},\n",
              " 19: {'accuracy': 0.5121520623762776, 'cluster_idx': 1},\n",
              " 20: {'accuracy': 0.5057891972690178, 'cluster_idx': 6},\n",
              " 21: {'accuracy': 0.5148264856785036, 'cluster_idx': 1},\n",
              " 22: {'accuracy': 0.5193309901830082, 'cluster_idx': 6},\n",
              " 23: {'accuracy': 0.5085444188583204, 'cluster_idx': 7},\n",
              " 24: {'accuracy': 0.5156869874358663, 'cluster_idx': 9},\n",
              " 25: {'accuracy': 0.4986991475780713, 'cluster_idx': 6},\n",
              " 26: {'accuracy': 0.5084595806568901, 'cluster_idx': 4},\n",
              " 27: {'accuracy': 0.5588211529915565, 'cluster_idx': 5},\n",
              " 28: {'accuracy': 0.4986749080919484, 'cluster_idx': 9},\n",
              " 29: {'accuracy': 0.5076071587282349, 'cluster_idx': 1},\n",
              " 30: {'accuracy': 0.5121035834040318, 'cluster_idx': 2},\n",
              " 31: {'accuracy': 0.4968529067183776, 'cluster_idx': 9},\n",
              " 32: {'accuracy': 0.5058578758130328, 'cluster_idx': 6},\n",
              " 33: {'accuracy': 0.48875691835333085, 'cluster_idx': 2},\n",
              " 34: {'accuracy': 0.5094735991596979, 'cluster_idx': 5},\n",
              " 35: {'accuracy': 0.5228982345574273, 'cluster_idx': 1},\n",
              " 36: {'accuracy': 0.5229224740435503, 'cluster_idx': 5},\n",
              " 37: {'accuracy': 0.5175291883812063, 'cluster_idx': 4},\n",
              " 38: {'accuracy': 0.5166282874803054, 'cluster_idx': 4},\n",
              " 39: {'accuracy': 0.5282592009049408, 'cluster_idx': 2},\n",
              " 40: {'accuracy': 0.5031592130246839, 'cluster_idx': 2},\n",
              " 41: {'accuracy': 0.5318870439946672, 'cluster_idx': 4},\n",
              " 42: {'accuracy': 0.5147982062780269, 'cluster_idx': 5},\n",
              " 43: {'accuracy': 0.5076152385569427, 'cluster_idx': 3},\n",
              " 44: {'accuracy': 0.5157112269219892, 'cluster_idx': 9},\n",
              " 45: {'accuracy': 0.4950551448309296, 'cluster_idx': 1},\n",
              " 46: {'accuracy': 0.5516583848422414, 'cluster_idx': 7},\n",
              " 47: {'accuracy': 0.5246879166161678, 'cluster_idx': 4},\n",
              " 48: {'accuracy': 0.520191491940371, 'cluster_idx': 1},\n",
              " 49: {'accuracy': 0.5102937017735224, 'cluster_idx': 3},\n",
              " 50: {'accuracy': 0.5202076515977863, 'cluster_idx': 1},\n",
              " 51: {'accuracy': 0.5453278390498121, 'cluster_idx': 6},\n",
              " 52: {'accuracy': 0.54265745566194, 'cluster_idx': 7},\n",
              " 53: {'accuracy': 0.5192582717246395, 'cluster_idx': 3},\n",
              " 54: {'accuracy': 0.5174645497515453, 'cluster_idx': 2},\n",
              " 55: {'accuracy': 0.523827414858805, 'cluster_idx': 9},\n",
              " 56: {'accuracy': 0.5229022744717812, 'cluster_idx': 7},\n",
              " 57: {'accuracy': 0.506706257827334, 'cluster_idx': 7},\n",
              " 58: {'accuracy': 0.5166686866238436, 'cluster_idx': 3},\n",
              " 59: {'accuracy': 0.5220094533995879, 'cluster_idx': 4},\n",
              " 60: {'accuracy': 0.5094937987314669, 'cluster_idx': 2},\n",
              " 61: {'accuracy': 0.5292126206924413, 'cluster_idx': 5},\n",
              " 62: {'accuracy': 0.5058336363269098, 'cluster_idx': 8},\n",
              " 63: {'accuracy': 0.48607441522239725, 'cluster_idx': 4},\n",
              " 64: {'accuracy': 0.5157516260655275, 'cluster_idx': 4},\n",
              " 65: {'accuracy': 0.5004524704076273, 'cluster_idx': 3},\n",
              " 66: {'accuracy': 0.5157152668363431, 'cluster_idx': 8},\n",
              " 67: {'accuracy': 0.5049488950834242, 'cluster_idx': 8},\n",
              " 68: {'accuracy': 0.4860703753080434, 'cluster_idx': 7},\n",
              " 69: {'accuracy': 0.4905627600694865, 'cluster_idx': 9},\n",
              " 70: {'accuracy': 0.5399426332161757, 'cluster_idx': 1},\n",
              " 71: {'accuracy': 0.5283682785924938, 'cluster_idx': 3},\n",
              " 72: {'accuracy': 0.5147860865349655, 'cluster_idx': 8},\n",
              " 73: {'accuracy': 0.5121843816911081, 'cluster_idx': 4},\n",
              " 74: {'accuracy': 0.5121278228901547, 'cluster_idx': 9},\n",
              " 75: {'accuracy': 0.4986789480063022, 'cluster_idx': 9},\n",
              " 76: {'accuracy': 0.5013250919080516, 'cluster_idx': 4},\n",
              " 77: {'accuracy': 0.5148224457641498, 'cluster_idx': 4},\n",
              " 78: {'accuracy': 0.5075667595846969, 'cluster_idx': 7},\n",
              " 79: {'accuracy': 0.5166040479941826, 'cluster_idx': 4},\n",
              " 80: {'accuracy': 0.5193188704399466, 'cluster_idx': 4},\n",
              " 81: {'accuracy': 0.5282874803054175, 'cluster_idx': 1},\n",
              " 82: {'accuracy': 0.5210600735264412, 'cluster_idx': 8},\n",
              " 83: {'accuracy': 0.5040803134973538, 'cluster_idx': 1},\n",
              " 84: {'accuracy': 0.5301054417646347, 'cluster_idx': 5},\n",
              " 85: {'accuracy': 0.49957580899284937, 'cluster_idx': 8},\n",
              " 86: {'accuracy': 0.5327596654950915, 'cluster_idx': 8},\n",
              " 87: {'accuracy': 0.5418050337332849, 'cluster_idx': 7},\n",
              " 88: {'accuracy': 0.5031672928533915, 'cluster_idx': 4},\n",
              " 89: {'accuracy': 0.49322910354300487, 'cluster_idx': 8},\n",
              " 90: {'accuracy': 0.5147941663636731, 'cluster_idx': 8},\n",
              " 91: {'accuracy': 0.5364036682422333, 'cluster_idx': 1},\n",
              " 92: {'accuracy': 0.49501070577303763, 'cluster_idx': 9},\n",
              " 93: {'accuracy': 0.5265018381610309, 'cluster_idx': 9},\n",
              " 94: {'accuracy': 0.5364319476427101, 'cluster_idx': 4},\n",
              " 95: {'accuracy': 0.5390780915444593, 'cluster_idx': 9},\n",
              " 96: {'accuracy': 0.5067143376560417, 'cluster_idx': 0},\n",
              " 97: {'accuracy': 0.5301216014220499, 'cluster_idx': 5},\n",
              " 98: {'accuracy': 0.5255484183735304, 'cluster_idx': 5},\n",
              " 99: {'accuracy': 0.5139296246919566, 'cluster_idx': 5}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Highest acuracy selection-Cluster Representative\n",
        "def getMaxAccuracyCluster(dicts):\n",
        "    clusterObj = {}\n",
        "    for key, value in dicts.items():\n",
        "      if(clusterObj.get(str(value[\"cluster_idx\"])) != None):\n",
        "        clusterObj[str(value[\"cluster_idx\"])].append({\"index\" : key, \"accuracy\" : value['accuracy']})\n",
        "      else:\n",
        "        clusterObj[str(value[\"cluster_idx\"])] = []\n",
        "        clusterObj[str(value[\"cluster_idx\"])].append({\"index\" : key, \"accuracy\" : value['accuracy']})\n",
        "    #Restructured the object so the key for dictionary is cluster_idx\n",
        "    #Now you can access all the accuracies of cluster as below\n",
        "    #print(clusterObj[\"2\"])\n",
        "    clusterMaxAccuracyObj = {}\n",
        "    for clusterIndex in clusterObj.keys():\n",
        "      max_acc = -1;\n",
        "      for obj in clusterObj[clusterIndex]:\n",
        "        if obj['accuracy'] == max_acc:\n",
        "          clusterMaxAccuracyObj[str(clusterIndex)].append(obj['index'])\n",
        "        if obj['accuracy'] > max_acc:\n",
        "          max_acc = obj['accuracy']\n",
        "          clusterMaxAccuracyObj[str(clusterIndex)] = []\n",
        "          clusterMaxAccuracyObj[str(clusterIndex)].append(obj['index'])\n",
        "    print(clusterMaxAccuracyObj)\n",
        "    dict1 = {}\n",
        "    print(\"Selecting first maximum accuracy of a decision tree in each cluster:\")\n",
        "    for key,val in clusterMaxAccuracyObj.items():\n",
        "      output = {key : val[0]}\n",
        "      print(output)\n",
        "    return clusterMaxAccuracyObj"
      ],
      "metadata": {
        "id": "rOP1xdA6a4Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getMaxAccuracyCluster(prf.info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyKxpK7Ca40w",
        "outputId": "90faace8-1028-460b-80fa-fa0c17358336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'1': [70], '5': [27], '9': [14], '2': [39], '8': [86], '4': [94], '3': [71], '6': [51], '7': [46], '0': [96]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'1': 70}\n",
            "{'5': 27}\n",
            "{'9': 14}\n",
            "{'2': 39}\n",
            "{'8': 86}\n",
            "{'4': 94}\n",
            "{'3': 71}\n",
            "{'6': 51}\n",
            "{'7': 46}\n",
            "{'0': 96}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': [70],\n",
              " '5': [27],\n",
              " '9': [14],\n",
              " '2': [39],\n",
              " '8': [86],\n",
              " '4': [94],\n",
              " '3': [71],\n",
              " '6': [51],\n",
              " '7': [46],\n",
              " '0': [96]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTreeList(X, dicts):\n",
        "    treeIdxs = []\n",
        "    for trees in dicts.values():\n",
        "        treeIdxs.append(trees[0])\n",
        "    return treeIdxs\n",
        "\n",
        "stored_ypred = []\n",
        "def predict(X, treeList, prf):\n",
        "    ypred = []\n",
        "    for treeIdx in treeList:\n",
        "        print(prf.decision_trees[treeIdx].predict(X))\n",
        "        ypred.append(prf.decision_trees[treeIdx].predict(X))\n",
        "    stored_ypred.append(ypred)\n",
        "    print(type(ypred))\n",
        "    return getMajorityLabels(ypred)\n",
        "\n",
        "def getMajorityLabels(pred):\n",
        "    predNp = np.array(pred)\n",
        "    rows,cols = predNp.shape\n",
        "    res = []\n",
        "    for colIdx in range(cols):\n",
        "        col = list(predNp[:, colIdx])\n",
        "        res.append(max(set(col), key = col.count))\n",
        "    return res\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bTNPmK1ta7qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "  \n",
        "print(\"testing target data:\",y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, y_preed))\n",
        "print(\"precision\", metrics.average_precision_score(y_test, y_preed))\n",
        "print(\"recall\", metrics.recall_score(y_test, y_preed))\n",
        "print(\"f1\", metrics.f1_score(y_test, y_preed))\n",
        "print(\"f2\", metrics.fbeta_score(y_test,y_preed, beta=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvGeTYr-a-hc",
        "outputId": "875e3da6-adf5-4e36-f8e0-509d7f4ecc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'1': [70], '5': [27], '9': [14], '2': [39], '8': [86], '4': [94], '3': [71], '6': [51], '7': [46], '0': [96]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'1': 70}\n",
            "{'5': 27}\n",
            "{'9': 14}\n",
            "{'2': 39}\n",
            "{'8': 86}\n",
            "{'4': 94}\n",
            "{'3': 71}\n",
            "{'6': 51}\n",
            "{'7': 46}\n",
            "{'0': 96}\n",
            "[0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
            " 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
            " 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
            "[1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
            "<class 'list'>\n",
            "final answer =  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
            "testing target data: 57      1\n",
            "270     1\n",
            "128     0\n",
            "706     1\n",
            "800     1\n",
            "       ..\n",
            "1051    0\n",
            "1045    1\n",
            "109     1\n",
            "427     0\n",
            "616     1\n",
            "Name: 384, Length: 334, dtype: int64\n",
            "Accuracy: 0.9910179640718563\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       165\n",
            "           1       0.99      0.99      0.99       169\n",
            "\n",
            "    accuracy                           0.99       334\n",
            "   macro avg       0.99      0.99      0.99       334\n",
            "weighted avg       0.99      0.99      0.99       334\n",
            "\n",
            "precision 0.9853817599746556\n",
            "recall 0.9940828402366864\n",
            "f1 0.9911504424778761\n",
            "f2 0.9929078014184397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf1.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf1)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "print(y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, y_preed))\n",
        "print(\"precision\", metrics.average_precision_score(y_test, y_preed))\n",
        "print(\"recall\", metrics.recall_score(y_test, y_preed))\n",
        "print(\"f1\", metrics.f1_score(y_test, y_preed))\n",
        "print(\"f2\", metrics.fbeta_score(y_test,y_preed, beta=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDAlsaRubBbz",
        "outputId": "3f8265a4-6d82-4bf4-8a17-049abbfddd50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'6': [351], '9': [217], '0': [139], '2': [410], '8': [207], '4': [19], '1': [361], '5': [388], '3': [42], '7': [339]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'6': 351}\n",
            "{'9': 217}\n",
            "{'0': 139}\n",
            "{'2': 410}\n",
            "{'8': 207}\n",
            "{'4': 19}\n",
            "{'1': 361}\n",
            "{'5': 388}\n",
            "{'3': 42}\n",
            "{'7': 339}\n",
            "[1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
            "[1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
            "[1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "<class 'list'>\n",
            "final answer =  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
            "57      1\n",
            "270     1\n",
            "128     0\n",
            "706     1\n",
            "800     1\n",
            "       ..\n",
            "1051    0\n",
            "1045    1\n",
            "109     1\n",
            "427     0\n",
            "616     1\n",
            "Name: 384, Length: 334, dtype: int64\n",
            "Accuracy: 0.9940119760479041\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       165\n",
            "           1       1.00      0.99      0.99       169\n",
            "\n",
            "    accuracy                           0.99       334\n",
            "   macro avg       0.99      0.99      0.99       334\n",
            "weighted avg       0.99      0.99      0.99       334\n",
            "\n",
            "precision 0.9941537044254686\n",
            "recall 0.9881656804733728\n",
            "f1 0.9940476190476192\n",
            "f2 0.9905100830367733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf2.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf2)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "print(y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, y_preed))\n",
        "print(\"precision\", metrics.average_precision_score(y_test, y_preed))\n",
        "print(\"recall\", metrics.recall_score(y_test, y_preed))\n",
        "print(\"f1\", metrics.f1_score(y_test, y_preed))\n",
        "print(\"f2\", metrics.fbeta_score(y_test,y_preed, beta=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxBXM-xbbH5j",
        "outputId": "88e0f677-192d-4db6-ac5c-a140a60ab428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4': [35], '5': [160], '9': [79], '2': [231], '8': [256], '6': [438], '3': [489], '1': [395], '0': [372], '7': [451]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'4': 35}\n",
            "{'5': 160}\n",
            "{'9': 79}\n",
            "{'2': 231}\n",
            "{'8': 256}\n",
            "{'6': 438}\n",
            "{'3': 489}\n",
            "{'1': 395}\n",
            "{'0': 372}\n",
            "{'7': 451}\n",
            "[1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
            " 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
            "[1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
            "[1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.\n",
            " 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1.]\n",
            "[1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
            "[1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
            "[1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0.\n",
            " 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
            "[0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0.]\n",
            "[1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
            "<class 'list'>\n",
            "final answer =  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
            "57      1\n",
            "270     1\n",
            "128     0\n",
            "706     1\n",
            "800     1\n",
            "       ..\n",
            "1051    0\n",
            "1045    1\n",
            "109     1\n",
            "427     0\n",
            "616     1\n",
            "Name: 384, Length: 334, dtype: int64\n",
            "Accuracy: 0.9910179640718563\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       165\n",
            "           1       1.00      0.98      0.99       169\n",
            "\n",
            "    accuracy                           0.99       334\n",
            "   macro avg       0.99      0.99      0.99       334\n",
            "weighted avg       0.99      0.99      0.99       334\n",
            "\n",
            "precision 0.9912305566382029\n",
            "recall 0.9822485207100592\n",
            "f1 0.9910447761194029\n",
            "f2 0.9857482185273159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf3.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf3)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "print(y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, y_preed))\n",
        "print(\"precision\", metrics.average_precision_score(y_test, y_preed))\n",
        "print(\"recall\", metrics.recall_score(y_test, y_preed))\n",
        "print(\"f1\", metrics.f1_score(y_test, y_preed))\n",
        "print(\"f2\", metrics.fbeta_score(y_test,y_preed, beta=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sM-Rr7EbMlF",
        "outputId": "42095565-6b7b-48c9-d70e-87417a6b695f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'9': [446], '0': [33], '1': [142], '7': [44], '3': [79], '6': [475], '8': [136], '4': [24], '5': [287], '2': [119]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'9': 446}\n",
            "{'0': 33}\n",
            "{'1': 142}\n",
            "{'7': 44}\n",
            "{'3': 79}\n",
            "{'6': 475}\n",
            "{'8': 136}\n",
            "{'4': 24}\n",
            "{'5': 287}\n",
            "{'2': 119}\n",
            "[1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
            "[1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
            "[1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
            "[0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
            " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
            " 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0.\n",
            " 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
            "[1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "<class 'list'>\n",
            "final answer =  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
            "57      1\n",
            "270     1\n",
            "128     0\n",
            "706     1\n",
            "800     1\n",
            "       ..\n",
            "1051    0\n",
            "1045    1\n",
            "109     1\n",
            "427     0\n",
            "616     1\n",
            "Name: 384, Length: 334, dtype: int64\n",
            "Accuracy: 0.9640718562874252\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       165\n",
            "           1       0.99      0.94      0.96       169\n",
            "\n",
            "    accuracy                           0.96       334\n",
            "   macro avg       0.96      0.96      0.96       334\n",
            "weighted avg       0.97      0.96      0.96       334\n",
            "\n",
            "precision 0.9590812127811708\n",
            "recall 0.9408284023668639\n",
            "f1 0.9636363636363637\n",
            "f2 0.9498207885304659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf4.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf4)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "print(y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, y_preed))\n",
        "print(\"precision\", metrics.average_precision_score(y_test, y_preed))\n",
        "print(\"recall\", metrics.recall_score(y_test, y_preed))\n",
        "print(\"f1\", metrics.f1_score(y_test, y_preed))\n",
        "print(\"f2\", metrics.fbeta_score(y_test,y_preed, beta=2))"
      ],
      "metadata": {
        "id": "iXp2EqAAetqM",
        "outputId": "03a42739-b603-48f9-cbd7-b8a90aa924a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'3': [479], '9': [412], '1': [270], '5': [4], '0': [72], '8': [204], '2': [315], '6': [109], '4': [477], '7': [205]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'3': 479}\n",
            "{'9': 412}\n",
            "{'1': 270}\n",
            "{'5': 4}\n",
            "{'0': 72}\n",
            "{'8': 204}\n",
            "{'2': 315}\n",
            "{'6': 109}\n",
            "{'4': 477}\n",
            "{'7': 205}\n",
            "[0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.]\n",
            "[1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
            "[0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
            "[0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
            "[0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
            "[1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0.\n",
            " 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1.]\n",
            "[1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1.]\n",
            "<class 'list'>\n",
            "final answer =  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
            "57      1\n",
            "270     1\n",
            "128     0\n",
            "706     1\n",
            "800     1\n",
            "       ..\n",
            "1051    0\n",
            "1045    1\n",
            "109     1\n",
            "427     0\n",
            "616     1\n",
            "Name: 384, Length: 334, dtype: int64\n",
            "Accuracy: 0.9910179640718563\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       165\n",
            "           1       1.00      0.98      0.99       169\n",
            "\n",
            "    accuracy                           0.99       334\n",
            "   macro avg       0.99      0.99      0.99       334\n",
            "weighted avg       0.99      0.99      0.99       334\n",
            "\n",
            "precision 0.9912305566382029\n",
            "recall 0.9822485207100592\n",
            "f1 0.9910447761194029\n",
            "f2 0.9857482185273159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KERAS MODEL WITH TENSORFLOW- NEURAL NETWORKS\n",
        "\n",
        "from numpy import loadtxt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "\n",
        "#tensorflow\n",
        "model_4 = tf.keras.Sequential([\n",
        "\n",
        "                               tf.keras.layers.Dense(4, activation = 'relu'), #we may right it \"tf.keras.activations.relu\" too\n",
        "\n",
        "                               tf.keras.layers.Dense(4, activation = 'relu'),\n",
        "\n",
        "                               tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "model_4.compile( loss= tf.keras.losses.binary_crossentropy,\n",
        "\n",
        "                optimizer = tf.keras.optimizers.Adam(lr = 0.01),\n",
        "\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_4.fit(X_train, y_train, epochs = 200, verbose = 2)"
      ],
      "metadata": {
        "id": "qyGkPo5HexcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00391ffc-eb75-470a-8672-4534deb1584c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "25/25 - 5s - loss: 0.7408 - accuracy: 0.5225 - 5s/epoch - 191ms/step\n",
            "Epoch 2/200\n",
            "25/25 - 0s - loss: 0.6949 - accuracy: 0.5379 - 92ms/epoch - 4ms/step\n",
            "Epoch 3/200\n",
            "25/25 - 0s - loss: 0.6759 - accuracy: 0.5610 - 74ms/epoch - 3ms/step\n",
            "Epoch 4/200\n",
            "25/25 - 0s - loss: 0.6629 - accuracy: 0.5661 - 70ms/epoch - 3ms/step\n",
            "Epoch 5/200\n",
            "25/25 - 0s - loss: 0.6525 - accuracy: 0.5956 - 68ms/epoch - 3ms/step\n",
            "Epoch 6/200\n",
            "25/25 - 0s - loss: 0.6443 - accuracy: 0.6162 - 99ms/epoch - 4ms/step\n",
            "Epoch 7/200\n",
            "25/25 - 0s - loss: 0.6343 - accuracy: 0.6329 - 95ms/epoch - 4ms/step\n",
            "Epoch 8/200\n",
            "25/25 - 0s - loss: 0.6277 - accuracy: 0.6444 - 113ms/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "25/25 - 0s - loss: 0.6179 - accuracy: 0.6765 - 95ms/epoch - 4ms/step\n",
            "Epoch 10/200\n",
            "25/25 - 0s - loss: 0.6103 - accuracy: 0.6958 - 93ms/epoch - 4ms/step\n",
            "Epoch 11/200\n",
            "25/25 - 0s - loss: 0.6024 - accuracy: 0.7137 - 97ms/epoch - 4ms/step\n",
            "Epoch 12/200\n",
            "25/25 - 0s - loss: 0.5947 - accuracy: 0.7240 - 102ms/epoch - 4ms/step\n",
            "Epoch 13/200\n",
            "25/25 - 0s - loss: 0.5866 - accuracy: 0.7381 - 96ms/epoch - 4ms/step\n",
            "Epoch 14/200\n",
            "25/25 - 0s - loss: 0.5795 - accuracy: 0.7574 - 94ms/epoch - 4ms/step\n",
            "Epoch 15/200\n",
            "25/25 - 0s - loss: 0.5694 - accuracy: 0.7677 - 103ms/epoch - 4ms/step\n",
            "Epoch 16/200\n",
            "25/25 - 0s - loss: 0.5658 - accuracy: 0.7548 - 92ms/epoch - 4ms/step\n",
            "Epoch 17/200\n",
            "25/25 - 0s - loss: 0.5557 - accuracy: 0.7651 - 94ms/epoch - 4ms/step\n",
            "Epoch 18/200\n",
            "25/25 - 0s - loss: 0.5470 - accuracy: 0.7766 - 94ms/epoch - 4ms/step\n",
            "Epoch 19/200\n",
            "25/25 - 0s - loss: 0.5380 - accuracy: 0.7882 - 95ms/epoch - 4ms/step\n",
            "Epoch 20/200\n",
            "25/25 - 0s - loss: 0.5291 - accuracy: 0.8151 - 93ms/epoch - 4ms/step\n",
            "Epoch 21/200\n",
            "25/25 - 0s - loss: 0.5230 - accuracy: 0.8177 - 92ms/epoch - 4ms/step\n",
            "Epoch 22/200\n",
            "25/25 - 0s - loss: 0.5155 - accuracy: 0.8203 - 90ms/epoch - 4ms/step\n",
            "Epoch 23/200\n",
            "25/25 - 0s - loss: 0.5080 - accuracy: 0.8190 - 93ms/epoch - 4ms/step\n",
            "Epoch 24/200\n",
            "25/25 - 0s - loss: 0.4984 - accuracy: 0.8408 - 102ms/epoch - 4ms/step\n",
            "Epoch 25/200\n",
            "25/25 - 0s - loss: 0.4922 - accuracy: 0.8421 - 90ms/epoch - 4ms/step\n",
            "Epoch 26/200\n",
            "25/25 - 0s - loss: 0.4844 - accuracy: 0.8293 - 90ms/epoch - 4ms/step\n",
            "Epoch 27/200\n",
            "25/25 - 0s - loss: 0.4821 - accuracy: 0.8537 - 102ms/epoch - 4ms/step\n",
            "Epoch 28/200\n",
            "25/25 - 0s - loss: 0.4700 - accuracy: 0.8472 - 97ms/epoch - 4ms/step\n",
            "Epoch 29/200\n",
            "25/25 - 0s - loss: 0.4603 - accuracy: 0.8601 - 115ms/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "25/25 - 0s - loss: 0.4537 - accuracy: 0.8626 - 95ms/epoch - 4ms/step\n",
            "Epoch 31/200\n",
            "25/25 - 0s - loss: 0.4503 - accuracy: 0.8575 - 93ms/epoch - 4ms/step\n",
            "Epoch 32/200\n",
            "25/25 - 0s - loss: 0.4434 - accuracy: 0.8755 - 92ms/epoch - 4ms/step\n",
            "Epoch 33/200\n",
            "25/25 - 0s - loss: 0.4366 - accuracy: 0.8742 - 94ms/epoch - 4ms/step\n",
            "Epoch 34/200\n",
            "25/25 - 0s - loss: 0.4355 - accuracy: 0.8755 - 96ms/epoch - 4ms/step\n",
            "Epoch 35/200\n",
            "25/25 - 0s - loss: 0.4224 - accuracy: 0.8858 - 101ms/epoch - 4ms/step\n",
            "Epoch 36/200\n",
            "25/25 - 0s - loss: 0.4128 - accuracy: 0.8922 - 97ms/epoch - 4ms/step\n",
            "Epoch 37/200\n",
            "25/25 - 0s - loss: 0.4131 - accuracy: 0.8896 - 105ms/epoch - 4ms/step\n",
            "Epoch 38/200\n",
            "25/25 - 0s - loss: 0.3998 - accuracy: 0.8973 - 96ms/epoch - 4ms/step\n",
            "Epoch 39/200\n",
            "25/25 - 0s - loss: 0.3923 - accuracy: 0.9024 - 100ms/epoch - 4ms/step\n",
            "Epoch 40/200\n",
            "25/25 - 0s - loss: 0.3933 - accuracy: 0.8935 - 92ms/epoch - 4ms/step\n",
            "Epoch 41/200\n",
            "25/25 - 0s - loss: 0.3858 - accuracy: 0.8986 - 93ms/epoch - 4ms/step\n",
            "Epoch 42/200\n",
            "25/25 - 0s - loss: 0.3784 - accuracy: 0.8999 - 68ms/epoch - 3ms/step\n",
            "Epoch 43/200\n",
            "25/25 - 0s - loss: 0.3693 - accuracy: 0.9089 - 158ms/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "25/25 - 0s - loss: 0.3632 - accuracy: 0.9127 - 159ms/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "25/25 - 0s - loss: 0.3575 - accuracy: 0.9153 - 122ms/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "25/25 - 0s - loss: 0.3533 - accuracy: 0.9166 - 66ms/epoch - 3ms/step\n",
            "Epoch 47/200\n",
            "25/25 - 0s - loss: 0.3427 - accuracy: 0.9178 - 67ms/epoch - 3ms/step\n",
            "Epoch 48/200\n",
            "25/25 - 0s - loss: 0.3362 - accuracy: 0.9243 - 79ms/epoch - 3ms/step\n",
            "Epoch 49/200\n",
            "25/25 - 0s - loss: 0.3321 - accuracy: 0.9255 - 75ms/epoch - 3ms/step\n",
            "Epoch 50/200\n",
            "25/25 - 0s - loss: 0.3267 - accuracy: 0.9255 - 66ms/epoch - 3ms/step\n",
            "Epoch 51/200\n",
            "25/25 - 0s - loss: 0.3229 - accuracy: 0.9243 - 75ms/epoch - 3ms/step\n",
            "Epoch 52/200\n",
            "25/25 - 0s - loss: 0.3239 - accuracy: 0.9217 - 69ms/epoch - 3ms/step\n",
            "Epoch 53/200\n",
            "25/25 - 0s - loss: 0.3108 - accuracy: 0.9281 - 155ms/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "25/25 - 0s - loss: 0.3078 - accuracy: 0.9358 - 155ms/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "25/25 - 0s - loss: 0.3045 - accuracy: 0.9332 - 122ms/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "25/25 - 0s - loss: 0.2982 - accuracy: 0.9409 - 73ms/epoch - 3ms/step\n",
            "Epoch 57/200\n",
            "25/25 - 0s - loss: 0.2977 - accuracy: 0.9345 - 71ms/epoch - 3ms/step\n",
            "Epoch 58/200\n",
            "25/25 - 0s - loss: 0.2888 - accuracy: 0.9409 - 71ms/epoch - 3ms/step\n",
            "Epoch 59/200\n",
            "25/25 - 0s - loss: 0.2838 - accuracy: 0.9461 - 80ms/epoch - 3ms/step\n",
            "Epoch 60/200\n",
            "25/25 - 0s - loss: 0.2838 - accuracy: 0.9320 - 71ms/epoch - 3ms/step\n",
            "Epoch 61/200\n",
            "25/25 - 0s - loss: 0.2734 - accuracy: 0.9409 - 77ms/epoch - 3ms/step\n",
            "Epoch 62/200\n",
            "25/25 - 0s - loss: 0.2733 - accuracy: 0.9461 - 67ms/epoch - 3ms/step\n",
            "Epoch 63/200\n",
            "25/25 - 0s - loss: 0.2660 - accuracy: 0.9474 - 72ms/epoch - 3ms/step\n",
            "Epoch 64/200\n",
            "25/25 - 0s - loss: 0.2659 - accuracy: 0.9422 - 65ms/epoch - 3ms/step\n",
            "Epoch 65/200\n",
            "25/25 - 0s - loss: 0.2600 - accuracy: 0.9448 - 67ms/epoch - 3ms/step\n",
            "Epoch 66/200\n",
            "25/25 - 0s - loss: 0.2556 - accuracy: 0.9474 - 65ms/epoch - 3ms/step\n",
            "Epoch 67/200\n",
            "25/25 - 0s - loss: 0.2510 - accuracy: 0.9551 - 66ms/epoch - 3ms/step\n",
            "Epoch 68/200\n",
            "25/25 - 0s - loss: 0.2479 - accuracy: 0.9487 - 64ms/epoch - 3ms/step\n",
            "Epoch 69/200\n",
            "25/25 - 0s - loss: 0.2427 - accuracy: 0.9564 - 66ms/epoch - 3ms/step\n",
            "Epoch 70/200\n",
            "25/25 - 0s - loss: 0.2367 - accuracy: 0.9564 - 66ms/epoch - 3ms/step\n",
            "Epoch 71/200\n",
            "25/25 - 0s - loss: 0.2346 - accuracy: 0.9525 - 82ms/epoch - 3ms/step\n",
            "Epoch 72/200\n",
            "25/25 - 0s - loss: 0.2304 - accuracy: 0.9538 - 76ms/epoch - 3ms/step\n",
            "Epoch 73/200\n",
            "25/25 - 0s - loss: 0.2271 - accuracy: 0.9538 - 74ms/epoch - 3ms/step\n",
            "Epoch 74/200\n",
            "25/25 - 0s - loss: 0.2316 - accuracy: 0.9499 - 70ms/epoch - 3ms/step\n",
            "Epoch 75/200\n",
            "25/25 - 0s - loss: 0.2236 - accuracy: 0.9576 - 71ms/epoch - 3ms/step\n",
            "Epoch 76/200\n",
            "25/25 - 0s - loss: 0.2193 - accuracy: 0.9576 - 73ms/epoch - 3ms/step\n",
            "Epoch 77/200\n",
            "25/25 - 0s - loss: 0.2145 - accuracy: 0.9615 - 76ms/epoch - 3ms/step\n",
            "Epoch 78/200\n",
            "25/25 - 0s - loss: 0.2134 - accuracy: 0.9564 - 72ms/epoch - 3ms/step\n",
            "Epoch 79/200\n",
            "25/25 - 0s - loss: 0.2146 - accuracy: 0.9551 - 65ms/epoch - 3ms/step\n",
            "Epoch 80/200\n",
            "25/25 - 0s - loss: 0.2164 - accuracy: 0.9538 - 71ms/epoch - 3ms/step\n",
            "Epoch 81/200\n",
            "25/25 - 0s - loss: 0.2094 - accuracy: 0.9576 - 74ms/epoch - 3ms/step\n",
            "Epoch 82/200\n",
            "25/25 - 0s - loss: 0.1985 - accuracy: 0.9679 - 67ms/epoch - 3ms/step\n",
            "Epoch 83/200\n",
            "25/25 - 0s - loss: 0.1970 - accuracy: 0.9666 - 69ms/epoch - 3ms/step\n",
            "Epoch 84/200\n",
            "25/25 - 0s - loss: 0.1974 - accuracy: 0.9628 - 71ms/epoch - 3ms/step\n",
            "Epoch 85/200\n",
            "25/25 - 0s - loss: 0.1936 - accuracy: 0.9615 - 75ms/epoch - 3ms/step\n",
            "Epoch 86/200\n",
            "25/25 - 0s - loss: 0.1894 - accuracy: 0.9641 - 91ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "25/25 - 0s - loss: 0.1971 - accuracy: 0.9564 - 80ms/epoch - 3ms/step\n",
            "Epoch 88/200\n",
            "25/25 - 0s - loss: 0.1853 - accuracy: 0.9692 - 76ms/epoch - 3ms/step\n",
            "Epoch 89/200\n",
            "25/25 - 0s - loss: 0.1827 - accuracy: 0.9666 - 73ms/epoch - 3ms/step\n",
            "Epoch 90/200\n",
            "25/25 - 0s - loss: 0.1765 - accuracy: 0.9641 - 70ms/epoch - 3ms/step\n",
            "Epoch 91/200\n",
            "25/25 - 0s - loss: 0.1767 - accuracy: 0.9692 - 65ms/epoch - 3ms/step\n",
            "Epoch 92/200\n",
            "25/25 - 0s - loss: 0.1765 - accuracy: 0.9641 - 74ms/epoch - 3ms/step\n",
            "Epoch 93/200\n",
            "25/25 - 0s - loss: 0.1687 - accuracy: 0.9743 - 65ms/epoch - 3ms/step\n",
            "Epoch 94/200\n",
            "25/25 - 0s - loss: 0.1675 - accuracy: 0.9743 - 66ms/epoch - 3ms/step\n",
            "Epoch 95/200\n",
            "25/25 - 0s - loss: 0.1817 - accuracy: 0.9589 - 65ms/epoch - 3ms/step\n",
            "Epoch 96/200\n",
            "25/25 - 0s - loss: 0.1677 - accuracy: 0.9718 - 65ms/epoch - 3ms/step\n",
            "Epoch 97/200\n",
            "25/25 - 0s - loss: 0.1701 - accuracy: 0.9705 - 72ms/epoch - 3ms/step\n",
            "Epoch 98/200\n",
            "25/25 - 0s - loss: 0.1609 - accuracy: 0.9743 - 74ms/epoch - 3ms/step\n",
            "Epoch 99/200\n",
            "25/25 - 0s - loss: 0.1636 - accuracy: 0.9743 - 76ms/epoch - 3ms/step\n",
            "Epoch 100/200\n",
            "25/25 - 0s - loss: 0.1586 - accuracy: 0.9705 - 71ms/epoch - 3ms/step\n",
            "Epoch 101/200\n",
            "25/25 - 0s - loss: 0.1528 - accuracy: 0.9730 - 70ms/epoch - 3ms/step\n",
            "Epoch 102/200\n",
            "25/25 - 0s - loss: 0.1543 - accuracy: 0.9718 - 74ms/epoch - 3ms/step\n",
            "Epoch 103/200\n",
            "25/25 - 0s - loss: 0.1487 - accuracy: 0.9756 - 71ms/epoch - 3ms/step\n",
            "Epoch 104/200\n",
            "25/25 - 0s - loss: 0.1470 - accuracy: 0.9756 - 68ms/epoch - 3ms/step\n",
            "Epoch 105/200\n",
            "25/25 - 0s - loss: 0.1437 - accuracy: 0.9769 - 67ms/epoch - 3ms/step\n",
            "Epoch 106/200\n",
            "25/25 - 0s - loss: 0.1411 - accuracy: 0.9782 - 74ms/epoch - 3ms/step\n",
            "Epoch 107/200\n",
            "25/25 - 0s - loss: 0.1418 - accuracy: 0.9756 - 73ms/epoch - 3ms/step\n",
            "Epoch 108/200\n",
            "25/25 - 0s - loss: 0.1412 - accuracy: 0.9782 - 65ms/epoch - 3ms/step\n",
            "Epoch 109/200\n",
            "25/25 - 0s - loss: 0.1353 - accuracy: 0.9820 - 67ms/epoch - 3ms/step\n",
            "Epoch 110/200\n",
            "25/25 - 0s - loss: 0.1345 - accuracy: 0.9795 - 68ms/epoch - 3ms/step\n",
            "Epoch 111/200\n",
            "25/25 - 0s - loss: 0.1353 - accuracy: 0.9820 - 64ms/epoch - 3ms/step\n",
            "Epoch 112/200\n",
            "25/25 - 0s - loss: 0.1320 - accuracy: 0.9795 - 79ms/epoch - 3ms/step\n",
            "Epoch 113/200\n",
            "25/25 - 0s - loss: 0.1293 - accuracy: 0.9820 - 82ms/epoch - 3ms/step\n",
            "Epoch 114/200\n",
            "25/25 - 0s - loss: 0.1253 - accuracy: 0.9807 - 66ms/epoch - 3ms/step\n",
            "Epoch 115/200\n",
            "25/25 - 0s - loss: 0.1290 - accuracy: 0.9807 - 71ms/epoch - 3ms/step\n",
            "Epoch 116/200\n",
            "25/25 - 0s - loss: 0.1261 - accuracy: 0.9807 - 74ms/epoch - 3ms/step\n",
            "Epoch 117/200\n",
            "25/25 - 0s - loss: 0.1222 - accuracy: 0.9820 - 80ms/epoch - 3ms/step\n",
            "Epoch 118/200\n",
            "25/25 - 0s - loss: 0.1275 - accuracy: 0.9782 - 72ms/epoch - 3ms/step\n",
            "Epoch 119/200\n",
            "25/25 - 0s - loss: 0.1207 - accuracy: 0.9820 - 76ms/epoch - 3ms/step\n",
            "Epoch 120/200\n",
            "25/25 - 0s - loss: 0.1200 - accuracy: 0.9782 - 67ms/epoch - 3ms/step\n",
            "Epoch 121/200\n",
            "25/25 - 0s - loss: 0.1201 - accuracy: 0.9795 - 75ms/epoch - 3ms/step\n",
            "Epoch 122/200\n",
            "25/25 - 0s - loss: 0.1200 - accuracy: 0.9782 - 65ms/epoch - 3ms/step\n",
            "Epoch 123/200\n",
            "25/25 - 0s - loss: 0.1195 - accuracy: 0.9769 - 64ms/epoch - 3ms/step\n",
            "Epoch 124/200\n",
            "25/25 - 0s - loss: 0.1158 - accuracy: 0.9807 - 65ms/epoch - 3ms/step\n",
            "Epoch 125/200\n",
            "25/25 - 0s - loss: 0.1141 - accuracy: 0.9820 - 81ms/epoch - 3ms/step\n",
            "Epoch 126/200\n",
            "25/25 - 0s - loss: 0.1119 - accuracy: 0.9833 - 75ms/epoch - 3ms/step\n",
            "Epoch 127/200\n",
            "25/25 - 0s - loss: 0.1094 - accuracy: 0.9820 - 67ms/epoch - 3ms/step\n",
            "Epoch 128/200\n",
            "25/25 - 0s - loss: 0.1103 - accuracy: 0.9820 - 74ms/epoch - 3ms/step\n",
            "Epoch 129/200\n",
            "25/25 - 0s - loss: 0.1091 - accuracy: 0.9820 - 72ms/epoch - 3ms/step\n",
            "Epoch 130/200\n",
            "25/25 - 0s - loss: 0.1105 - accuracy: 0.9807 - 74ms/epoch - 3ms/step\n",
            "Epoch 131/200\n",
            "25/25 - 0s - loss: 0.1074 - accuracy: 0.9795 - 65ms/epoch - 3ms/step\n",
            "Epoch 132/200\n",
            "25/25 - 0s - loss: 0.1071 - accuracy: 0.9820 - 73ms/epoch - 3ms/step\n",
            "Epoch 133/200\n",
            "25/25 - 0s - loss: 0.1060 - accuracy: 0.9833 - 74ms/epoch - 3ms/step\n",
            "Epoch 134/200\n",
            "25/25 - 0s - loss: 0.1049 - accuracy: 0.9807 - 65ms/epoch - 3ms/step\n",
            "Epoch 135/200\n",
            "25/25 - 0s - loss: 0.1024 - accuracy: 0.9833 - 67ms/epoch - 3ms/step\n",
            "Epoch 136/200\n",
            "25/25 - 0s - loss: 0.1045 - accuracy: 0.9820 - 72ms/epoch - 3ms/step\n",
            "Epoch 137/200\n",
            "25/25 - 0s - loss: 0.1009 - accuracy: 0.9833 - 71ms/epoch - 3ms/step\n",
            "Epoch 138/200\n",
            "25/25 - 0s - loss: 0.1087 - accuracy: 0.9782 - 91ms/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "25/25 - 0s - loss: 0.1528 - accuracy: 0.9615 - 70ms/epoch - 3ms/step\n",
            "Epoch 140/200\n",
            "25/25 - 0s - loss: 0.1259 - accuracy: 0.9718 - 70ms/epoch - 3ms/step\n",
            "Epoch 141/200\n",
            "25/25 - 0s - loss: 0.1290 - accuracy: 0.9705 - 73ms/epoch - 3ms/step\n",
            "Epoch 142/200\n",
            "25/25 - 0s - loss: 0.1306 - accuracy: 0.9679 - 66ms/epoch - 3ms/step\n",
            "Epoch 143/200\n",
            "25/25 - 0s - loss: 0.1231 - accuracy: 0.9743 - 84ms/epoch - 3ms/step\n",
            "Epoch 144/200\n",
            "25/25 - 0s - loss: 0.1193 - accuracy: 0.9743 - 69ms/epoch - 3ms/step\n",
            "Epoch 145/200\n",
            "25/25 - 0s - loss: 0.1021 - accuracy: 0.9782 - 65ms/epoch - 3ms/step\n",
            "Epoch 146/200\n",
            "25/25 - 0s - loss: 0.0991 - accuracy: 0.9820 - 69ms/epoch - 3ms/step\n",
            "Epoch 147/200\n",
            "25/25 - 0s - loss: 0.0954 - accuracy: 0.9820 - 72ms/epoch - 3ms/step\n",
            "Epoch 148/200\n",
            "25/25 - 0s - loss: 0.0931 - accuracy: 0.9846 - 65ms/epoch - 3ms/step\n",
            "Epoch 149/200\n",
            "25/25 - 0s - loss: 0.0926 - accuracy: 0.9820 - 64ms/epoch - 3ms/step\n",
            "Epoch 150/200\n",
            "25/25 - 0s - loss: 0.0910 - accuracy: 0.9859 - 66ms/epoch - 3ms/step\n",
            "Epoch 151/200\n",
            "25/25 - 0s - loss: 0.0911 - accuracy: 0.9833 - 68ms/epoch - 3ms/step\n",
            "Epoch 152/200\n",
            "25/25 - 0s - loss: 0.0911 - accuracy: 0.9833 - 81ms/epoch - 3ms/step\n",
            "Epoch 153/200\n",
            "25/25 - 0s - loss: 0.0900 - accuracy: 0.9833 - 74ms/epoch - 3ms/step\n",
            "Epoch 154/200\n",
            "25/25 - 0s - loss: 0.0891 - accuracy: 0.9846 - 69ms/epoch - 3ms/step\n",
            "Epoch 155/200\n",
            "25/25 - 0s - loss: 0.0949 - accuracy: 0.9846 - 66ms/epoch - 3ms/step\n",
            "Epoch 156/200\n",
            "25/25 - 0s - loss: 0.0898 - accuracy: 0.9846 - 79ms/epoch - 3ms/step\n",
            "Epoch 157/200\n",
            "25/25 - 0s - loss: 0.0888 - accuracy: 0.9846 - 78ms/epoch - 3ms/step\n",
            "Epoch 158/200\n",
            "25/25 - 0s - loss: 0.0893 - accuracy: 0.9833 - 81ms/epoch - 3ms/step\n",
            "Epoch 159/200\n",
            "25/25 - 0s - loss: 0.0857 - accuracy: 0.9846 - 67ms/epoch - 3ms/step\n",
            "Epoch 160/200\n",
            "25/25 - 0s - loss: 0.0947 - accuracy: 0.9807 - 67ms/epoch - 3ms/step\n",
            "Epoch 161/200\n",
            "25/25 - 0s - loss: 0.1003 - accuracy: 0.9807 - 68ms/epoch - 3ms/step\n",
            "Epoch 162/200\n",
            "25/25 - 0s - loss: 0.0929 - accuracy: 0.9820 - 72ms/epoch - 3ms/step\n",
            "Epoch 163/200\n",
            "25/25 - 0s - loss: 0.0860 - accuracy: 0.9859 - 73ms/epoch - 3ms/step\n",
            "Epoch 164/200\n",
            "25/25 - 0s - loss: 0.0886 - accuracy: 0.9859 - 67ms/epoch - 3ms/step\n",
            "Epoch 165/200\n",
            "25/25 - 0s - loss: 0.0894 - accuracy: 0.9846 - 99ms/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "25/25 - 0s - loss: 0.0816 - accuracy: 0.9859 - 105ms/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "25/25 - 0s - loss: 0.0816 - accuracy: 0.9846 - 103ms/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "25/25 - 0s - loss: 0.0786 - accuracy: 0.9872 - 96ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "25/25 - 0s - loss: 0.0791 - accuracy: 0.9859 - 98ms/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "25/25 - 0s - loss: 0.0811 - accuracy: 0.9846 - 93ms/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "25/25 - 0s - loss: 0.0772 - accuracy: 0.9859 - 93ms/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "25/25 - 0s - loss: 0.0774 - accuracy: 0.9859 - 91ms/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "25/25 - 0s - loss: 0.0775 - accuracy: 0.9859 - 98ms/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "25/25 - 0s - loss: 0.0780 - accuracy: 0.9872 - 93ms/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "25/25 - 0s - loss: 0.0754 - accuracy: 0.9872 - 109ms/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "25/25 - 0s - loss: 0.0755 - accuracy: 0.9872 - 99ms/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "25/25 - 0s - loss: 0.0744 - accuracy: 0.9872 - 94ms/epoch - 4ms/step\n",
            "Epoch 178/200\n",
            "25/25 - 0s - loss: 0.0744 - accuracy: 0.9872 - 93ms/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "25/25 - 0s - loss: 0.0748 - accuracy: 0.9872 - 93ms/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "25/25 - 0s - loss: 0.0740 - accuracy: 0.9872 - 92ms/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "25/25 - 0s - loss: 0.0739 - accuracy: 0.9872 - 96ms/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "25/25 - 0s - loss: 0.0744 - accuracy: 0.9859 - 91ms/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "25/25 - 0s - loss: 0.0742 - accuracy: 0.9872 - 94ms/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "25/25 - 0s - loss: 0.0728 - accuracy: 0.9872 - 95ms/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "25/25 - 0s - loss: 0.0766 - accuracy: 0.9846 - 115ms/epoch - 5ms/step\n",
            "Epoch 186/200\n",
            "25/25 - 0s - loss: 0.0724 - accuracy: 0.9872 - 98ms/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "25/25 - 0s - loss: 0.0725 - accuracy: 0.9872 - 95ms/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "25/25 - 0s - loss: 0.0717 - accuracy: 0.9872 - 92ms/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "25/25 - 0s - loss: 0.0719 - accuracy: 0.9872 - 92ms/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "25/25 - 0s - loss: 0.0712 - accuracy: 0.9872 - 91ms/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "25/25 - 0s - loss: 0.0718 - accuracy: 0.9859 - 90ms/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "25/25 - 0s - loss: 0.0761 - accuracy: 0.9833 - 90ms/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "25/25 - 0s - loss: 0.0780 - accuracy: 0.9846 - 93ms/epoch - 4ms/step\n",
            "Epoch 194/200\n",
            "25/25 - 0s - loss: 0.0749 - accuracy: 0.9859 - 100ms/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "25/25 - 0s - loss: 0.0756 - accuracy: 0.9846 - 95ms/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "25/25 - 0s - loss: 0.0741 - accuracy: 0.9859 - 101ms/epoch - 4ms/step\n",
            "Epoch 197/200\n",
            "25/25 - 0s - loss: 0.0794 - accuracy: 0.9846 - 100ms/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "25/25 - 0s - loss: 0.0699 - accuracy: 0.9872 - 93ms/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "25/25 - 0s - loss: 0.0730 - accuracy: 0.9846 - 67ms/epoch - 3ms/step\n",
            "Epoch 200/200\n",
            "25/25 - 0s - loss: 0.0715 - accuracy: 0.9859 - 65ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ac02033d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict probabilities for test set\n",
        "from numpy import argmax\n",
        "from sklearn.metrics import ( accuracy_score, roc_auc_score,\n",
        "                             precision_score, recall_score, f1_score,fbeta_score,\n",
        "                             classification_report\n",
        "                             )\n",
        "yhats = model_4.predict(X_test, verbose=0)\n",
        "yhat = argmax(yhats, axis=-1).astype('int')\n",
        "# evaluate on test set\n",
        "yhat = model_4.predict(X_test)\n",
        "yhat = argmax(yhat, axis=-1).astype('int')\n",
        "acc = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.3f' % acc)\n",
        "\n",
        "precision = precision_score(y_test,yhat)*100\n",
        "recall = recall_score(y_test,yhat)*100\n",
        "f1 = f1_score(y_test,yhat)*100\n",
        "\n",
        "print(\"precision\",precision)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1\",f1)\n",
        "\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhEmLGbmw7_7",
        "outputId": "46fc761f-72f5-481d-ccae-3b01c3cf53e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.458\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      1.00      0.63       153\n",
            "           1       0.00      0.00      0.00       181\n",
            "\n",
            "    accuracy                           0.46       334\n",
            "   macro avg       0.23      0.50      0.31       334\n",
            "weighted avg       0.21      0.46      0.29       334\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = X.shape[1]\n",
        "\n",
        "n_class = len(unique(y))\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(60, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(30, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(n_class, activation='softmax'))\n",
        "# compile the keras model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=2)\n",
        "# evaluate on test set\n",
        "yhat = model.predict(X_test)\n",
        "yhat = argmax(yhat, axis=-1).astype('int')\n",
        "acc = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.3f' % acc)\n",
        "\n",
        "precision = precision_score(y_test,yhat)*100\n",
        "recall = recall_score(y_test,yhat)*100\n",
        "f1 = f1_score(y_test,yhat)*100\n",
        "\n",
        "print(\"precision\",precision)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1\",f1)\n",
        "\n",
        "print(classification_report(y_test, yhat))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzHcHMtYw_Ne",
        "outputId": "a64d58c1-bf88-4356-bbb3-bfad815a3ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "25/25 - 1s - loss: 0.8697 - 1s/epoch - 47ms/step\n",
            "Epoch 2/200\n",
            "25/25 - 0s - loss: 0.6070 - 59ms/epoch - 2ms/step\n",
            "Epoch 3/200\n",
            "25/25 - 0s - loss: 0.5143 - 57ms/epoch - 2ms/step\n",
            "Epoch 4/200\n",
            "25/25 - 0s - loss: 0.4523 - 58ms/epoch - 2ms/step\n",
            "Epoch 5/200\n",
            "25/25 - 0s - loss: 0.4137 - 73ms/epoch - 3ms/step\n",
            "Epoch 6/200\n",
            "25/25 - 0s - loss: 0.3495 - 57ms/epoch - 2ms/step\n",
            "Epoch 7/200\n",
            "25/25 - 0s - loss: 0.3037 - 63ms/epoch - 3ms/step\n",
            "Epoch 8/200\n",
            "25/25 - 0s - loss: 0.2659 - 55ms/epoch - 2ms/step\n",
            "Epoch 9/200\n",
            "25/25 - 0s - loss: 0.2300 - 55ms/epoch - 2ms/step\n",
            "Epoch 10/200\n",
            "25/25 - 0s - loss: 0.2022 - 61ms/epoch - 2ms/step\n",
            "Epoch 11/200\n",
            "25/25 - 0s - loss: 0.1923 - 62ms/epoch - 2ms/step\n",
            "Epoch 12/200\n",
            "25/25 - 0s - loss: 0.1548 - 57ms/epoch - 2ms/step\n",
            "Epoch 13/200\n",
            "25/25 - 0s - loss: 0.1387 - 61ms/epoch - 2ms/step\n",
            "Epoch 14/200\n",
            "25/25 - 0s - loss: 0.1120 - 63ms/epoch - 3ms/step\n",
            "Epoch 15/200\n",
            "25/25 - 0s - loss: 0.0966 - 73ms/epoch - 3ms/step\n",
            "Epoch 16/200\n",
            "25/25 - 0s - loss: 0.0870 - 88ms/epoch - 4ms/step\n",
            "Epoch 17/200\n",
            "25/25 - 0s - loss: 0.0728 - 80ms/epoch - 3ms/step\n",
            "Epoch 18/200\n",
            "25/25 - 0s - loss: 0.0634 - 77ms/epoch - 3ms/step\n",
            "Epoch 19/200\n",
            "25/25 - 0s - loss: 0.0585 - 80ms/epoch - 3ms/step\n",
            "Epoch 20/200\n",
            "25/25 - 0s - loss: 0.0517 - 78ms/epoch - 3ms/step\n",
            "Epoch 21/200\n",
            "25/25 - 0s - loss: 0.0505 - 78ms/epoch - 3ms/step\n",
            "Epoch 22/200\n",
            "25/25 - 0s - loss: 0.0475 - 77ms/epoch - 3ms/step\n",
            "Epoch 23/200\n",
            "25/25 - 0s - loss: 0.0474 - 82ms/epoch - 3ms/step\n",
            "Epoch 24/200\n",
            "25/25 - 0s - loss: 0.0382 - 84ms/epoch - 3ms/step\n",
            "Epoch 25/200\n",
            "25/25 - 0s - loss: 0.0300 - 101ms/epoch - 4ms/step\n",
            "Epoch 26/200\n",
            "25/25 - 0s - loss: 0.0245 - 103ms/epoch - 4ms/step\n",
            "Epoch 27/200\n",
            "25/25 - 0s - loss: 0.0262 - 102ms/epoch - 4ms/step\n",
            "Epoch 28/200\n",
            "25/25 - 0s - loss: 0.0222 - 92ms/epoch - 4ms/step\n",
            "Epoch 29/200\n",
            "25/25 - 0s - loss: 0.0205 - 98ms/epoch - 4ms/step\n",
            "Epoch 30/200\n",
            "25/25 - 0s - loss: 0.0245 - 87ms/epoch - 3ms/step\n",
            "Epoch 31/200\n",
            "25/25 - 0s - loss: 0.0213 - 83ms/epoch - 3ms/step\n",
            "Epoch 32/200\n",
            "25/25 - 0s - loss: 0.0237 - 81ms/epoch - 3ms/step\n",
            "Epoch 33/200\n",
            "25/25 - 0s - loss: 0.0267 - 78ms/epoch - 3ms/step\n",
            "Epoch 34/200\n",
            "25/25 - 0s - loss: 0.0181 - 83ms/epoch - 3ms/step\n",
            "Epoch 35/200\n",
            "25/25 - 0s - loss: 0.0255 - 78ms/epoch - 3ms/step\n",
            "Epoch 36/200\n",
            "25/25 - 0s - loss: 0.0278 - 82ms/epoch - 3ms/step\n",
            "Epoch 37/200\n",
            "25/25 - 0s - loss: 0.0251 - 92ms/epoch - 4ms/step\n",
            "Epoch 38/200\n",
            "25/25 - 0s - loss: 0.0226 - 91ms/epoch - 4ms/step\n",
            "Epoch 39/200\n",
            "25/25 - 0s - loss: 0.0145 - 79ms/epoch - 3ms/step\n",
            "Epoch 40/200\n",
            "25/25 - 0s - loss: 0.0105 - 81ms/epoch - 3ms/step\n",
            "Epoch 41/200\n",
            "25/25 - 0s - loss: 0.0155 - 84ms/epoch - 3ms/step\n",
            "Epoch 42/200\n",
            "25/25 - 0s - loss: 0.0119 - 78ms/epoch - 3ms/step\n",
            "Epoch 43/200\n",
            "25/25 - 0s - loss: 0.0120 - 85ms/epoch - 3ms/step\n",
            "Epoch 44/200\n",
            "25/25 - 0s - loss: 0.0094 - 79ms/epoch - 3ms/step\n",
            "Epoch 45/200\n",
            "25/25 - 0s - loss: 0.0099 - 78ms/epoch - 3ms/step\n",
            "Epoch 46/200\n",
            "25/25 - 0s - loss: 0.0082 - 80ms/epoch - 3ms/step\n",
            "Epoch 47/200\n",
            "25/25 - 0s - loss: 0.0117 - 97ms/epoch - 4ms/step\n",
            "Epoch 48/200\n",
            "25/25 - 0s - loss: 0.0104 - 91ms/epoch - 4ms/step\n",
            "Epoch 49/200\n",
            "25/25 - 0s - loss: 0.0163 - 95ms/epoch - 4ms/step\n",
            "Epoch 50/200\n",
            "25/25 - 0s - loss: 0.0177 - 91ms/epoch - 4ms/step\n",
            "Epoch 51/200\n",
            "25/25 - 0s - loss: 0.0134 - 86ms/epoch - 3ms/step\n",
            "Epoch 52/200\n",
            "25/25 - 0s - loss: 0.0113 - 86ms/epoch - 3ms/step\n",
            "Epoch 53/200\n",
            "25/25 - 0s - loss: 0.0107 - 83ms/epoch - 3ms/step\n",
            "Epoch 54/200\n",
            "25/25 - 0s - loss: 0.0068 - 78ms/epoch - 3ms/step\n",
            "Epoch 55/200\n",
            "25/25 - 0s - loss: 0.0072 - 84ms/epoch - 3ms/step\n",
            "Epoch 56/200\n",
            "25/25 - 0s - loss: 0.0113 - 57ms/epoch - 2ms/step\n",
            "Epoch 57/200\n",
            "25/25 - 0s - loss: 0.0110 - 62ms/epoch - 2ms/step\n",
            "Epoch 58/200\n",
            "25/25 - 0s - loss: 0.0120 - 57ms/epoch - 2ms/step\n",
            "Epoch 59/200\n",
            "25/25 - 0s - loss: 0.0118 - 61ms/epoch - 2ms/step\n",
            "Epoch 60/200\n",
            "25/25 - 0s - loss: 0.0095 - 57ms/epoch - 2ms/step\n",
            "Epoch 61/200\n",
            "25/25 - 0s - loss: 0.0090 - 63ms/epoch - 3ms/step\n",
            "Epoch 62/200\n",
            "25/25 - 0s - loss: 0.0150 - 57ms/epoch - 2ms/step\n",
            "Epoch 63/200\n",
            "25/25 - 0s - loss: 0.0137 - 66ms/epoch - 3ms/step\n",
            "Epoch 64/200\n",
            "25/25 - 0s - loss: 0.0183 - 61ms/epoch - 2ms/step\n",
            "Epoch 65/200\n",
            "25/25 - 0s - loss: 0.0094 - 62ms/epoch - 2ms/step\n",
            "Epoch 66/200\n",
            "25/25 - 0s - loss: 0.0044 - 56ms/epoch - 2ms/step\n",
            "Epoch 67/200\n",
            "25/25 - 0s - loss: 0.0088 - 59ms/epoch - 2ms/step\n",
            "Epoch 68/200\n",
            "25/25 - 0s - loss: 0.0103 - 63ms/epoch - 3ms/step\n",
            "Epoch 69/200\n",
            "25/25 - 0s - loss: 0.0071 - 63ms/epoch - 3ms/step\n",
            "Epoch 70/200\n",
            "25/25 - 0s - loss: 0.0055 - 56ms/epoch - 2ms/step\n",
            "Epoch 71/200\n",
            "25/25 - 0s - loss: 0.0073 - 72ms/epoch - 3ms/step\n",
            "Epoch 72/200\n",
            "25/25 - 0s - loss: 0.0070 - 67ms/epoch - 3ms/step\n",
            "Epoch 73/200\n",
            "25/25 - 0s - loss: 0.0073 - 60ms/epoch - 2ms/step\n",
            "Epoch 74/200\n",
            "25/25 - 0s - loss: 0.0074 - 68ms/epoch - 3ms/step\n",
            "Epoch 75/200\n",
            "25/25 - 0s - loss: 0.0033 - 60ms/epoch - 2ms/step\n",
            "Epoch 76/200\n",
            "25/25 - 0s - loss: 0.0059 - 63ms/epoch - 3ms/step\n",
            "Epoch 77/200\n",
            "25/25 - 0s - loss: 0.0018 - 68ms/epoch - 3ms/step\n",
            "Epoch 78/200\n",
            "25/25 - 0s - loss: 0.0037 - 71ms/epoch - 3ms/step\n",
            "Epoch 79/200\n",
            "25/25 - 0s - loss: 0.0055 - 63ms/epoch - 3ms/step\n",
            "Epoch 80/200\n",
            "25/25 - 0s - loss: 0.0051 - 61ms/epoch - 2ms/step\n",
            "Epoch 81/200\n",
            "25/25 - 0s - loss: 0.0042 - 65ms/epoch - 3ms/step\n",
            "Epoch 82/200\n",
            "25/25 - 0s - loss: 0.0042 - 62ms/epoch - 2ms/step\n",
            "Epoch 83/200\n",
            "25/25 - 0s - loss: 0.0016 - 58ms/epoch - 2ms/step\n",
            "Epoch 84/200\n",
            "25/25 - 0s - loss: 0.0043 - 61ms/epoch - 2ms/step\n",
            "Epoch 85/200\n",
            "25/25 - 0s - loss: 0.0052 - 63ms/epoch - 3ms/step\n",
            "Epoch 86/200\n",
            "25/25 - 0s - loss: 0.0021 - 61ms/epoch - 2ms/step\n",
            "Epoch 87/200\n",
            "25/25 - 0s - loss: 0.0032 - 57ms/epoch - 2ms/step\n",
            "Epoch 88/200\n",
            "25/25 - 0s - loss: 0.0059 - 66ms/epoch - 3ms/step\n",
            "Epoch 89/200\n",
            "25/25 - 0s - loss: 0.0044 - 65ms/epoch - 3ms/step\n",
            "Epoch 90/200\n",
            "25/25 - 0s - loss: 0.0016 - 56ms/epoch - 2ms/step\n",
            "Epoch 91/200\n",
            "25/25 - 0s - loss: 0.0021 - 61ms/epoch - 2ms/step\n",
            "Epoch 92/200\n",
            "25/25 - 0s - loss: 0.0033 - 65ms/epoch - 3ms/step\n",
            "Epoch 93/200\n",
            "25/25 - 0s - loss: 0.0040 - 58ms/epoch - 2ms/step\n",
            "Epoch 94/200\n",
            "25/25 - 0s - loss: 0.0044 - 79ms/epoch - 3ms/step\n",
            "Epoch 95/200\n",
            "25/25 - 0s - loss: 0.0029 - 62ms/epoch - 2ms/step\n",
            "Epoch 96/200\n",
            "25/25 - 0s - loss: 0.0024 - 54ms/epoch - 2ms/step\n",
            "Epoch 97/200\n",
            "25/25 - 0s - loss: 0.0034 - 62ms/epoch - 2ms/step\n",
            "Epoch 98/200\n",
            "25/25 - 0s - loss: 0.0033 - 68ms/epoch - 3ms/step\n",
            "Epoch 99/200\n",
            "25/25 - 0s - loss: 0.0043 - 77ms/epoch - 3ms/step\n",
            "Epoch 100/200\n",
            "25/25 - 0s - loss: 0.0023 - 60ms/epoch - 2ms/step\n",
            "Epoch 101/200\n",
            "25/25 - 0s - loss: 0.0013 - 71ms/epoch - 3ms/step\n",
            "Epoch 102/200\n",
            "25/25 - 0s - loss: 0.0013 - 62ms/epoch - 2ms/step\n",
            "Epoch 103/200\n",
            "25/25 - 0s - loss: 0.0012 - 66ms/epoch - 3ms/step\n",
            "Epoch 104/200\n",
            "25/25 - 0s - loss: 0.0015 - 72ms/epoch - 3ms/step\n",
            "Epoch 105/200\n",
            "25/25 - 0s - loss: 0.0013 - 69ms/epoch - 3ms/step\n",
            "Epoch 106/200\n",
            "25/25 - 0s - loss: 0.0025 - 62ms/epoch - 2ms/step\n",
            "Epoch 107/200\n",
            "25/25 - 0s - loss: 0.0113 - 56ms/epoch - 2ms/step\n",
            "Epoch 108/200\n",
            "25/25 - 0s - loss: 0.0144 - 70ms/epoch - 3ms/step\n",
            "Epoch 109/200\n",
            "25/25 - 0s - loss: 0.0387 - 63ms/epoch - 3ms/step\n",
            "Epoch 110/200\n",
            "25/25 - 0s - loss: 0.4227 - 54ms/epoch - 2ms/step\n",
            "Epoch 111/200\n",
            "25/25 - 0s - loss: 0.5407 - 57ms/epoch - 2ms/step\n",
            "Epoch 112/200\n",
            "25/25 - 0s - loss: 0.1958 - 55ms/epoch - 2ms/step\n",
            "Epoch 113/200\n",
            "25/25 - 0s - loss: 0.1587 - 57ms/epoch - 2ms/step\n",
            "Epoch 114/200\n",
            "25/25 - 0s - loss: 0.0807 - 63ms/epoch - 3ms/step\n",
            "Epoch 115/200\n",
            "25/25 - 0s - loss: 0.0303 - 58ms/epoch - 2ms/step\n",
            "Epoch 116/200\n",
            "25/25 - 0s - loss: 0.0197 - 61ms/epoch - 2ms/step\n",
            "Epoch 117/200\n",
            "25/25 - 0s - loss: 0.0104 - 64ms/epoch - 3ms/step\n",
            "Epoch 118/200\n",
            "25/25 - 0s - loss: 0.0074 - 57ms/epoch - 2ms/step\n",
            "Epoch 119/200\n",
            "25/25 - 0s - loss: 0.0060 - 59ms/epoch - 2ms/step\n",
            "Epoch 120/200\n",
            "25/25 - 0s - loss: 0.0054 - 60ms/epoch - 2ms/step\n",
            "Epoch 121/200\n",
            "25/25 - 0s - loss: 0.0048 - 58ms/epoch - 2ms/step\n",
            "Epoch 122/200\n",
            "25/25 - 0s - loss: 0.0043 - 67ms/epoch - 3ms/step\n",
            "Epoch 123/200\n",
            "25/25 - 0s - loss: 0.0040 - 65ms/epoch - 3ms/step\n",
            "Epoch 124/200\n",
            "25/25 - 0s - loss: 0.0038 - 68ms/epoch - 3ms/step\n",
            "Epoch 125/200\n",
            "25/25 - 0s - loss: 0.0034 - 56ms/epoch - 2ms/step\n",
            "Epoch 126/200\n",
            "25/25 - 0s - loss: 0.0034 - 59ms/epoch - 2ms/step\n",
            "Epoch 127/200\n",
            "25/25 - 0s - loss: 0.0032 - 67ms/epoch - 3ms/step\n",
            "Epoch 128/200\n",
            "25/25 - 0s - loss: 0.0029 - 68ms/epoch - 3ms/step\n",
            "Epoch 129/200\n",
            "25/25 - 0s - loss: 0.0029 - 80ms/epoch - 3ms/step\n",
            "Epoch 130/200\n",
            "25/25 - 0s - loss: 0.0027 - 67ms/epoch - 3ms/step\n",
            "Epoch 131/200\n",
            "25/25 - 0s - loss: 0.0026 - 68ms/epoch - 3ms/step\n",
            "Epoch 132/200\n",
            "25/25 - 0s - loss: 0.0023 - 68ms/epoch - 3ms/step\n",
            "Epoch 133/200\n",
            "25/25 - 0s - loss: 0.0024 - 64ms/epoch - 3ms/step\n",
            "Epoch 134/200\n",
            "25/25 - 0s - loss: 0.0022 - 71ms/epoch - 3ms/step\n",
            "Epoch 135/200\n",
            "25/25 - 0s - loss: 0.0023 - 59ms/epoch - 2ms/step\n",
            "Epoch 136/200\n",
            "25/25 - 0s - loss: 0.0024 - 63ms/epoch - 3ms/step\n",
            "Epoch 137/200\n",
            "25/25 - 0s - loss: 0.0026 - 56ms/epoch - 2ms/step\n",
            "Epoch 138/200\n",
            "25/25 - 0s - loss: 0.0035 - 56ms/epoch - 2ms/step\n",
            "Epoch 139/200\n",
            "25/25 - 0s - loss: 0.0032 - 61ms/epoch - 2ms/step\n",
            "Epoch 140/200\n",
            "25/25 - 0s - loss: 0.0020 - 55ms/epoch - 2ms/step\n",
            "Epoch 141/200\n",
            "25/25 - 0s - loss: 0.0017 - 56ms/epoch - 2ms/step\n",
            "Epoch 142/200\n",
            "25/25 - 0s - loss: 0.0017 - 57ms/epoch - 2ms/step\n",
            "Epoch 143/200\n",
            "25/25 - 0s - loss: 0.0017 - 56ms/epoch - 2ms/step\n",
            "Epoch 144/200\n",
            "25/25 - 0s - loss: 0.0016 - 71ms/epoch - 3ms/step\n",
            "Epoch 145/200\n",
            "25/25 - 0s - loss: 0.0015 - 56ms/epoch - 2ms/step\n",
            "Epoch 146/200\n",
            "25/25 - 0s - loss: 0.0016 - 54ms/epoch - 2ms/step\n",
            "Epoch 147/200\n",
            "25/25 - 0s - loss: 0.0015 - 61ms/epoch - 2ms/step\n",
            "Epoch 148/200\n",
            "25/25 - 0s - loss: 0.0017 - 62ms/epoch - 2ms/step\n",
            "Epoch 149/200\n",
            "25/25 - 0s - loss: 0.0016 - 61ms/epoch - 2ms/step\n",
            "Epoch 150/200\n",
            "25/25 - 0s - loss: 0.0016 - 63ms/epoch - 3ms/step\n",
            "Epoch 151/200\n",
            "25/25 - 0s - loss: 0.0013 - 71ms/epoch - 3ms/step\n",
            "Epoch 152/200\n",
            "25/25 - 0s - loss: 0.0013 - 62ms/epoch - 2ms/step\n",
            "Epoch 153/200\n",
            "25/25 - 0s - loss: 0.0013 - 58ms/epoch - 2ms/step\n",
            "Epoch 154/200\n",
            "25/25 - 0s - loss: 0.0012 - 67ms/epoch - 3ms/step\n",
            "Epoch 155/200\n",
            "25/25 - 0s - loss: 0.0011 - 65ms/epoch - 3ms/step\n",
            "Epoch 156/200\n",
            "25/25 - 0s - loss: 0.0011 - 72ms/epoch - 3ms/step\n",
            "Epoch 157/200\n",
            "25/25 - 0s - loss: 0.0011 - 73ms/epoch - 3ms/step\n",
            "Epoch 158/200\n",
            "25/25 - 0s - loss: 0.0011 - 62ms/epoch - 2ms/step\n",
            "Epoch 159/200\n",
            "25/25 - 0s - loss: 0.0011 - 69ms/epoch - 3ms/step\n",
            "Epoch 160/200\n",
            "25/25 - 0s - loss: 0.0010 - 71ms/epoch - 3ms/step\n",
            "Epoch 161/200\n",
            "25/25 - 0s - loss: 0.0017 - 65ms/epoch - 3ms/step\n",
            "Epoch 162/200\n",
            "25/25 - 0s - loss: 0.0034 - 70ms/epoch - 3ms/step\n",
            "Epoch 163/200\n",
            "25/25 - 0s - loss: 0.0086 - 71ms/epoch - 3ms/step\n",
            "Epoch 164/200\n",
            "25/25 - 0s - loss: 0.0058 - 57ms/epoch - 2ms/step\n",
            "Epoch 165/200\n",
            "25/25 - 0s - loss: 0.0199 - 61ms/epoch - 2ms/step\n",
            "Epoch 166/200\n",
            "25/25 - 0s - loss: 0.0073 - 56ms/epoch - 2ms/step\n",
            "Epoch 167/200\n",
            "25/25 - 0s - loss: 0.0018 - 54ms/epoch - 2ms/step\n",
            "Epoch 168/200\n",
            "25/25 - 0s - loss: 0.0018 - 63ms/epoch - 3ms/step\n",
            "Epoch 169/200\n",
            "25/25 - 0s - loss: 0.0014 - 64ms/epoch - 3ms/step\n",
            "Epoch 170/200\n",
            "25/25 - 0s - loss: 0.0013 - 56ms/epoch - 2ms/step\n",
            "Epoch 171/200\n",
            "25/25 - 0s - loss: 0.0014 - 55ms/epoch - 2ms/step\n",
            "Epoch 172/200\n",
            "25/25 - 0s - loss: 0.0012 - 57ms/epoch - 2ms/step\n",
            "Epoch 173/200\n",
            "25/25 - 0s - loss: 0.0011 - 61ms/epoch - 2ms/step\n",
            "Epoch 174/200\n",
            "25/25 - 0s - loss: 0.0011 - 64ms/epoch - 3ms/step\n",
            "Epoch 175/200\n",
            "25/25 - 0s - loss: 0.0011 - 57ms/epoch - 2ms/step\n",
            "Epoch 176/200\n",
            "25/25 - 0s - loss: 0.0012 - 65ms/epoch - 3ms/step\n",
            "Epoch 177/200\n",
            "25/25 - 0s - loss: 0.0016 - 58ms/epoch - 2ms/step\n",
            "Epoch 178/200\n",
            "25/25 - 0s - loss: 0.0015 - 62ms/epoch - 2ms/step\n",
            "Epoch 179/200\n",
            "25/25 - 0s - loss: 0.0012 - 66ms/epoch - 3ms/step\n",
            "Epoch 180/200\n",
            "25/25 - 0s - loss: 9.8241e-04 - 58ms/epoch - 2ms/step\n",
            "Epoch 181/200\n",
            "25/25 - 0s - loss: 0.0011 - 62ms/epoch - 2ms/step\n",
            "Epoch 182/200\n",
            "25/25 - 0s - loss: 0.0010 - 66ms/epoch - 3ms/step\n",
            "Epoch 183/200\n",
            "25/25 - 0s - loss: 8.6150e-04 - 60ms/epoch - 2ms/step\n",
            "Epoch 184/200\n",
            "25/25 - 0s - loss: 8.8580e-04 - 69ms/epoch - 3ms/step\n",
            "Epoch 185/200\n",
            "25/25 - 0s - loss: 9.2880e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 186/200\n",
            "25/25 - 0s - loss: 9.3681e-04 - 74ms/epoch - 3ms/step\n",
            "Epoch 187/200\n",
            "25/25 - 0s - loss: 0.0011 - 69ms/epoch - 3ms/step\n",
            "Epoch 188/200\n",
            "25/25 - 0s - loss: 0.0013 - 65ms/epoch - 3ms/step\n",
            "Epoch 189/200\n",
            "25/25 - 0s - loss: 0.0011 - 72ms/epoch - 3ms/step\n",
            "Epoch 190/200\n",
            "25/25 - 0s - loss: 7.8921e-04 - 71ms/epoch - 3ms/step\n",
            "Epoch 191/200\n",
            "25/25 - 0s - loss: 7.4506e-04 - 68ms/epoch - 3ms/step\n",
            "Epoch 192/200\n",
            "25/25 - 0s - loss: 8.3796e-04 - 63ms/epoch - 3ms/step\n",
            "Epoch 193/200\n",
            "25/25 - 0s - loss: 8.3131e-04 - 64ms/epoch - 3ms/step\n",
            "Epoch 194/200\n",
            "25/25 - 0s - loss: 5.3400e-04 - 69ms/epoch - 3ms/step\n",
            "Epoch 195/200\n",
            "25/25 - 0s - loss: 0.0010 - 66ms/epoch - 3ms/step\n",
            "Epoch 196/200\n",
            "25/25 - 0s - loss: 6.4062e-04 - 64ms/epoch - 3ms/step\n",
            "Epoch 197/200\n",
            "25/25 - 0s - loss: 7.1539e-04 - 62ms/epoch - 2ms/step\n",
            "Epoch 198/200\n",
            "25/25 - 0s - loss: 7.7860e-04 - 59ms/epoch - 2ms/step\n",
            "Epoch 199/200\n",
            "25/25 - 0s - loss: 7.1112e-04 - 64ms/epoch - 3ms/step\n",
            "Epoch 200/200\n",
            "25/25 - 0s - loss: 6.3568e-04 - 55ms/epoch - 2ms/step\n",
            "11/11 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.611\n",
            "precision 64.24581005586593\n",
            "recall 63.53591160220995\n",
            "f1 63.888888888888886\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.58      0.58       153\n",
            "           1       0.64      0.64      0.64       181\n",
            "\n",
            "    accuracy                           0.61       334\n",
            "   macro avg       0.61      0.61      0.61       334\n",
            "weighted avg       0.61      0.61      0.61       334\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(X)\n",
        "print(scaled)\n",
        "X = pd.DataFrame(scaled)\n",
        "print(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWznSuG_xA7Y",
        "outputId": "e314a45f-65cd-43c9-e02d-d91cc1ca9101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.23427536 -0.87076632 -0.5519429  ...  0.36611581 -0.37239391\n",
            "   0.04849428]\n",
            " [-0.08906344 -0.20490089 -0.67694081 ... -1.54908636 -1.74031722\n",
            "  -0.13508253]\n",
            " [ 1.9249399   2.4343237  -0.021955   ... -1.6390264   1.56279418\n",
            "   0.85594144]\n",
            " ...\n",
            " [-0.17009248 -0.2166922   0.63608194 ...  0.28764747 -0.23313941\n",
            "   0.14057102]\n",
            " [ 0.00560889  0.28478825  0.5226109  ... -0.13862661 -1.12131413\n",
            "  -0.25860244]\n",
            " [-0.72625274  0.47149966  0.32674036 ... -0.74807932  0.3333198\n",
            "   0.43727823]]\n",
            "           0         1         2         3         4         5         6    \\\n",
            "0    -0.234275 -0.870766 -0.551943  0.647007 -0.513894  1.881730 -0.936612   \n",
            "1    -0.089063 -0.204901 -0.676941  1.648936 -0.050750  0.760996 -0.180061   \n",
            "2     1.924940  2.434324 -0.021955  0.646565  1.970107 -0.443700 -2.000153   \n",
            "3    -1.881790 -2.054625  0.176561  0.753801  2.235826  2.337784 -0.065538   \n",
            "4    -0.459759  0.288134 -0.630831 -0.047019  0.421873 -0.511784  1.121777   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "1108 -0.454127 -1.552871 -0.306417  1.644478  0.907684 -0.712573 -1.143127   \n",
            "1109  1.623303  1.075879 -0.254610 -0.347430  0.171834 -1.671017 -0.835309   \n",
            "1110 -0.170092 -0.216692  0.636082  0.020982 -0.805924  0.786974  0.197506   \n",
            "1111  0.005609  0.284788  0.522611  0.048785 -1.262380 -0.014861  0.340799   \n",
            "1112 -0.726253  0.471500  0.326740  0.063114 -0.411867  0.239108  0.531883   \n",
            "\n",
            "           7         8         9    ...       374       375       376  \\\n",
            "0    -1.050434  0.023160  0.926500  ...  0.278137 -0.809306 -1.254900   \n",
            "1     0.151034 -1.085559 -1.357408  ...  0.909600 -1.615120 -0.697182   \n",
            "2     0.130011  2.600844 -0.170185  ... -3.138157 -0.232105 -0.290317   \n",
            "3    -0.112580  1.070814  0.335309  ...  0.170600  1.295302  0.214732   \n",
            "4    -0.381685 -0.301601 -0.250748  ...  0.150787  1.153198  0.277128   \n",
            "...        ...       ...       ...  ...       ...       ...       ...   \n",
            "1108 -0.271707  1.527294 -0.031144  ... -0.149033  0.458134  0.757735   \n",
            "1109  1.649229  0.929360 -0.013875  ... -0.076843 -0.436308  0.067365   \n",
            "1110  0.073225 -0.417604  0.787077  ... -0.544389  0.347465 -0.025096   \n",
            "1111 -0.519602 -1.264328  0.625449  ... -0.917961  0.108956 -0.707416   \n",
            "1112 -1.181301  0.003045  0.592758  ...  0.185812 -0.491815 -0.234818   \n",
            "\n",
            "           377       378       379       380       381       382       383  \n",
            "0    -0.371747  0.884120  0.437407  0.076612  0.366116 -0.372394  0.048494  \n",
            "1     0.491988 -0.160041  0.437617 -0.969405 -1.549086 -1.740317 -0.135083  \n",
            "2     0.881302  0.594281  1.990800  0.098633 -1.639026  1.562794  0.855941  \n",
            "3     0.976453 -1.338347 -0.616795  0.398934  0.412311  0.017056 -2.833859  \n",
            "4    -0.404991  0.007598  0.113892  0.618088  0.625284  0.349581 -0.566607  \n",
            "...        ...       ...       ...       ...       ...       ...       ...  \n",
            "1108 -0.448534  1.591627 -2.490111  0.165216 -0.355763  1.515568  0.974078  \n",
            "1109  0.224164 -1.506515  1.220076 -1.314908 -0.113934  0.478529  0.077216  \n",
            "1110  0.006817 -0.314711  0.270416  0.042634  0.287647 -0.233139  0.140571  \n",
            "1111  0.721769  0.209661  0.868025 -0.143716 -0.138627 -1.121314 -0.258602  \n",
            "1112 -0.019256 -0.627925 -0.631622  0.719651 -0.748079  0.333320  0.437278  \n",
            "\n",
            "[1113 rows x 384 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import f1_score\n",
        "# Making the Neural Network Classifier\n",
        "NN = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(10, 30), random_state=1)\n",
        "\n",
        "# Training the model on the training data and labels\n",
        "NN.fit(X_train, y_train)\n",
        "\n",
        "# Testing the model i.e. predicting the labels of the test data.\n",
        "y_pred = NN.predict(X_test)\n",
        "\n",
        "# Evaluating the results of the model\n",
        "accuracy = accuracy_score(y_test,y_pred)*100\n",
        "confusion_mat = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "# Step 8\n",
        "# Printing the Results\n",
        "print(\"Accuracy for Neural Network is:\",accuracy)\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_mat)\n",
        "\n",
        "precision = precision_score(y_test,y_pred)*100\n",
        "recall = recall_score(y_test,y_pred)*100\n",
        "f1 = f1_score(y_test,y_pred)*100\n",
        "f2 = fbeta_score(y_test,y_pred, beta=2)*100\n",
        "print(\"precision\",precision)\n",
        "print(\"recall\",recall)\n",
        "print(\"f1\",f1)\n",
        "print(\"f2\",f2)\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HclBed5dxDKA",
        "outputId": "51312930-5a40-4649-b541-94f41a15fa1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Neural Network is: 55.97826086956522\n",
            "Confusion Matrix\n",
            "[[ 98  74]\n",
            " [ 88 108]]\n",
            "precision 59.34065934065934\n",
            "recall 55.10204081632652\n",
            "f1 57.14285714285714\n",
            "f2 55.90062111801242\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.57      0.55       172\n",
            "           1       0.59      0.55      0.57       196\n",
            "\n",
            "    accuracy                           0.56       368\n",
            "   macro avg       0.56      0.56      0.56       368\n",
            "weighted avg       0.56      0.56      0.56       368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "54EhAEvsxC-_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}